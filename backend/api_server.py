"""
FastAPI æœåŠ¡å…¥å£

æä¾›æ³•åŠ¡æ–‡æœ¬å®¡é˜…ç³»ç»Ÿçš„ RESTful APIã€‚
"""

from __future__ import annotations

import asyncio
import logging
import os
from datetime import datetime, timedelta
from pathlib import Path

# åŠ è½½ .env æ–‡ä»¶ï¼ˆæœ¬åœ°å¼€å‘ç”¨ï¼‰
from dotenv import load_dotenv
load_dotenv()
from typing import List, Optional

import httpx
import jwt
from fastapi import BackgroundTasks, Depends, FastAPI, File, HTTPException, Query, UploadFile
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse, Response, StreamingResponse
from fastapi.security import HTTPAuthorizationCredentials, HTTPBearer
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel

from src.contract_review.config import get_settings, load_settings
from src.contract_review.document_loader import load_document, load_document_async
from src.contract_review.ocr_service import OCRService, init_ocr_service, get_ocr_service
from src.contract_review.models import (
    MaterialType,
    ModificationSuggestion,
    ReviewResult,
    ReviewStandard,
    ReviewTask,
    StandardRecommendation,
)
from src.contract_review.result_formatter import ResultFormatter, generate_summary_report
from src.contract_review.review_engine import ReviewEngine
from src.contract_review.standard_library import StandardLibraryManager
from src.contract_review.business_library import BusinessLibraryManager
from src.contract_review.redline_generator import generate_redline_document
from src.contract_review.standard_parser import parse_standard_file
from src.contract_review.storage import StorageManager
from src.contract_review.tasks import TaskManager
from src.contract_review.supabase_tasks import SupabaseTaskManager
from src.contract_review.supabase_storage import SupabaseStorageManager
from src.contract_review.supabase_business import SupabaseBusinessManager
from src.contract_review.supabase_standards import SupabaseStandardLibraryManager
from src.contract_review.supabase_client import get_supabase_client
from src.contract_review.prompts import (
    build_usage_instruction_messages,
    build_standard_recommendation_messages,
    build_standard_modification_messages,
    build_merge_special_requirements_messages,
    build_collection_recommendation_messages,
    build_collection_usage_instruction_messages,
)
from src.contract_review.prompts_interactive import (
    build_item_chat_messages,
    format_document_structure,
)
from src.contract_review.llm_client import LLMClient
from src.contract_review.fallback_llm import FallbackLLMClient, create_fallback_client
from src.contract_review.quota_service import get_quota_service, QuotaInfo
from src.contract_review.interactive_engine import InteractiveReviewEngine
from src.contract_review.supabase_interactive import get_interactive_manager, InteractiveChat, ChatMessage
from src.contract_review.document_preprocessor import DocumentPreprocessor
from src.contract_review.document_tools import DOCUMENT_TOOLS, DocumentToolExecutor
from src.contract_review.sse_protocol import (
    SSEEventType,
    create_tool_thinking_event,
    create_tool_call_event,
    create_tool_result_event,
    create_tool_error_event,
    create_doc_update_event,
    create_message_delta_event,
    create_done_event,
    create_error_event,
)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
)
logger = logging.getLogger(__name__)

# åŠ è½½é…ç½®
settings = load_settings()

# åˆ›å»º FastAPI åº”ç”¨
app = FastAPI(
    title="æ³•åŠ¡æ–‡æœ¬å®¡é˜…ç³»ç»Ÿ API",
    description="ä½¿ç”¨ LLM ä»æ³•åŠ¡è§’åº¦å®¡é˜…åˆåŒã€è¥é”€ææ–™ç­‰æ–‡æœ¬",
    version="1.0.0",
)

# é…ç½® CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
    expose_headers=["*"],  # å…è®¸å‰ç«¯è®¿é—®è‡ªå®šä¹‰å“åº”å¤´
)


# å…¨å±€å¼‚å¸¸å¤„ç†å™¨ - ç¡®ä¿å¼‚å¸¸å“åº”ä¹ŸåŒ…å« CORS å¤´
from fastapi.responses import JSONResponse
from fastapi.exceptions import RequestValidationError
from starlette.exceptions import HTTPException as StarletteHTTPException
from postgrest.exceptions import APIError as PostgrestAPIError
import ast
import json as json_module


@app.exception_handler(StarletteHTTPException)
async def http_exception_handler(request, exc):
    return JSONResponse(
        status_code=exc.status_code,
        content={"detail": exc.detail},
        headers={
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Methods": "*",
            "Access-Control-Allow-Headers": "*",
        },
    )


@app.exception_handler(RequestValidationError)
async def validation_exception_handler(request, exc):
    """å¤„ç†è¯·æ±‚éªŒè¯é”™è¯¯ï¼Œè¿”å›æ›´å‹å¥½çš„é”™è¯¯ä¿¡æ¯"""
    errors = exc.errors()
    # æå–ç¬¬ä¸€ä¸ªé”™è¯¯çš„è¯¦ç»†ä¿¡æ¯
    if errors:
        first_error = errors[0]
        loc = " -> ".join(str(x) for x in first_error.get("loc", []))
        msg = first_error.get("msg", "éªŒè¯å¤±è´¥")
        detail = f"å‚æ•°éªŒè¯å¤±è´¥ ({loc}): {msg}"
    else:
        detail = "è¯·æ±‚å‚æ•°éªŒè¯å¤±è´¥"

    # è®°å½•è¯¦ç»†çš„éªŒè¯é”™è¯¯ä¿¡æ¯å’Œè¯·æ±‚å†…å®¹
    try:
        body = await request.body()
        body_str = body.decode('utf-8')[:500] if body else "(empty)"
    except Exception:
        body_str = "(unable to read body)"

    logger.warning(f"è¯·æ±‚éªŒè¯å¤±è´¥ [{request.method} {request.url.path}]: {errors}")
    logger.warning(f"è¯·æ±‚ä½“å†…å®¹: {body_str}")
    return JSONResponse(
        status_code=422,
        content={"detail": detail},
        headers={
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Methods": "*",
            "Access-Control-Allow-Headers": "*",
        },
    )


def _extract_supabase_detail_message(details: str) -> Optional[str]:
    if not details:
        return None
    try:
        if details.startswith("b'") or details.startswith('b"'):
            details_bytes = ast.literal_eval(details)
            if isinstance(details_bytes, (bytes, bytearray)):
                details = details_bytes.decode("utf-8", errors="replace")
        payload = json_module.loads(details)
        if isinstance(payload, dict):
            return payload.get("message")
    except Exception:
        return None
    return None


@app.exception_handler(PostgrestAPIError)
async def postgrest_exception_handler(request, exc):
    detail_message = _extract_supabase_detail_message(exc.details or "")
    combined = " ".join(
        text for text in [detail_message, exc.message, exc.hint, exc.details] if text
    )
    if "exceed_storage_size_quota" in combined:
        detail = "Supabase é¡¹ç›®å­˜å‚¨å·²è¶…é™ï¼ŒæœåŠ¡è¢«é™åˆ¶ã€‚è¯·æ¸…ç†å­˜å‚¨æˆ–è”ç³» Supabase æ”¯æŒï¼ˆhttps://supabase.helpï¼‰ã€‚"
        status_code = 503
    else:
        detail = detail_message or exc.message or "Supabase è¯·æ±‚å¤±è´¥"
        status_code = int(exc.code) if exc.code and exc.code.isdigit() else 502
    logger.error(f"Supabase è¯·æ±‚å¤±è´¥: {combined}")
    return JSONResponse(
        status_code=status_code,
        content={"detail": detail},
        headers={
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Methods": "*",
            "Access-Control-Allow-Headers": "*",
        },
    )


@app.exception_handler(Exception)
async def general_exception_handler(request, exc):
    logger.error(f"æœªæ•è·çš„å¼‚å¸¸: {exc}", exc_info=True)
    return JSONResponse(
        status_code=500,
        content={"detail": f"æœåŠ¡å™¨å†…éƒ¨é”™è¯¯: {str(exc)}"},
        headers={
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Methods": "*",
            "Access-Control-Allow-Headers": "*",
        },
    )


# åˆå§‹åŒ–ç®¡ç†å™¨
# æ£€æŸ¥æ˜¯å¦é…ç½®äº† Contract ä¸šåŠ¡æ•°æ®åº“ï¼Œå¦‚æœæ˜¯åˆ™ä½¿ç”¨ Supabase ç‰ˆæœ¬
USE_SUPABASE = bool(os.getenv("CONTRACT_DB_URL") and os.getenv("CONTRACT_DB_KEY"))

if USE_SUPABASE:
    logger.info("ä½¿ç”¨ Supabase å­˜å‚¨åç«¯")
    task_manager = SupabaseTaskManager()
    storage_manager = SupabaseStorageManager()
else:
    logger.info("ä½¿ç”¨æœ¬åœ°æ–‡ä»¶å­˜å‚¨åç«¯")
    task_manager = TaskManager(settings.review.tasks_dir)
    storage_manager = StorageManager(settings.review.tasks_dir)

# ==================== Storage æ¸…ç†ä»»åŠ¡ ====================

_storage_cleanup_task = None


async def _scheduled_storage_cleanup():
    from src.contract_review.storage_cleanup import cleanup_old_files_async, get_retention_days

    while True:
        try:
            now = datetime.utcnow()
            target = now.replace(hour=3, minute=0, second=0, microsecond=0)
            if now >= target:
                target = target + timedelta(days=1)
            wait_seconds = (target - now).total_seconds()
            logger.info(
                f"ğŸ“… ä¸‹æ¬¡ Storage æ¸…ç†ä»»åŠ¡: {target.isoformat()} UTC "
                f"(ç­‰å¾… {wait_seconds/3600:.1f} å°æ—¶)"
            )
            await asyncio.sleep(wait_seconds)
            retention_days = get_retention_days()
            logger.info(f"ğŸ§¹ å¼€å§‹æ‰§è¡Œ Storage æ¸…ç†ä»»åŠ¡ (ä¿ç•™ {retention_days} å¤©)...")
            result = await cleanup_old_files_async(retention_days)
            logger.info(
                f"ğŸ§¹ æ¸…ç†å®Œæˆ: åˆ é™¤ {result['files_deleted']} æ–‡ä»¶, "
                f"å¤±è´¥ {result['files_failed']} æ–‡ä»¶"
            )
        except asyncio.CancelledError:
            logger.info("ğŸ“… Storage æ¸…ç†ä»»åŠ¡å·²å–æ¶ˆ")
            break
        except Exception as exc:
            logger.error(f"ğŸ“… Storage æ¸…ç†ä»»åŠ¡å¼‚å¸¸: {exc}")
            await asyncio.sleep(3600)


@app.on_event("startup")
async def _start_storage_cleanup_task():
    global _storage_cleanup_task
    if USE_SUPABASE:
        _storage_cleanup_task = asyncio.create_task(_scheduled_storage_cleanup())
        logger.info("ğŸ“… Storage æ¸…ç†ä»»åŠ¡å·²å¯åŠ¨ (æ¯æ—¥ 03:00 UTC æ‰§è¡Œ)")


@app.on_event("shutdown")
async def _stop_storage_cleanup_task():
    global _storage_cleanup_task
    if _storage_cleanup_task:
        _storage_cleanup_task.cancel()
        _storage_cleanup_task = None

formatter = ResultFormatter()

# æ ‡å‡†åº“ç›®å½•ï¼ˆæœ¬åœ°æ–‡ä»¶å­˜å‚¨å¤‡é€‰æ–¹æ¡ˆï¼‰
STANDARD_LIBRARY_DIR = Path(settings.review.tasks_dir).parent / "data" / "standard_library"

# æ ‡å‡†åº“ç®¡ç†å™¨å’Œä¸šåŠ¡æ¡çº¿ç®¡ç†å™¨ï¼ˆæ ¹æ®å­˜å‚¨åç«¯é€‰æ‹©ï¼‰
if USE_SUPABASE:
    standard_library_manager = SupabaseStandardLibraryManager()
    business_library_manager = SupabaseBusinessManager()
    logger.info("æ ‡å‡†åº“ä½¿ç”¨ Supabase å­˜å‚¨åç«¯")
else:
    standard_library_manager = StandardLibraryManager(STANDARD_LIBRARY_DIR)
    BUSINESS_LIBRARY_DIR = Path(settings.review.tasks_dir).parent / "data" / "business_library"
    business_library_manager = BusinessLibraryManager(BUSINESS_LIBRARY_DIR)
    logger.info("æ ‡å‡†åº“ä½¿ç”¨æœ¬åœ°æ–‡ä»¶å­˜å‚¨åç«¯")

# LLM å®¢æˆ·ç«¯ï¼ˆå¸¦ fallback æœºåˆ¶ï¼‰
# é»˜è®¤ä½¿ç”¨ DeepSeekï¼Œå¤±è´¥æ—¶è‡ªåŠ¨åˆ‡æ¢åˆ° Gemini
llm_client = create_fallback_client(settings, primary_provider="deepseek")

# OCR æœåŠ¡åˆå§‹åŒ–ï¼ˆç”¨äºå›¾ç‰‡å’Œæ‰«æ PDF è¯†åˆ«ï¼‰
DASHSCOPE_API_KEY = os.getenv("DASHSCOPE_API_KEY", "")
QWEN_OCR_MODEL = os.getenv("QWEN_OCR_MODEL", "qwen-vl-ocr-2025-11-20")

if DASHSCOPE_API_KEY:
    logger.info("OCR æœåŠ¡å·²é…ç½®ï¼ˆé˜¿é‡Œäº‘ DashScopeï¼‰")
    init_ocr_service(api_key=DASHSCOPE_API_KEY, model=QWEN_OCR_MODEL)
else:
    logger.warning("OCR æœåŠ¡æœªé…ç½®ï¼ˆDASHSCOPE_API_KEY æœªè®¾ç½®ï¼‰ï¼Œå›¾ç‰‡å’Œæ‰«æ PDF å°†æ— æ³•å¤„ç†")

# é»˜è®¤æ¨¡æ¿ç›®å½•
TEMPLATES_DIR = settings.review.templates_dir

# ==================== Clerk èº«ä»½éªŒè¯ ====================

# ä»ç¯å¢ƒå˜é‡åŠ è½½ Clerk é…ç½®
CLERK_SECRET_KEY = os.getenv("CLERK_SECRET_KEY", "")
# Clerk JWKS URLï¼ˆç”¨äºéªŒè¯ JWTï¼‰
CLERK_JWKS_URL = None

# HTTP Bearer è®¤è¯
security = HTTPBearer(auto_error=False)

# ç¼“å­˜ JWKS
_jwks_cache = None
_jwks_cache_time = 0
JWKS_CACHE_DURATION = 3600  # 1å°æ—¶


async def get_clerk_jwks():
    """è·å– Clerk çš„ JWKSï¼ˆJSON Web Key Setï¼‰ç”¨äºéªŒè¯ JWT"""
    global _jwks_cache, _jwks_cache_time, CLERK_JWKS_URL

    import time
    current_time = time.time()

    # å¦‚æœç¼“å­˜æœ‰æ•ˆï¼Œç›´æ¥è¿”å›
    if _jwks_cache and (current_time - _jwks_cache_time) < JWKS_CACHE_DURATION:
        return _jwks_cache

    # ä» CLERK_SECRET_KEY æ¨æ–­ JWKS URL
    # Clerk çš„ publishable key æ ¼å¼: pk_test_xxx æˆ– pk_live_xxx
    # å¯¹åº”çš„ JWKS URL: https://{frontend_api}/.well-known/jwks.json
    if not CLERK_JWKS_URL:
        # å°è¯•ä»ç¯å¢ƒå˜é‡è·å– frontend API
        clerk_frontend_api = os.getenv("CLERK_FRONTEND_API", "")
        if clerk_frontend_api:
            CLERK_JWKS_URL = f"https://{clerk_frontend_api}/.well-known/jwks.json"
        else:
            # ä» publishable key ä¸­æå–ï¼ˆbase64 è§£ç ï¼‰
            publishable_key = os.getenv("CLERK_PUBLISHABLE_KEY", os.getenv("VITE_CLERK_PUBLISHABLE_KEY", ""))
            if publishable_key and publishable_key.startswith("pk_"):
                try:
                    import base64
                    # pk_test_xxx æ ¼å¼ï¼Œxxx æ˜¯ base64 ç¼–ç çš„ frontend API
                    encoded_part = publishable_key.split("_")[-1]
                    # æ·»åŠ  padding
                    padding = 4 - len(encoded_part) % 4
                    if padding != 4:
                        encoded_part += "=" * padding
                    frontend_api = base64.b64decode(encoded_part).decode("utf-8").rstrip("$")
                    CLERK_JWKS_URL = f"https://{frontend_api}/.well-known/jwks.json"
                except Exception as e:
                    logger.warning(f"æ— æ³•ä» publishable key è§£æ JWKS URL: {e}")

    if not CLERK_JWKS_URL:
        raise HTTPException(status_code=500, detail="Clerk JWKS URL æœªé…ç½®")

    try:
        async with httpx.AsyncClient() as client:
            response = await client.get(CLERK_JWKS_URL, timeout=10.0)
            response.raise_for_status()
            _jwks_cache = response.json()
            _jwks_cache_time = current_time
            return _jwks_cache
    except Exception as e:
        logger.error(f"è·å– Clerk JWKS å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail="æ— æ³•éªŒè¯èº«ä»½å‡­è¯")


def get_signing_key(jwks: dict, kid: str):
    """ä» JWKS ä¸­è·å–ç­¾åå¯†é’¥"""
    from jwt import algorithms

    for key in jwks.get("keys", []):
        if key.get("kid") == kid:
            return algorithms.RSAAlgorithm.from_jwk(key)

    raise HTTPException(status_code=401, detail="æ— æ³•æ‰¾åˆ°åŒ¹é…çš„ç­¾åå¯†é’¥")


async def get_current_user(
    credentials: HTTPAuthorizationCredentials = Depends(security),
) -> str:
    """
    éªŒè¯ Clerk JWT Token å¹¶è¿”å›ç”¨æˆ· ID

    ä»è¯·æ±‚å¤´ Authorization: Bearer <token> ä¸­æå–å¹¶éªŒè¯ Tokenã€‚
    æˆåŠŸè¿”å› user_idï¼Œå¤±è´¥æŠ›å‡º 401 å¼‚å¸¸ã€‚
    """
    if not credentials:
        raise HTTPException(
            status_code=401,
            detail="Missing authentication credentials",
            headers={"WWW-Authenticate": "Bearer"},
        )

    token = credentials.credentials

    try:
        # å…ˆè§£ç  header è·å– kid
        unverified_header = jwt.get_unverified_header(token)
        kid = unverified_header.get("kid")

        if not kid:
            raise HTTPException(status_code=401, detail="Invalid token header")

        # è·å– JWKS å¹¶æ‰¾åˆ°å¯¹åº”çš„å…¬é’¥
        jwks = await get_clerk_jwks()
        signing_key = get_signing_key(jwks, kid)

        # éªŒè¯å¹¶è§£ç  token
        payload = jwt.decode(
            token,
            signing_key,
            algorithms=["RS256"],
            options={
                "verify_aud": False,  # Clerk ä¸ä½¿ç”¨ audience
                "verify_iss": False,  # issuer éªŒè¯å¯é€‰
            },
        )

        # è·å–ç”¨æˆ· IDï¼ˆClerk ä½¿ç”¨ sub å­—æ®µï¼‰
        user_id = payload.get("sub")
        if not user_id:
            raise HTTPException(status_code=401, detail="Invalid token: missing user ID")

        return user_id

    except jwt.ExpiredSignatureError:
        raise HTTPException(status_code=401, detail="Token has expired")
    except jwt.InvalidTokenError as e:
        logger.warning(f"Token éªŒè¯å¤±è´¥: {e}")
        raise HTTPException(status_code=401, detail="Invalid authentication credentials")
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"èº«ä»½éªŒè¯å¼‚å¸¸: {e}")
        raise HTTPException(status_code=401, detail="Authentication failed")

# å¯åŠ¨æ—¶å°†é¢„è®¾æ¨¡æ¿å¯¼å…¥æ ‡å‡†åº“ï¼ˆå¦‚æœå°šæœªå¯¼å…¥ï¼‰
try:
    imported_count = standard_library_manager.import_preset_templates(TEMPLATES_DIR)
    if imported_count > 0:
        logger.info(f"å·²å°† {imported_count} ä¸ªé¢„è®¾æ¨¡æ¿å¯¼å…¥æ ‡å‡†åº“")
except Exception as e:
    logger.warning(f"å¯¼å…¥é¢„è®¾æ¨¡æ¿å¤±è´¥: {e}")

# å¯åŠ¨æ—¶è¿ç§»æ— å½’å±çš„é£é™©ç‚¹
try:
    migrated_count = standard_library_manager.migrate_orphan_standards()
    if migrated_count > 0:
        logger.info(f"å·²è¿ç§» {migrated_count} æ¡æ— å½’å±é£é™©ç‚¹åˆ°é»˜è®¤é›†åˆ")
except Exception as e:
    logger.warning(f"è¿ç§»æ— å½’å±é£é™©ç‚¹å¤±è´¥: {e}")


# ==================== è¯·æ±‚/å“åº”æ¨¡å‹ ====================

class CreateTaskRequest(BaseModel):
    name: str
    our_party: str
    material_type: MaterialType = "contract"
    language: str = "zh-CN"  # å®¡é˜…è¯­è¨€: "zh-CN" æˆ– "en"


class TaskResponse(BaseModel):
    id: str
    name: str
    our_party: str
    material_type: str
    language: str = "zh-CN"
    status: str
    message: Optional[str] = None
    document_filename: Optional[str] = None
    standard_filename: Optional[str] = None
    created_at: str
    updated_at: str

    @classmethod
    def from_task(cls, task: ReviewTask) -> "TaskResponse":
        return cls(
            id=task.id,
            name=task.name,
            our_party=task.our_party,
            material_type=task.material_type,
            language=getattr(task, 'language', 'zh-CN'),
            status=task.status,
            message=task.message,
            document_filename=task.document_filename,
            standard_filename=task.standard_filename,
            created_at=task.created_at.isoformat(),
            updated_at=task.updated_at.isoformat(),
        )


class TaskStatusResponse(BaseModel):
    status: str
    message: Optional[str] = None
    progress: dict


class UpdateModificationRequest(BaseModel):
    user_confirmed: Optional[bool] = None
    user_modified_text: Optional[str] = None


class UpdateActionRequest(BaseModel):
    user_confirmed: Optional[bool] = None
    description: Optional[str] = None
    action_type: Optional[str] = None
    urgency: Optional[str] = None
    responsible_party: Optional[str] = None
    deadline_suggestion: Optional[str] = None


# ---------- æ ‡å‡†åˆ¶ä½œç›¸å…³æ¨¡å‹ ----------

class StandardCreationRequest(BaseModel):
    """æ ‡å‡†åˆ¶ä½œè¯·æ±‚"""
    document_type: str  # "contract" | "marketing" | "both"
    business_scenario: str  # ä¸šåŠ¡åœºæ™¯æè¿°
    focus_areas: List[str]  # æ ¸å¿ƒå…³æ³¨ç‚¹åˆ—è¡¨
    our_role: Optional[str] = None  # æˆ‘æ–¹è§’è‰²
    industry: Optional[str] = None  # è¡Œä¸šé¢†åŸŸ
    special_risks: Optional[str] = None  # ç‰¹æ®Šé£é™©æç¤º
    reference_material: Optional[str] = None  # å‚è€ƒææ–™æ–‡æœ¬
    language: str = "zh-CN"  # è¯­è¨€: "zh-CN" æˆ– "en"


class GeneratedStandard(BaseModel):
    """ç”Ÿæˆçš„æ ‡å‡†"""
    category: str
    item: str
    description: str
    risk_level: str
    applicable_to: List[str]
    usage_instruction: str


class StandardCreationResponse(BaseModel):
    """æ ‡å‡†åˆ¶ä½œå“åº”"""
    collection_name: str  # AIç”Ÿæˆçš„é›†åˆåç§°
    standards: List[GeneratedStandard]
    generation_summary: str


class TemplateInfo(BaseModel):
    name: str
    filename: str
    description: str


# ---------- æ ‡å‡†åº“ç›¸å…³æ¨¡å‹ ----------

class StandardResponse(BaseModel):
    """æ ‡å‡†å“åº”"""
    id: str
    category: str
    item: str
    description: str
    risk_level: str
    applicable_to: List[str]
    usage_instruction: Optional[str] = None
    tags: List[str] = []
    created_at: Optional[str] = None
    updated_at: Optional[str] = None


class CreateStandardRequest(BaseModel):
    """åˆ›å»ºæ ‡å‡†è¯·æ±‚"""
    category: str
    item: str
    description: str
    risk_level: str = "medium"
    applicable_to: List[str] = ["contract", "marketing"]
    usage_instruction: Optional[str] = None
    tags: List[str] = []


class UpdateStandardRequest(BaseModel):
    """æ›´æ–°æ ‡å‡†è¯·æ±‚"""
    category: Optional[str] = None
    item: Optional[str] = None
    description: Optional[str] = None
    risk_level: Optional[str] = None
    applicable_to: Optional[List[str]] = None
    usage_instruction: Optional[str] = None
    tags: Optional[List[str]] = None


class BatchCreateStandardsRequest(BaseModel):
    """æ‰¹é‡åˆ›å»ºæ ‡å‡†è¯·æ±‚"""
    standards: List[CreateStandardRequest]


class StandardPreviewResponse(BaseModel):
    """æ ‡å‡†é¢„è§ˆå“åº”"""
    standards: List[StandardResponse]
    total_count: int
    parse_warnings: List[str] = []


class SaveToLibraryRequest(BaseModel):
    """ä¿å­˜åˆ°æ ‡å‡†åº“è¯·æ±‚"""
    collection_name: str  # é›†åˆåç§°ï¼ˆå¿…å¡«ï¼‰
    collection_description: str = ""  # é›†åˆæè¿°
    material_type: str = "both"  # ææ–™ç±»å‹
    language: str = "zh-CN"  # è¯­è¨€ ("zh-CN" æˆ– "en")
    standards: List[CreateStandardRequest]


class StandardLibraryStatsResponse(BaseModel):
    """æ ‡å‡†åº“ç»Ÿè®¡ä¿¡æ¯"""
    total: int
    by_category: dict
    by_risk_level: dict
    by_material_type: dict
    updated_at: Optional[str] = None


class GenerateUsageInstructionRequest(BaseModel):
    """ç”Ÿæˆé€‚ç”¨è¯´æ˜è¯·æ±‚"""
    standard_ids: List[str]
    sample_document_text: Optional[str] = None


class UsageInstructionResult(BaseModel):
    """é€‚ç”¨è¯´æ˜ç”Ÿæˆç»“æœ"""
    standard_id: str
    usage_instruction: str


class RecommendStandardsRequest(BaseModel):
    """æ¨èæ ‡å‡†è¯·æ±‚"""
    document_text: str
    material_type: str = "contract"


class StandardRecommendationResponse(BaseModel):
    """æ ‡å‡†æ¨èå“åº”"""
    standard_id: str
    relevance_score: float
    match_reason: str
    standard: StandardResponse


# ---------- æ ‡å‡†é›†åˆæ¨èæ¨¡å‹ ----------

class RecommendCollectionsRequest(BaseModel):
    """æ¨èæ ‡å‡†é›†åˆè¯·æ±‚"""
    document_text: str  # æ–‡æ¡£å†…å®¹ï¼ˆå‰1000å­—ï¼‰
    material_type: str = "contract"


class CollectionRecommendationItem(BaseModel):
    """é›†åˆæ¨èé¡¹"""
    collection_id: str
    collection_name: str
    relevance_score: float  # 0-1
    match_reason: str
    standard_count: int
    usage_instruction: Optional[str] = None


# ==================== ä»»åŠ¡ç®¡ç† API ====================

@app.post("/api/tasks", response_model=TaskResponse)
async def create_task(
    request: CreateTaskRequest,
    user_id: str = Depends(get_current_user),
):
    """åˆ›å»ºå®¡é˜…ä»»åŠ¡ï¼ˆéœ€è¦ç™»å½•ï¼‰"""
    print(f"User {user_id} is creating a new task...")
    if USE_SUPABASE:
        task = task_manager.create_task(
            name=request.name,
            our_party=request.our_party,
            user_id=user_id,
            material_type=request.material_type,
            language=request.language,
        )
    else:
        task = task_manager.create_task(
            name=request.name,
            our_party=request.our_party,
            material_type=request.material_type,
            language=request.language,
        )
    logger.info(f"åˆ›å»ºä»»åŠ¡: {task.id} - {task.name} (language={request.language}) by user {user_id}")
    return TaskResponse.from_task(task)


@app.get("/api/tasks", response_model=List[TaskResponse])
async def list_tasks(
    limit: int = Query(default=100, ge=1, le=500),
    user_id: str = Depends(get_current_user),
):
    """è·å–ä»»åŠ¡åˆ—è¡¨ï¼ˆéœ€è¦ç™»å½•ï¼Œåªè¿”å›å½“å‰ç”¨æˆ·çš„ä»»åŠ¡ï¼‰"""
    if USE_SUPABASE:
        tasks = task_manager.list_tasks(user_id=user_id, limit=limit)
    else:
        tasks = task_manager.list_tasks(limit=limit)
    return [TaskResponse.from_task(t) for t in tasks]


@app.get("/api/tasks/{task_id}", response_model=TaskResponse)
async def get_task(task_id: str):
    """è·å–ä»»åŠ¡è¯¦æƒ…"""
    task = task_manager.get_task(task_id)
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
    return TaskResponse.from_task(task)


@app.delete("/api/tasks/{task_id}")
async def delete_task(
    task_id: str,
    user_id: str = Depends(get_current_user),
):
    """åˆ é™¤ä»»åŠ¡ï¼ˆéœ€è¦ç™»å½•ï¼‰"""
    if USE_SUPABASE:
        success = task_manager.delete_task(task_id, user_id)
    else:
        success = task_manager.delete_task(task_id)
    if not success:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
    return {"message": "åˆ é™¤æˆåŠŸ"}


class TaskUpdateRequest(BaseModel):
    name: Optional[str] = None
    our_party: Optional[str] = None
    material_type: Optional[str] = None
    language: Optional[str] = None


@app.patch("/api/tasks/{task_id}")
async def update_task(
    task_id: str,
    request: TaskUpdateRequest,
    user_id: str = Depends(get_current_user),
):
    """æ›´æ–°ä»»åŠ¡åŸºæœ¬ä¿¡æ¯ï¼ˆéœ€è¦ç™»å½•ï¼‰"""
    task = task_manager.get_task(task_id)
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")

    # éªŒè¯ç”¨æˆ·æƒé™
    if USE_SUPABASE:
        task_owner = task_manager.get_task_user_id(task_id)
        if task_owner != user_id:
            raise HTTPException(status_code=403, detail="æ— æƒè®¿é—®æ­¤ä»»åŠ¡")

    # æ„å»ºæ›´æ–°æ•°æ®
    update_data = {}
    if request.name is not None:
        update_data["name"] = request.name
    if request.our_party is not None:
        update_data["our_party"] = request.our_party
    if request.material_type is not None:
        update_data["material_type"] = request.material_type
    if request.language is not None:
        update_data["language"] = request.language

    if not update_data:
        return TaskResponse.from_task(task)

    # æ›´æ–°ä»»åŠ¡
    if USE_SUPABASE:
        updated_task = task_manager.update_task(task_id, update_data)
    else:
        # æœ¬åœ°æ¨¡å¼ï¼šç›´æ¥æ›´æ–°å†…å­˜ä¸­çš„ä»»åŠ¡
        for key, value in update_data.items():
            setattr(task, key, value)
        updated_task = task

    if not updated_task:
        raise HTTPException(status_code=500, detail="æ›´æ–°å¤±è´¥")

    return TaskResponse.from_task(updated_task)


@app.get("/api/tasks/{task_id}/status", response_model=TaskStatusResponse)
async def get_task_status(task_id: str):
    """è·å–ä»»åŠ¡çŠ¶æ€å’Œè¿›åº¦"""
    task = task_manager.get_task(task_id)
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")

    return TaskStatusResponse(
        status=task.status,
        message=task.message,
        progress={
            "stage": task.progress.stage,
            "percentage": task.progress.percentage,
            "message": task.progress.message,
        },
    )


# ==================== æ–‡ä»¶ä¸Šä¼  API ====================

# æ–‡ä»¶å¤§å°é™åˆ¶ï¼ˆMBï¼‰
MAX_DOCUMENT_SIZE_MB = 10  # å¾…å®¡é˜…æ–‡æ¡£æœ€å¤§ 10MB
MAX_STANDARD_SIZE_MB = 5   # å®¡æ ¸æ ‡å‡†æœ€å¤§ 5MB


@app.post("/api/tasks/{task_id}/document")
async def upload_document(
    task_id: str,
    file: UploadFile = File(...),
    user_id: str = Depends(get_current_user),
):
    """ä¸Šä¼ å¾…å®¡é˜…æ–‡æ¡£ï¼ˆéœ€è¦ç™»å½•ï¼‰"""
    print(f"User {user_id} is uploading document to task {task_id}...")
    task = task_manager.get_task(task_id)
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")

    # æ£€æŸ¥æ–‡ä»¶ç±»å‹
    suffix = Path(file.filename).suffix.lower()
    allowed = {".pdf", ".jpg", ".jpeg", ".png", ".webp", ".docx", ".xlsx", ".md", ".txt"}
    if suffix not in allowed:
        raise HTTPException(
            status_code=400,
            detail=f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹ã€‚æ”¯æŒçš„æ ¼å¼: PDFã€å›¾ç‰‡ã€Wordã€Excelã€Markdown",
        )

    content = await file.read()

    # æ£€æŸ¥æ–‡ä»¶å¤§å°
    file_size_mb = len(content) / (1024 * 1024)
    if file_size_mb > MAX_DOCUMENT_SIZE_MB:
        raise HTTPException(
            status_code=400,
            detail=f"æ–‡ä»¶è¿‡å¤§ï¼ˆ{file_size_mb:.1f}MBï¼‰ã€‚å¾…å®¡é˜…æ–‡æ¡£æœ€å¤§æ”¯æŒ {MAX_DOCUMENT_SIZE_MB}MB",
        )
    if USE_SUPABASE:
        task_manager.save_document(task_id, user_id, file.filename, content)
    else:
        task_manager.save_document(task_id, file.filename, content)

    logger.info(f"ä»»åŠ¡ {task_id} ä¸Šä¼ æ–‡æ¡£: {file.filename}")
    return {"message": "ä¸Šä¼ æˆåŠŸ", "filename": file.filename}


@app.post("/api/tasks/{task_id}/standard")
async def upload_standard(
    task_id: str,
    file: UploadFile = File(...),
    user_id: str = Depends(get_current_user),
):
    """ä¸Šä¼ å®¡æ ¸æ ‡å‡†ï¼ˆéœ€è¦ç™»å½•ï¼‰"""
    print(f"User {user_id} is uploading standard to task {task_id}...")
    task = task_manager.get_task(task_id)
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")

    # æ£€æŸ¥æ–‡ä»¶ç±»å‹
    suffix = Path(file.filename).suffix.lower()
    allowed = {".xlsx", ".xls", ".csv", ".docx", ".md", ".txt"}
    if suffix not in allowed:
        raise HTTPException(
            status_code=400,
            detail=f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹ã€‚æ”¯æŒçš„æ ¼å¼: {', '.join(allowed)}",
        )

    content = await file.read()

    # æ£€æŸ¥æ–‡ä»¶å¤§å°
    file_size_mb = len(content) / (1024 * 1024)
    if file_size_mb > MAX_STANDARD_SIZE_MB:
        raise HTTPException(
            status_code=400,
            detail=f"æ–‡ä»¶è¿‡å¤§ï¼ˆ{file_size_mb:.1f}MBï¼‰ã€‚å®¡æ ¸æ ‡å‡†æ–‡ä»¶æœ€å¤§æ”¯æŒ {MAX_STANDARD_SIZE_MB}MB",
        )

    if USE_SUPABASE:
        task_manager.save_standard(task_id, user_id, file.filename, content)
    else:
        task_manager.save_standard(task_id, file.filename, content)

    logger.info(f"ä»»åŠ¡ {task_id} ä¸Šä¼ å®¡æ ¸æ ‡å‡†: {file.filename}")
    return {"message": "ä¸Šä¼ æˆåŠŸ", "filename": file.filename}


@app.post("/api/tasks/{task_id}/standard/template")
async def use_template(
    task_id: str,
    template_name: str = Query(...),
    user_id: str = Depends(get_current_user),
):
    """ä½¿ç”¨é»˜è®¤æ¨¡æ¿ä½œä¸ºå®¡æ ¸æ ‡å‡†ï¼ˆéœ€è¦ç™»å½•ï¼‰"""
    task = task_manager.get_task(task_id)
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")

    # æŸ¥æ‰¾æ¨¡æ¿
    template_path = TEMPLATES_DIR / f"{template_name}.xlsx"
    if not template_path.exists():
        template_path = TEMPLATES_DIR / f"{template_name}.csv"
    if not template_path.exists():
        raise HTTPException(status_code=404, detail="æ¨¡æ¿ä¸å­˜åœ¨")

    # å¤åˆ¶æ¨¡æ¿åˆ°ä»»åŠ¡ç›®å½•
    content = template_path.read_bytes()
    if USE_SUPABASE:
        task_manager.save_standard(task_id, user_id, template_path.name, content)
    else:
        task_manager.save_standard(task_id, template_path.name, content)

    # æ›´æ–°ä»»åŠ¡
    task.standard_template = template_name
    task_manager.update_task(task)

    return {"message": "æ¨¡æ¿åº”ç”¨æˆåŠŸ", "template": template_name}


# ==================== å®¡é˜…æ‰§è¡Œ API ====================

async def run_review(
    task_id: str,
    user_id: str,
    llm_provider: str = "deepseek",
    business_line_id: Optional[str] = None,
    special_requirements: Optional[str] = None,
):
    """åå°æ‰§è¡Œå®¡é˜…ä»»åŠ¡

    Args:
        task_id: ä»»åŠ¡ ID
        user_id: ç”¨æˆ· IDï¼ˆç”¨äº Supabase å­˜å‚¨è·¯å¾„ï¼‰
        llm_provider: LLM æä¾›è€…ï¼Œå¯é€‰ "deepseek" æˆ– "gemini"
        business_line_id: ä¸šåŠ¡æ¡çº¿ IDï¼ˆå¯é€‰ï¼Œç”¨äºè·å–ä¸šåŠ¡ä¸Šä¸‹æ–‡ï¼‰
        special_requirements: æœ¬æ¬¡ç‰¹æ®Šè¦æ±‚ï¼ˆå¯é€‰ï¼Œç›´æ¥ä¼ é€’ç»™LLMï¼‰
    """
    task = task_manager.get_task(task_id)
    if not task:
        return

    try:
        # æ›´æ–°çŠ¶æ€
        task.update_status("reviewing", "æ­£åœ¨å‡†å¤‡å®¡é˜…...")
        task_manager.update_task(task)

        # è·å–æ–‡æ¡£
        if USE_SUPABASE:
            doc_path = task_manager.get_document_path(task_id, user_id)
        else:
            doc_path = task_manager.get_document_path(task_id)
        if not doc_path:
            raise ValueError("æœªä¸Šä¼ æ–‡æ¡£")

        # è·å–å®¡æ ¸æ ‡å‡†
        if USE_SUPABASE:
            std_path = task_manager.get_standard_path(task_id, user_id)
        else:
            std_path = task_manager.get_standard_path(task_id)
        if not std_path:
            raise ValueError("æœªä¸Šä¼ å®¡æ ¸æ ‡å‡†")

        # åŠ è½½æ–‡æ¡£ï¼ˆä½¿ç”¨å¼‚æ­¥ç‰ˆæœ¬æ”¯æŒ OCRï¼‰
        ocr_service = get_ocr_service()
        suffix = doc_path.suffix.lower()

        # æ£€æŸ¥æ˜¯å¦éœ€è¦ OCR ä½†æœªé…ç½®
        if suffix in {".jpg", ".jpeg", ".png", ".webp"} and not ocr_service:
            raise ValueError("å¤„ç†å›¾ç‰‡æ–‡ä»¶éœ€è¦é…ç½® OCR æœåŠ¡ï¼ˆDASHSCOPE_API_KEYï¼‰")

        document = await load_document_async(doc_path, ocr_service=ocr_service)

        # è§£æå®¡æ ¸æ ‡å‡†
        standard_set = parse_standard_file(std_path)

        # è·å–ä¸šåŠ¡ä¸Šä¸‹æ–‡ï¼ˆå¦‚æœæŒ‡å®šäº†ä¸šåŠ¡æ¡çº¿ï¼‰
        business_context = None
        if business_line_id:
            business_line = business_library_manager.get_business_line(business_line_id)
            if business_line:
                business_context = {
                    "business_line_id": business_line.id,
                    "business_line_name": business_line.name,
                    "name": business_line.name,  # prompts.py ä½¿ç”¨ "name" é”®
                    "industry": business_line.industry,
                    "contexts": business_line.contexts,  # ç›´æ¥ä¼ é€’ BusinessContext å¯¹è±¡åˆ—è¡¨
                }
                logger.info(f"ä½¿ç”¨ä¸šåŠ¡æ¡çº¿: {business_line.name} ({len(business_line.contexts)} æ¡èƒŒæ™¯ä¿¡æ¯)")

        # è¿›åº¦å›è°ƒ
        def progress_callback(stage: str, percentage: int, message: str):
            task.update_progress(stage, percentage, message)
            task_manager.update_task(task)

        # æ‰§è¡Œå®¡é˜…ï¼ˆæ ¹æ® llm_provider é€‰æ‹©æ¨¡å‹ï¼‰
        engine = ReviewEngine(settings, llm_provider=llm_provider)
        result = await engine.review_document(
            document=document,
            standards=standard_set.standards,
            our_party=task.our_party,
            material_type=task.material_type,
            task_id=task_id,
            language=getattr(task, 'language', 'zh-CN'),
            progress_callback=progress_callback,
            business_context=business_context,
            special_requirements=special_requirements,
        )

        # ä¿å­˜ç»“æœ
        if USE_SUPABASE:
            storage_manager.save_result(result)
        else:
            task_dir = settings.review.tasks_dir / task_id
            storage_manager.save_result(result, task_dir)

        # æ›´æ–°ä»»åŠ¡
        task.result = result
        task.update_status("completed", "å®¡é˜…å®Œæˆ")
        task_manager.update_task(task)

        # å®¡é˜…æˆåŠŸå®Œæˆåæ‰£é™¤é…é¢
        try:
            quota_service = get_quota_service()
            await quota_service.deduct_quota(user_id, task_id=task_id)
            logger.info(f"ä»»åŠ¡ {task_id} é…é¢æ‰£é™¤æˆåŠŸ")
        except Exception as quota_error:
            logger.error(f"ä»»åŠ¡ {task_id} é…é¢æ‰£é™¤å¤±è´¥: {quota_error}")

        logger.info(f"ä»»åŠ¡ {task_id} å®¡é˜…å®Œæˆï¼Œå‘ç° {len(result.risks)} ä¸ªé£é™©ç‚¹")

    except Exception as e:
        logger.error(f"ä»»åŠ¡ {task_id} å®¡é˜…å¤±è´¥: {e}")
        task.update_status("failed", str(e))
        task_manager.update_task(task)


@app.post("/api/tasks/{task_id}/review")
async def start_review(
    task_id: str,
    background_tasks: BackgroundTasks,
    llm_provider: str = Query(default="deepseek", regex="^(deepseek|gemini)$"),
    business_line_id: Optional[str] = Query(default=None, description="ä¸šåŠ¡æ¡çº¿IDï¼ˆå¯é€‰ï¼‰"),
    special_requirements: Optional[str] = Query(default=None, description="æœ¬æ¬¡ç‰¹æ®Šè¦æ±‚ï¼ˆå¯é€‰ï¼Œä¼˜å…ˆçº§æœ€é«˜ï¼‰"),
    user_id: str = Depends(get_current_user),
):
    """å¼€å§‹å®¡é˜…ï¼ˆéœ€è¦ç™»å½•ï¼‰

    Args:
        task_id: ä»»åŠ¡ ID
        llm_provider: LLM æä¾›è€…ï¼Œå¯é€‰ "deepseek"ï¼ˆåˆçº§ï¼‰æˆ– "gemini"ï¼ˆé«˜çº§ï¼‰
        business_line_id: ä¸šåŠ¡æ¡çº¿ IDï¼ˆå¯é€‰ï¼Œç”¨äºæä¾›ä¸šåŠ¡ä¸Šä¸‹æ–‡ï¼‰
        special_requirements: æœ¬æ¬¡ç‰¹æ®Šè¦æ±‚ï¼ˆå¯é€‰ï¼Œç›´æ¥ä¼ é€’ç»™LLMï¼Œä¼˜å…ˆçº§æœ€é«˜ï¼‰
    """
    print(f"User {user_id} is starting review for task {task_id}...")

    # æ£€æŸ¥é…é¢ï¼ˆåœ¨æ‰§è¡Œä»»ä½•æ“ä½œä¹‹å‰ï¼‰
    quota_service = get_quota_service()
    await quota_service.check_quota(user_id)

    task = task_manager.get_task(task_id)
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")

    if task.status == "reviewing":
        raise HTTPException(status_code=400, detail="ä»»åŠ¡æ­£åœ¨å®¡é˜…ä¸­")

    # æ£€æŸ¥æ–‡ä»¶
    if not task.document_filename:
        raise HTTPException(status_code=400, detail="è¯·å…ˆä¸Šä¼ å¾…å®¡é˜…æ–‡æ¡£")
    if not task.standard_filename:
        raise HTTPException(status_code=400, detail="è¯·å…ˆä¸Šä¼ å®¡æ ¸æ ‡å‡†")

    # å¦‚æœé€‰æ‹© Geminiï¼Œæ£€æŸ¥ API Key æ˜¯å¦é…ç½®
    if llm_provider == "gemini" and not settings.gemini.api_key:
        raise HTTPException(status_code=400, detail="é«˜çº§æ™ºèƒ½æ¨¡å¼æœªé…ç½®ï¼Œè¯·è”ç³»ç®¡ç†å‘˜")

    # éªŒè¯ä¸šåŠ¡æ¡çº¿ï¼ˆå¦‚æœæä¾›äº†ï¼‰
    if business_line_id:
        business_line = business_library_manager.get_business_line(business_line_id)
        if not business_line:
            raise HTTPException(status_code=400, detail="æŒ‡å®šçš„ä¸šåŠ¡æ¡çº¿ä¸å­˜åœ¨")
        logger.info(f"ä»»åŠ¡ {task_id} å°†ä½¿ç”¨ä¸šåŠ¡æ¡çº¿: {business_line.name}")

    # å¯åŠ¨åå°ä»»åŠ¡ï¼Œä¼ é€’å‚æ•°
    background_tasks.add_task(run_review, task_id, user_id, llm_provider, business_line_id, special_requirements)

    task.update_status("reviewing", "å®¡é˜…ä»»åŠ¡å·²å¯åŠ¨")
    task.update_progress("analyzing", 0, "æ­£åœ¨å¯åŠ¨...")
    task_manager.update_task(task)

    return {"message": "å®¡é˜…ä»»åŠ¡å·²å¯åŠ¨"}


# ==================== é…é¢ç®¡ç† API ====================

class QuotaResponse(BaseModel):
    """é…é¢ä¿¡æ¯å“åº”"""
    user_id: str
    product_id: str
    plan_tier: str
    credits_balance: int
    total_usage: int
    billing_enabled: bool


@app.get("/api/quota", response_model=QuotaResponse)
async def get_quota(user_id: str = Depends(get_current_user)):
    """è·å–å½“å‰ç”¨æˆ·çš„é…é¢ä¿¡æ¯"""
    quota_service = get_quota_service()
    quota = await quota_service.get_or_create_quota(user_id)

    return QuotaResponse(
        user_id=quota.user_id,
        product_id=quota.product_id,
        plan_tier=quota.plan_tier,
        credits_balance=quota.credits_balance,
        total_usage=quota.total_usage,
        billing_enabled=quota_service.is_enabled(),
    )


# ==================== è¯­è¨€æ£€æµ‹ API ====================

class LanguageDetectionRequest(BaseModel):
    text: str


class LanguageDetectionResponse(BaseModel):
    detected_language: str
    confidence: float


@app.post("/api/detect-language", response_model=LanguageDetectionResponse)
async def detect_language(request: LanguageDetectionRequest):
    """æ£€æµ‹æ–‡æ¡£è¯­è¨€ï¼ˆåŸºäºä¸­æ–‡å­—ç¬¦æ¯”ä¾‹ï¼‰"""
    text = request.text[:5000]  # åªæ£€æµ‹å‰5000å­—ç¬¦

    # ç»Ÿè®¡ä¸­æ–‡å­—ç¬¦æ•°é‡
    chinese_chars = sum(1 for c in text if '\u4e00' <= c <= '\u9fff')
    # ç»Ÿè®¡éç©ºç™½å­—ç¬¦æ€»æ•°
    total_chars = len([c for c in text if c.strip()])

    if total_chars == 0:
        return LanguageDetectionResponse(
            detected_language="zh-CN",
            confidence=0.5
        )

    chinese_ratio = chinese_chars / total_chars

    # é˜ˆå€¼ï¼š15%ä»¥ä¸Šä¸­æ–‡å­—ç¬¦åˆ¤å®šä¸ºä¸­æ–‡
    if chinese_ratio > 0.15:
        return LanguageDetectionResponse(
            detected_language="zh-CN",
            confidence=min(chinese_ratio * 2, 0.95)
        )
    else:
        return LanguageDetectionResponse(
            detected_language="en",
            confidence=min((1 - chinese_ratio), 0.95)
        )


# ==================== æ–‡æ¡£é¢„å¤„ç† API ====================

class PartyInfo(BaseModel):
    role: str  # ç”²æ–¹ã€ä¹™æ–¹ã€å‡ºç§Ÿäººç­‰
    name: str  # å…·ä½“åç§°
    description: str = ""  # è§’è‰²æè¿°


class PreprocessRequest(BaseModel):
    task_id: str


class PreprocessResponse(BaseModel):
    parties: List[PartyInfo]
    suggested_name: str
    language: str
    document_type: str = ""
    document_preview: str = ""  # æ–‡æ¡£å¼€å¤´å†…å®¹é¢„è§ˆï¼Œæ–¹ä¾¿ç”¨æˆ·åˆ¤æ–­èº«ä»½


@app.post("/api/tasks/{task_id}/preprocess", response_model=PreprocessResponse)
async def preprocess_document(
    task_id: str,
    user_id: str = Depends(get_current_user),
):
    """
    é¢„å¤„ç†æ–‡æ¡£ï¼Œè¯†åˆ«åˆåŒå„æ–¹å’Œæ–‡æ¡£ç±»å‹

    ç”¨äºç®€åŒ–ç”¨æˆ·æ“ä½œï¼šä¸Šä¼ æ–‡æ¡£åè‡ªåŠ¨è¯†åˆ«å„æ–¹ï¼Œè®©ç”¨æˆ·é€‰æ‹©è€Œéæ‰‹åŠ¨è¾“å…¥
    """
    task_manager = SupabaseTaskManager()
    storage_manager = SupabaseStorageManager()

    # è·å–ä»»åŠ¡
    task = task_manager.get_task(task_id)
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")

    # éªŒè¯ç”¨æˆ·æƒé™
    task_owner = task_manager.get_task_user_id(task_id)
    if task_owner != user_id:
        raise HTTPException(status_code=403, detail="æ— æƒè®¿é—®æ­¤ä»»åŠ¡")

    # æ£€æŸ¥æ˜¯å¦æœ‰æ–‡æ¡£
    if not task.document_filename:
        raise HTTPException(status_code=400, detail="è¯·å…ˆä¸Šä¼ æ–‡æ¡£")

    # è¯»å–æ–‡æ¡£å†…å®¹
    try:
        # è·å–æ–‡æ¡£è·¯å¾„ï¼ˆä¼šè‡ªåŠ¨ä» Supabase Storage ä¸‹è½½åˆ°æœ¬åœ°ä¸´æ—¶ç›®å½•ï¼‰
        if USE_SUPABASE:
            doc_path = task_manager.get_document_path(task_id, user_id)
        else:
            doc_path = task_manager.get_document_path(task_id)

        if not doc_path or not doc_path.exists():
            raise HTTPException(status_code=400, detail="æ–‡æ¡£æ–‡ä»¶ä¸å­˜åœ¨")

        # è¯»å–æ–‡æ¡£å†…å®¹
        document = await load_document_async(doc_path, ocr_service=get_ocr_service())
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è¯»å–æ–‡æ¡£å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è¯»å–æ–‡æ¡£å¤±è´¥: {str(e)}")

    # æ‰§è¡Œé¢„å¤„ç†
    try:
        preprocessor = DocumentPreprocessor(settings)
        result = await preprocessor.preprocess(document.text)

        # æå–æ–‡æ¡£å¼€å¤´å†…å®¹ä½œä¸ºé¢„è§ˆï¼ˆå‰1500å­—ç¬¦ï¼‰
        document_preview = document.text[:1500].strip()
        if len(document.text) > 1500:
            document_preview += "\n\n..."

        return PreprocessResponse(
            parties=[PartyInfo(**p) for p in result.get("parties", [])],
            suggested_name=result.get("suggested_name", "æœªå‘½åæ–‡æ¡£"),
            language=result.get("language", "zh-CN"),
            document_type=result.get("document_type", ""),
            document_preview=document_preview,
        )
    except Exception as e:
        logger.error(f"æ–‡æ¡£é¢„å¤„ç†å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æ–‡æ¡£é¢„å¤„ç†å¤±è´¥: {str(e)}")


# ==================== ç»“æœç®¡ç† API ====================

@app.get("/api/tasks/{task_id}/result")
async def get_result(task_id: str):
    """è·å–å®¡é˜…ç»“æœ"""
    task = task_manager.get_task(task_id)
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")

    if USE_SUPABASE:
        result = storage_manager.load_result(task_id)
    else:
        task_dir = settings.review.tasks_dir / task_id
        result = storage_manager.load_result(task_dir)

    if not result:
        raise HTTPException(status_code=404, detail="æš‚æ— å®¡é˜…ç»“æœ")

    return result.model_dump(mode="json")


@app.patch("/api/tasks/{task_id}/result/modifications/{modification_id}")
async def update_modification(
    task_id: str,
    modification_id: str,
    request: UpdateModificationRequest,
):
    """æ›´æ–°ä¿®æ”¹å»ºè®®ï¼ˆç”¨æˆ·ç¡®è®¤æˆ–ä¿®æ”¹æ–‡æœ¬ï¼‰"""
    task = task_manager.get_task(task_id)
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")

    if USE_SUPABASE:
        result = storage_manager.load_result(task_id)
    else:
        task_dir = settings.review.tasks_dir / task_id
        result = storage_manager.load_result(task_dir)

    if not result:
        raise HTTPException(status_code=404, detail="æš‚æ— å®¡é˜…ç»“æœ")

    # æŸ¥æ‰¾å¹¶æ›´æ–°ä¿®æ”¹å»ºè®®
    found = False
    for mod in result.modifications:
        if mod.id == modification_id:
            if request.user_confirmed is not None:
                mod.user_confirmed = request.user_confirmed
            if request.user_modified_text is not None:
                mod.user_modified_text = request.user_modified_text
            found = True
            break

    if not found:
        raise HTTPException(status_code=404, detail="ä¿®æ”¹å»ºè®®ä¸å­˜åœ¨")

    # ä¿å­˜æ›´æ–°
    if USE_SUPABASE:
        storage_manager.update_result(task_id, result)
    else:
        storage_manager.update_result(task_dir, result)

    return {"message": "æ›´æ–°æˆåŠŸ"}


@app.patch("/api/tasks/{task_id}/result/actions/{action_id}")
async def update_action(
    task_id: str,
    action_id: str,
    request: UpdateActionRequest = None,
    user_confirmed: Optional[bool] = Query(None)  # ä¿æŒå‘åå…¼å®¹
):
    """æ›´æ–°è¡ŒåŠ¨å»ºè®®ï¼ˆæ”¯æŒç¼–è¾‘æ‰€æœ‰å­—æ®µï¼‰"""
    task = task_manager.get_task(task_id)
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")

    if USE_SUPABASE:
        result = storage_manager.load_result(task_id)
    else:
        task_dir = settings.review.tasks_dir / task_id
        result = storage_manager.load_result(task_dir)

    if not result:
        raise HTTPException(status_code=404, detail="æš‚æ— å®¡é˜…ç»“æœ")

    # æŸ¥æ‰¾å¹¶æ›´æ–°è¡ŒåŠ¨å»ºè®®
    found = False
    for action in result.actions:
        if action.id == action_id:
            # æ”¯æŒæ—§çš„queryå‚æ•°æ–¹å¼ï¼ˆå‘åå…¼å®¹ï¼‰
            if user_confirmed is not None:
                action.user_confirmed = user_confirmed
            # æ”¯æŒæ–°çš„bodyæ–¹å¼
            if request:
                if request.user_confirmed is not None:
                    action.user_confirmed = request.user_confirmed
                if request.description is not None:
                    action.description = request.description
                if request.action_type is not None:
                    action.action_type = request.action_type
                if request.urgency is not None:
                    action.urgency = request.urgency
                if request.responsible_party is not None:
                    action.responsible_party = request.responsible_party
                if request.deadline_suggestion is not None:
                    action.deadline_suggestion = request.deadline_suggestion
            found = True
            break

    if not found:
        raise HTTPException(status_code=404, detail="è¡ŒåŠ¨å»ºè®®ä¸å­˜åœ¨")

    # ä¿å­˜æ›´æ–°
    if USE_SUPABASE:
        storage_manager.update_result(task_id, result)
    else:
        storage_manager.update_result(task_dir, result)

    return {"message": "æ›´æ–°æˆåŠŸ"}


# ==================== å¯¼å‡º API ====================

@app.get("/api/tasks/{task_id}/export/json")
async def export_json(task_id: str):
    """å¯¼å‡º JSON"""
    if USE_SUPABASE:
        json_content = storage_manager.export_to_json(task_id)
    else:
        task_dir = settings.review.tasks_dir / task_id
        json_content = storage_manager.export_to_json(task_dir)

    if not json_content:
        raise HTTPException(status_code=404, detail="æš‚æ— å®¡é˜…ç»“æœ")

    return Response(
        content=json_content,
        media_type="application/json",
        headers={
            "Content-Disposition": f'attachment; filename="review_result_{task_id}.json"'
        },
    )


@app.get("/api/tasks/{task_id}/export/excel")
async def export_excel(task_id: str):
    """å¯¼å‡º Excel"""
    if USE_SUPABASE:
        excel_content = storage_manager.export_to_excel(task_id)
    else:
        task_dir = settings.review.tasks_dir / task_id
        excel_content = storage_manager.export_to_excel(task_dir)

    if not excel_content:
        raise HTTPException(status_code=404, detail="æš‚æ— å®¡é˜…ç»“æœ")

    return Response(
        content=excel_content,
        media_type="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        headers={
            "Content-Disposition": f'attachment; filename="review_result_{task_id}.xlsx"'
        },
    )


@app.get("/api/tasks/{task_id}/export/csv")
async def export_csv(task_id: str):
    """å¯¼å‡º CSV"""
    if USE_SUPABASE:
        csv_content = storage_manager.export_to_csv(task_id)
    else:
        task_dir = settings.review.tasks_dir / task_id
        csv_content = storage_manager.export_to_csv(task_dir)

    if not csv_content:
        raise HTTPException(status_code=404, detail="æš‚æ— å®¡é˜…ç»“æœ")

    return Response(
        content=csv_content,
        media_type="text/csv",
        headers={
            "Content-Disposition": f'attachment; filename="review_result_{task_id}.csv"'
        },
    )


@app.get("/api/tasks/{task_id}/export/report")
async def export_report(task_id: str):
    """å¯¼å‡º Markdown æ‘˜è¦æŠ¥å‘Š"""
    if USE_SUPABASE:
        result = storage_manager.load_result(task_id)
    else:
        task_dir = settings.review.tasks_dir / task_id
        result = storage_manager.load_result(task_dir)

    if not result:
        raise HTTPException(status_code=404, detail="æš‚æ— å®¡é˜…ç»“æœ")

    report = generate_summary_report(result)

    return Response(
        content=report,
        media_type="text/markdown",
        headers={
            "Content-Disposition": f'attachment; filename="review_report_{task_id}.md"'
        },
    )


class ExportRedlineRequest(BaseModel):
    """å¯¼å‡º Redline æ–‡æ¡£è¯·æ±‚"""
    modification_ids: Optional[List[str]] = None  # è¦åº”ç”¨çš„ä¿®æ”¹ IDï¼Œç©ºåˆ™ä½¿ç”¨å·²ç¡®è®¤çš„
    include_comments: bool = False  # æ˜¯å¦å°†è¡ŒåŠ¨å»ºè®®ä½œä¸ºæ‰¹æ³¨æ·»åŠ 


# ==================== Redline å¼‚æ­¥å¯¼å‡ºç›¸å…³ ====================

from dataclasses import dataclass
from typing import Dict
from datetime import datetime, timedelta
import threading

@dataclass
class RedlineExportJob:
    """Redline å¯¼å‡ºä»»åŠ¡"""
    task_id: str
    user_id: str
    status: str  # pending, processing, completed, failed
    progress: int  # 0-100
    message: str
    document_bytes: Optional[bytes] = None
    filename: Optional[str] = None
    created_at: datetime = None
    completed_at: datetime = None
    error: Optional[str] = None
    # ç»Ÿè®¡ä¿¡æ¯
    applied_count: int = 0
    skipped_count: int = 0
    comments_added: int = 0
    comments_skipped: int = 0
    # æ¨¡æ‹Ÿè¿›åº¦ç›¸å…³
    estimated_total_seconds: int = 180  # é¢„è®¡æ€»æ—¶é•¿ï¼ˆé»˜è®¤3åˆ†é’Ÿï¼‰
    processing_started_at: Optional[datetime] = None  # å¼€å§‹å¤„ç†æ—¶é—´

# å†…å­˜ç¼“å­˜å­˜å‚¨å¯¼å‡ºä»»åŠ¡ï¼ˆé”®: task_idï¼‰
_redline_export_jobs: Dict[str, RedlineExportJob] = {}
_redline_jobs_lock = threading.Lock()

def _cleanup_old_jobs():
    """æ¸…ç†è¶…è¿‡1å°æ—¶çš„å¯¼å‡ºä»»åŠ¡"""
    with _redline_jobs_lock:
        now = datetime.now()
        expired_keys = [
            k for k, v in _redline_export_jobs.items()
            if v.created_at and (now - v.created_at) > timedelta(hours=1)
        ]
        for k in expired_keys:
            del _redline_export_jobs[k]


async def _update_simulated_progress(job: RedlineExportJob):
    """
    æ¨¡æ‹Ÿè¿›åº¦æ›´æ–°
    åœ¨å®é™…å¤„ç†æœŸé—´ï¼ˆ30%â†’89%ï¼‰ï¼Œæ ¹æ®é¢„ä¼°æ—¶é—´çº¿æ€§å¢åŠ è¿›åº¦
    """
    import asyncio

    if not job.processing_started_at:
        return

    while job.status == "processing" and job.progress < 90:
        elapsed = (datetime.now() - job.processing_started_at).total_seconds()
        # é¢„ä¼°æ—¶é—´çš„80%ç”¨äº30%â†’90%çš„è¿›åº¦ï¼ˆ60%è¿›åº¦èŒƒå›´ï¼‰
        estimated_processing_time = job.estimated_total_seconds * 0.8

        if elapsed < estimated_processing_time:
            # çº¿æ€§è¿›åº¦ï¼š30% + (elapsed / estimated_processing_time) * 59%
            simulated_progress = 30 + int((elapsed / estimated_processing_time) * 59)
            # ç¡®ä¿ä¸è¶…è¿‡89%ï¼Œç•™ç»™çœŸæ­£å®Œæˆæ—¶çš„90%
            job.progress = min(simulated_progress, 89)

            # æ›´æ–°æ¶ˆæ¯ï¼Œæ˜¾ç¤ºé¢„è®¡å‰©ä½™æ—¶é—´
            remaining = max(0, estimated_processing_time - elapsed)
            if remaining > 60:
                job.message = f"æ­£åœ¨åº”ç”¨ä¿®æ”¹... é¢„è®¡è¿˜éœ€ {int(remaining / 60)} åˆ†é’Ÿ"
            elif remaining > 10:
                job.message = f"æ­£åœ¨åº”ç”¨ä¿®æ”¹... é¢„è®¡è¿˜éœ€ {int(remaining)} ç§’"
            else:
                job.message = "æ­£åœ¨åº”ç”¨ä¿®æ”¹... å³å°†å®Œæˆ"

        await asyncio.sleep(2)  # æ¯2ç§’æ›´æ–°ä¸€æ¬¡


async def _persist_redline_to_storage(job: RedlineExportJob):
    """
    å°†ç”Ÿæˆçš„ Redline æ–‡ä»¶æŒä¹…åŒ–åˆ° Supabase Storage
    """
    if not USE_SUPABASE or not job.document_bytes:
        logger.info("è·³è¿‡ Redline æŒä¹…åŒ–ï¼šæœªå¯ç”¨ Supabase æˆ–æ— æ–‡ä»¶å†…å®¹")
        return

    try:
        from uuid import uuid4
        from src.contract_review.supabase_client import get_supabase_client, get_storage_bucket

        # ç”Ÿæˆå®‰å…¨çš„å­˜å‚¨æ–‡ä»¶å
        safe_filename = f"{uuid4().hex}.docx"
        storage_path = f"{job.user_id}/{job.task_id}/redlines/{safe_filename}"

        supabase = get_supabase_client()
        bucket = get_storage_bucket()

        # åˆ é™¤ä¹‹å‰çš„ redline æ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        try:
            existing = supabase.storage.from_(bucket).list(f"{job.user_id}/{job.task_id}/redlines")
            if existing:
                old_paths = [f"{job.user_id}/{job.task_id}/redlines/{f['name']}" for f in existing]
                if old_paths:
                    supabase.storage.from_(bucket).remove(old_paths)
        except Exception as e:
            logger.warning(f"æ¸…ç†æ—§ Redline æ–‡ä»¶æ—¶å‡ºé”™: {e}")

        # ä¸Šä¼ æ–°æ–‡ä»¶
        supabase.storage.from_(bucket).upload(
            storage_path,
            job.document_bytes,
            file_options={
                "content-type": "application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                "upsert": "true"
            }
        )

        # æ›´æ–° tasks è¡¨
        supabase.table("tasks").update({
            "redline_filename": job.filename,
            "redline_storage_name": safe_filename,
            "redline_generated_at": datetime.now().isoformat(),
            "redline_applied_count": job.applied_count,
            "redline_comments_count": job.comments_added,
        }).eq("id", job.task_id).execute()

        logger.info(f"Redline æ–‡ä»¶å·²æŒä¹…åŒ–: {storage_path}")

    except Exception as e:
        logger.error(f"Redline æŒä¹…åŒ–å¤±è´¥: {e}", exc_info=True)
        # ä¸æŠ›å‡ºå¼‚å¸¸ï¼Œå…è®¸å¯¼å‡ºç»§ç»­å®Œæˆ


async def _run_redline_export(
    job: RedlineExportJob,
    doc_path: Path,
    result: ReviewResult,
    request: Optional[ExportRedlineRequest],
):
    """åå°æ‰§è¡Œ Redline å¯¼å‡º"""
    import asyncio
    import concurrent.futures

    try:
        job.status = "processing"
        job.progress = 10
        job.message = "æ­£åœ¨å‡†å¤‡æ–‡æ¡£..."

        # ç­›é€‰è¦åº”ç”¨çš„ä¿®æ”¹
        if request and request.modification_ids:
            modifications = [
                m for m in result.modifications
                if m.id in request.modification_ids
            ]
            filter_confirmed = False
        else:
            modifications = result.modifications
            filter_confirmed = True

        include_comments = request.include_comments if request else False

        job.progress = 30
        job.message = "æ­£åœ¨åº”ç”¨ä¿®æ”¹... é¢„è®¡éœ€è¦ 2-3 åˆ†é’Ÿ"
        job.processing_started_at = datetime.now()

        # å¯åŠ¨æ¨¡æ‹Ÿè¿›åº¦æ›´æ–°ä»»åŠ¡
        progress_task = asyncio.create_task(_update_simulated_progress(job))

        # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡ŒåŒæ­¥é˜»å¡æ“ä½œ
        loop = asyncio.get_event_loop()
        with concurrent.futures.ThreadPoolExecutor() as executor:
            redline_result = await loop.run_in_executor(
                executor,
                lambda: generate_redline_document(
                    docx_path=doc_path,
                    modifications=modifications,
                    author="åè¡ŒåŠ©ç†",
                    filter_confirmed=filter_confirmed,
                    actions=result.actions if include_comments else None,
                    risks=result.risks if include_comments else None,
                    include_comments=include_comments,
                )
            )

        # å–æ¶ˆè¿›åº¦æ›´æ–°ä»»åŠ¡
        progress_task.cancel()
        try:
            await progress_task
        except asyncio.CancelledError:
            pass

        job.progress = 90
        job.message = "æ­£åœ¨å®Œæˆå¯¼å‡º..."

        if not redline_result.success:
            error_msg = "; ".join(redline_result.skipped_reasons[:3])
            job.status = "failed"
            job.error = f"ç”Ÿæˆå¤±è´¥: {error_msg}"
            job.message = job.error
            return

        # ç”Ÿæˆæ–‡ä»¶å
        original_name = doc_path.stem
        filename = f"{original_name}_redline.docx"

        # ä¿å­˜ç»“æœ
        job.document_bytes = redline_result.document_bytes
        job.filename = filename
        job.applied_count = redline_result.applied_count
        job.skipped_count = redline_result.skipped_count
        job.comments_added = redline_result.comments_added
        job.comments_skipped = redline_result.comments_skipped

        # æŒä¹…åŒ–åˆ° Supabase Storage
        await _persist_redline_to_storage(job)

        job.status = "completed"
        job.progress = 100
        job.message = "å¯¼å‡ºå®Œæˆ"
        job.completed_at = datetime.now()

        logger.info(
            f"ä»»åŠ¡ {job.task_id} Redline å¯¼å‡ºå®Œæˆ: åº”ç”¨ {redline_result.applied_count} æ¡ä¿®æ”¹ï¼Œ"
            f"æ·»åŠ  {redline_result.comments_added} æ¡æ‰¹æ³¨"
        )

    except Exception as e:
        logger.error(f"Redline å¯¼å‡ºå¤±è´¥: {e}", exc_info=True)
        job.status = "failed"
        job.error = str(e)
        job.message = f"å¯¼å‡ºå¤±è´¥: {str(e)}"


@app.post("/api/tasks/{task_id}/export/redline/start")
async def start_redline_export(
    task_id: str,
    background_tasks: BackgroundTasks,
    request: ExportRedlineRequest = None,
    user_id: str = Depends(get_current_user),
):
    """
    å¯åŠ¨åå° Redline å¯¼å‡ºä»»åŠ¡ï¼ˆéœ€è¦ç™»å½•ï¼‰

    è¿”å›ä»»åŠ¡çŠ¶æ€ï¼Œå‰ç«¯å¯ä»¥è½®è¯¢ /status ç«¯ç‚¹æŸ¥è¯¢è¿›åº¦ã€‚
    """
    # æ¸…ç†è¿‡æœŸä»»åŠ¡
    _cleanup_old_jobs()

    # æ£€æŸ¥æ˜¯å¦å·²æœ‰è¿›è¡Œä¸­çš„ä»»åŠ¡
    with _redline_jobs_lock:
        existing_job = _redline_export_jobs.get(task_id)
        if existing_job and existing_job.status in ("pending", "processing"):
            return {
                "job_id": task_id,
                "status": existing_job.status,
                "progress": existing_job.progress,
                "message": existing_job.message,
            }

    task = task_manager.get_task(task_id)
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")

    # æ£€æŸ¥åŸå§‹æ–‡æ¡£
    if USE_SUPABASE:
        doc_path = task_manager.get_document_path(task_id, user_id)
    else:
        doc_path = task_manager.get_document_path(task_id)
    if not doc_path:
        raise HTTPException(status_code=400, detail="æœªæ‰¾åˆ°åŸå§‹æ–‡æ¡£")

    if doc_path.suffix.lower() != '.docx':
        raise HTTPException(
            status_code=400,
            detail=f"Redline å¯¼å‡ºåªæ”¯æŒ .docx æ ¼å¼ï¼Œå½“å‰æ–‡æ¡£æ ¼å¼ä¸º {doc_path.suffix}"
        )

    # è·å–å®¡é˜…ç»“æœ
    if USE_SUPABASE:
        result = storage_manager.load_result(task_id)
    else:
        task_dir = settings.review.tasks_dir / task_id
        result = storage_manager.load_result(task_dir)

    if not result:
        raise HTTPException(status_code=404, detail="æš‚æ— å®¡é˜…ç»“æœ")

    # æ£€æŸ¥æ˜¯å¦æœ‰å†…å®¹å¯å¯¼å‡º
    if request and request.modification_ids:
        confirmed_count = len(request.modification_ids)
    else:
        confirmed_count = sum(1 for m in result.modifications if m.user_confirmed)

    include_comments = request.include_comments if request else False
    has_actions = bool(result.actions) if include_comments else False

    if confirmed_count == 0 and not has_actions:
        raise HTTPException(status_code=400, detail="æ²¡æœ‰å·²ç¡®è®¤çš„ä¿®æ”¹å»ºè®®æˆ–è¡ŒåŠ¨å»ºè®®")

    # åˆ›å»ºå¯¼å‡ºä»»åŠ¡
    job = RedlineExportJob(
        task_id=task_id,
        user_id=user_id,
        status="pending",
        progress=0,
        message="æ­£åœ¨æ’é˜Ÿ...",
        created_at=datetime.now(),
    )

    with _redline_jobs_lock:
        _redline_export_jobs[task_id] = job

    # å¯åŠ¨åå°ä»»åŠ¡
    background_tasks.add_task(_run_redline_export, job, doc_path, result, request)

    return {
        "job_id": task_id,
        "status": "pending",
        "progress": 0,
        "message": "å¯¼å‡ºä»»åŠ¡å·²å¯åŠ¨",
    }


@app.get("/api/tasks/{task_id}/export/redline/status")
async def get_redline_export_status(
    task_id: str,
    user_id: str = Depends(get_current_user),
):
    """
    æŸ¥è¯¢ Redline å¯¼å‡ºä»»åŠ¡çŠ¶æ€ï¼ˆéœ€è¦ç™»å½•ï¼‰
    """
    with _redline_jobs_lock:
        job = _redline_export_jobs.get(task_id)

    if not job:
        return {
            "job_id": task_id,
            "status": "not_found",
            "progress": 0,
            "message": "æ²¡æœ‰æ‰¾åˆ°å¯¼å‡ºä»»åŠ¡",
        }

    response = {
        "job_id": task_id,
        "status": job.status,
        "progress": job.progress,
        "message": job.message,
    }

    if job.status == "completed":
        response["applied_count"] = job.applied_count
        response["skipped_count"] = job.skipped_count
        response["comments_added"] = job.comments_added
        response["comments_skipped"] = job.comments_skipped
        response["filename"] = job.filename
    elif job.status == "failed":
        response["error"] = job.error

    return response


@app.get("/api/tasks/{task_id}/export/redline/download")
async def download_redline_export(
    task_id: str,
    user_id: str = Depends(get_current_user),
):
    """
    ä¸‹è½½å·²å®Œæˆçš„ Redline å¯¼å‡ºæ–‡ä»¶ï¼ˆéœ€è¦ç™»å½•ï¼‰
    """
    with _redline_jobs_lock:
        job = _redline_export_jobs.get(task_id)

    if not job:
        raise HTTPException(status_code=404, detail="æ²¡æœ‰æ‰¾åˆ°å¯¼å‡ºä»»åŠ¡")

    if job.status != "completed":
        raise HTTPException(status_code=400, detail=f"å¯¼å‡ºä»»åŠ¡æœªå®Œæˆï¼Œå½“å‰çŠ¶æ€: {job.status}")

    if not job.document_bytes:
        raise HTTPException(status_code=500, detail="å¯¼å‡ºæ–‡ä»¶ä¸¢å¤±")

    # URL ç¼–ç æ–‡ä»¶åä»¥æ”¯æŒä¸­æ–‡
    from urllib.parse import quote
    filename_encoded = quote(job.filename or "redline.docx")
    content_disposition = f"attachment; filename*=UTF-8''{filename_encoded}"

    return Response(
        content=job.document_bytes,
        media_type="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
        headers={
            "Content-Disposition": content_disposition,
            "X-Redline-Applied": str(job.applied_count),
            "X-Redline-Skipped": str(job.skipped_count),
            "X-Comments-Added": str(job.comments_added),
            "X-Comments-Skipped": str(job.comments_skipped),
        },
    )


# ==================== æŒä¹…åŒ– Redline æ–‡ä»¶ API ====================

@app.get("/api/tasks/{task_id}/redline/info")
async def get_redline_info(
    task_id: str,
    user_id: str = Depends(get_current_user),
):
    """
    è·å–ä»»åŠ¡çš„ Redline æ–‡ä»¶ä¿¡æ¯ï¼ˆå¦‚æœå·²ç”Ÿæˆå¹¶æŒä¹…åŒ–ï¼‰
    """
    if not USE_SUPABASE:
        return {"exists": False, "message": "æŒä¹…åŒ–å­˜å‚¨æœªå¯ç”¨"}

    task = task_manager.get_task(task_id)
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")

    # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦æœ‰æŒä¹…åŒ–çš„ redline æ–‡ä»¶
    if not task.redline_storage_name:
        return {"exists": False}

    return {
        "exists": True,
        "filename": task.redline_filename,
        "generated_at": task.redline_generated_at.isoformat() if task.redline_generated_at else None,
        "applied_count": task.redline_applied_count,
        "comments_count": task.redline_comments_count,
    }


@app.get("/api/tasks/{task_id}/redline/download-persisted")
async def download_persisted_redline(
    task_id: str,
    user_id: str = Depends(get_current_user),
):
    """
    ä¸‹è½½å·²æŒä¹…åŒ–çš„ Redline æ–‡ä»¶
    """
    if not USE_SUPABASE:
        raise HTTPException(status_code=400, detail="æŒä¹…åŒ–å­˜å‚¨æœªå¯ç”¨")

    task = task_manager.get_task(task_id)
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")

    if not task.redline_storage_name:
        raise HTTPException(status_code=404, detail="æ²¡æœ‰æ‰¾åˆ°å·²ç”Ÿæˆçš„ Redline æ–‡ä»¶")

    try:
        from src.contract_review.supabase_client import get_supabase_client, get_storage_bucket

        supabase = get_supabase_client()
        bucket = get_storage_bucket()
        storage_path = f"{user_id}/{task_id}/redlines/{task.redline_storage_name}"

        file_bytes = supabase.storage.from_(bucket).download(storage_path)

        from urllib.parse import quote
        filename_encoded = quote(task.redline_filename or "redline.docx")
        content_disposition = f"attachment; filename*=UTF-8''{filename_encoded}"

        return Response(
            content=file_bytes,
            media_type="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
            headers={
                "Content-Disposition": content_disposition,
                "X-Redline-Applied": str(task.redline_applied_count or 0),
                "X-Comments-Added": str(task.redline_comments_count or 0),
            },
        )
    except Exception as e:
        logger.error(f"ä¸‹è½½ Redline æ–‡ä»¶å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="ä¸‹è½½å¤±è´¥")


# ==================== åŸåŒæ­¥å¯¼å‡º APIï¼ˆä¿ç•™å…¼å®¹æ€§ï¼‰====================

@app.post("/api/tasks/{task_id}/export/redline")
async def export_redline(
    task_id: str,
    request: ExportRedlineRequest = None,
    user_id: str = Depends(get_current_user),
):
    """
    å¯¼å‡ºå¸¦ä¿®è®¢æ ‡è®°çš„ Word æ–‡æ¡£ï¼ˆéœ€è¦ç™»å½•ï¼‰

    å°†ç”¨æˆ·ç¡®è®¤çš„ä¿®æ”¹å»ºè®®ä»¥ Track Changes å½¢å¼åº”ç”¨åˆ°åŸå§‹æ–‡æ¡£ã€‚
    å¯é€‰æ‹©å°†è¡ŒåŠ¨å»ºè®®ä½œä¸ºæ‰¹æ³¨æ·»åŠ åˆ°å¯¹åº”é£é™©ç‚¹ä½ç½®ã€‚
    åªæ”¯æŒ .docx æ ¼å¼çš„åŸå§‹æ–‡æ¡£ã€‚
    """
    task = task_manager.get_task(task_id)
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")

    # æ£€æŸ¥åŸå§‹æ–‡æ¡£
    if USE_SUPABASE:
        doc_path = task_manager.get_document_path(task_id, user_id)
    else:
        doc_path = task_manager.get_document_path(task_id)
    if not doc_path:
        raise HTTPException(status_code=400, detail="æœªæ‰¾åˆ°åŸå§‹æ–‡æ¡£")

    if doc_path.suffix.lower() != '.docx':
        raise HTTPException(
            status_code=400,
            detail=f"Redline å¯¼å‡ºåªæ”¯æŒ .docx æ ¼å¼ï¼Œå½“å‰æ–‡æ¡£æ ¼å¼ä¸º {doc_path.suffix}"
        )

    # è·å–å®¡é˜…ç»“æœ
    if USE_SUPABASE:
        result = storage_manager.load_result(task_id)
    else:
        task_dir = settings.review.tasks_dir / task_id
        result = storage_manager.load_result(task_dir)

    if not result:
        raise HTTPException(status_code=404, detail="æš‚æ— å®¡é˜…ç»“æœ")

    # ç­›é€‰è¦åº”ç”¨çš„ä¿®æ”¹
    if request and request.modification_ids:
        # ä½¿ç”¨æŒ‡å®šçš„ä¿®æ”¹ ID
        modifications = [
            m for m in result.modifications
            if m.id in request.modification_ids
        ]
        filter_confirmed = False
    else:
        # ä½¿ç”¨å·²ç¡®è®¤çš„ä¿®æ”¹
        modifications = result.modifications
        filter_confirmed = True

    # æ˜¯å¦åŒ…å«æ‰¹æ³¨
    include_comments = request.include_comments if request else False

    # æ£€æŸ¥æ˜¯å¦æœ‰å†…å®¹å¯å¯¼å‡º
    confirmed_mods = [m for m in modifications if m.user_confirmed] if filter_confirmed else modifications
    has_actions = bool(result.actions) if include_comments else False

    if not confirmed_mods and not has_actions:
        raise HTTPException(status_code=400, detail="æ²¡æœ‰å·²ç¡®è®¤çš„ä¿®æ”¹å»ºè®®æˆ–è¡ŒåŠ¨å»ºè®®")

    # ç”Ÿæˆ Redline æ–‡æ¡£
    try:
        redline_result = generate_redline_document(
            docx_path=doc_path,
            modifications=modifications,
            author="åè¡ŒåŠ©ç†",
            filter_confirmed=filter_confirmed,
            actions=result.actions if include_comments else None,
            risks=result.risks if include_comments else None,
            include_comments=include_comments,
        )
    except Exception as e:
        logger.error(f"ç”Ÿæˆ Redline æ–‡æ¡£æ—¶å‘ç”Ÿå¼‚å¸¸: {e}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail=f"ç”Ÿæˆ Redline æ–‡æ¡£æ—¶å‘ç”Ÿå†…éƒ¨é”™è¯¯: {str(e)}"
        )

    if not redline_result.success:
        error_msg = "; ".join(redline_result.skipped_reasons[:3])
        raise HTTPException(
            status_code=400,
            detail=f"ç”Ÿæˆ Redline æ–‡æ¡£å¤±è´¥: {error_msg}"
        )

    # ç”Ÿæˆæ–‡ä»¶åï¼ˆå¤„ç†ä¸­æ–‡æ–‡ä»¶åï¼‰
    original_name = doc_path.stem
    filename = f"{original_name}_redline.docx"

    # URL ç¼–ç æ–‡ä»¶åä»¥æ”¯æŒä¸­æ–‡ï¼ˆRFC 5987ï¼‰
    from urllib.parse import quote
    filename_encoded = quote(filename)
    # ä½¿ç”¨ filename* å‚æ•°æ”¯æŒ UTF-8 ç¼–ç çš„æ–‡ä»¶å
    content_disposition = f"attachment; filename*=UTF-8''{filename_encoded}"

    logger.info(
        f"ä»»åŠ¡ {task_id} å¯¼å‡º Redline: åº”ç”¨ {redline_result.applied_count} æ¡ä¿®æ”¹ï¼Œ"
        f"æ·»åŠ  {redline_result.comments_added} æ¡æ‰¹æ³¨ï¼Œ"
        f"è·³è¿‡ {redline_result.skipped_count + redline_result.comments_skipped} æ¡"
    )

    # æ„å»ºå“åº”å¤´
    response_headers = {
        "Content-Disposition": content_disposition,
        "X-Redline-Applied": str(redline_result.applied_count),
        "X-Redline-Skipped": str(redline_result.skipped_count),
        "X-Comments-Added": str(redline_result.comments_added),
        "X-Comments-Skipped": str(redline_result.comments_skipped),
    }

    # æ·»åŠ è·³è¿‡åŸå› æ‘˜è¦ï¼ˆæœ€å¤š3æ¡ï¼Œæ–¹ä¾¿å‰ç«¯æ˜¾ç¤ºï¼‰
    if redline_result.skipped_reasons:
        # ç®€åŒ–åŸå› æè¿°ï¼Œåªä¿ç•™å…³é”®ä¿¡æ¯
        brief_reasons = []
        for reason in redline_result.skipped_reasons[:3]:
            # æˆªå–å…³é”®éƒ¨åˆ†
            if len(reason) > 80:
                reason = reason[:77] + "..."
            brief_reasons.append(reason)
        response_headers["X-Redline-Skipped-Reasons"] = "; ".join(brief_reasons)

    return Response(
        content=redline_result.document_bytes,
        media_type="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
        headers=response_headers,
    )


@app.get("/api/tasks/{task_id}/export/redline/preview")
async def preview_redline(
    task_id: str,
    user_id: str = Depends(get_current_user),
):
    """
    é¢„è§ˆ Redline å¯¼å‡ºä¿¡æ¯ï¼ˆéœ€è¦ç™»å½•ï¼‰

    è¿”å›å¯ä»¥å¯¼å‡ºçš„ä¿®æ”¹å»ºè®®æ•°é‡ã€è¡ŒåŠ¨å»ºè®®æ•°é‡å’ŒçŠ¶æ€ã€‚
    """
    task = task_manager.get_task(task_id)
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")

    # æ£€æŸ¥åŸå§‹æ–‡æ¡£æ ¼å¼
    if USE_SUPABASE:
        doc_path = task_manager.get_document_path(task_id, user_id)
    else:
        doc_path = task_manager.get_document_path(task_id)
    can_export = doc_path and doc_path.suffix.lower() == '.docx'

    # è·å–å®¡é˜…ç»“æœ
    if USE_SUPABASE:
        result = storage_manager.load_result(task_id)
    else:
        task_dir = settings.review.tasks_dir / task_id
        result = storage_manager.load_result(task_dir)

    if not result:
        return {
            "can_export": False,
            "reason": "æš‚æ— å®¡é˜…ç»“æœ",
            "total_modifications": 0,
            "confirmed_modifications": 0,
            "total_actions": 0,
        }

    confirmed_count = sum(1 for m in result.modifications if m.user_confirmed)
    actions_count = len(result.actions) if result.actions else 0
    confirmed_actions_count = sum(1 for a in result.actions if a.user_confirmed) if result.actions else 0

    # æ£€æŸ¥æœ‰å¤šå°‘å·²ç¡®è®¤çš„è¡ŒåŠ¨å»ºè®®å¯ä»¥ä½œä¸ºæ‰¹æ³¨ï¼ˆæœ‰å…³è”é£é™©ç‚¹ä¸”é£é™©ç‚¹æœ‰åŸæ–‡ï¼‰
    commentable_actions = 0
    if result.actions and result.risks:
        risk_map = {r.id: r for r in result.risks}
        for action in result.actions:
            # åªç»Ÿè®¡ç”¨æˆ·å·²ç¡®è®¤çš„è¡ŒåŠ¨å»ºè®®
            if not action.user_confirmed:
                continue
            for risk_id in action.related_risk_ids:
                risk = risk_map.get(risk_id)
                if risk and risk.location and risk.location.original_text:
                    commentable_actions += 1
                    break

    return {
        "can_export": can_export and (confirmed_count > 0 or commentable_actions > 0),
        "reason": None if can_export else "åŸå§‹æ–‡æ¡£ä¸æ˜¯ .docx æ ¼å¼",
        "total_modifications": len(result.modifications),
        "confirmed_modifications": confirmed_count,
        "total_actions": actions_count,
        "confirmed_actions": confirmed_actions_count,
        "commentable_actions": commentable_actions,
        "document_format": doc_path.suffix.lower() if doc_path else None,
    }


# ==================== æ¨¡æ¿ API ====================

@app.get("/api/templates", response_model=List[TemplateInfo])
async def list_templates():
    """è·å–å¯ç”¨çš„å®¡æ ¸æ ‡å‡†æ¨¡æ¿åˆ—è¡¨"""
    templates = []

    if TEMPLATES_DIR.exists():
        for f in TEMPLATES_DIR.iterdir():
            if f.suffix.lower() in {".xlsx", ".csv"}:
                # ä»æ–‡ä»¶åæ¨æ–­æè¿°
                name = f.stem
                if "contract" in name.lower() or "åˆåŒ" in name:
                    desc = "é€šç”¨åˆåŒå®¡æ ¸æ ‡å‡†æ¨¡æ¿"
                elif "marketing" in name.lower() or "è¥é”€" in name:
                    desc = "è¥é”€ææ–™åˆè§„æ£€æŸ¥æ ‡å‡†æ¨¡æ¿"
                else:
                    desc = "å®¡æ ¸æ ‡å‡†æ¨¡æ¿"

                templates.append(TemplateInfo(
                    name=name,
                    filename=f.name,
                    description=desc,
                ))

    return templates


@app.get("/api/templates/{template_name}")
async def download_template(template_name: str):
    """ä¸‹è½½æ¨¡æ¿æ–‡ä»¶"""
    template_path = TEMPLATES_DIR / f"{template_name}.xlsx"
    if not template_path.exists():
        template_path = TEMPLATES_DIR / f"{template_name}.csv"
    if not template_path.exists():
        raise HTTPException(status_code=404, detail="æ¨¡æ¿ä¸å­˜åœ¨")

    return FileResponse(
        template_path,
        filename=template_path.name,
        media_type="application/octet-stream",
    )


# ==================== æ ‡å‡†åº“ç®¡ç† API ====================

def _standard_to_response(s: ReviewStandard) -> StandardResponse:
    """å°† ReviewStandard è½¬æ¢ä¸º StandardResponse"""
    return StandardResponse(
        id=s.id,
        category=s.category,
        item=s.item,
        description=s.description,
        risk_level=s.risk_level,
        applicable_to=list(s.applicable_to),
        usage_instruction=s.usage_instruction,
        tags=list(s.tags),
        created_at=s.created_at.isoformat() if s.created_at else None,
        updated_at=s.updated_at.isoformat() if s.updated_at else None,
    )


@app.get("/api/standard-library", response_model=StandardLibraryStatsResponse)
async def get_standard_library_stats():
    """è·å–æ ‡å‡†åº“ç»Ÿè®¡ä¿¡æ¯"""
    stats = standard_library_manager.get_stats()
    return StandardLibraryStatsResponse(**stats)


@app.get("/api/standard-library/standards", response_model=List[StandardResponse])
async def list_library_standards(
    category: Optional[str] = Query(default=None, description="æŒ‰åˆ†ç±»ç­›é€‰"),
    material_type: Optional[str] = Query(default=None, description="æŒ‰ææ–™ç±»å‹ç­›é€‰"),
    keyword: Optional[str] = Query(default=None, description="æœç´¢å…³é”®è¯"),
):
    """è·å–æ ‡å‡†åº“ä¸­çš„æ‰€æœ‰æ ‡å‡†"""
    standards = standard_library_manager.list_standards(
        category=category,
        material_type=material_type,
        keyword=keyword,
    )
    return [_standard_to_response(s) for s in standards]


@app.post("/api/standard-library/standards", response_model=StandardResponse)
async def create_library_standard(request: CreateStandardRequest):
    """æ·»åŠ å•æ¡æ ‡å‡†åˆ°æ ‡å‡†åº“"""
    standard = ReviewStandard(
        category=request.category,
        item=request.item,
        description=request.description,
        risk_level=request.risk_level,
        applicable_to=request.applicable_to,
        usage_instruction=request.usage_instruction,
        tags=request.tags,
    )
    standard_id = standard_library_manager.add_standard(standard)

    # é‡æ–°è·å–ä»¥è¿”å›å®Œæ•´ä¿¡æ¯
    created = standard_library_manager.get_standard(standard_id)
    logger.info(f"åˆ›å»ºæ ‡å‡†: {standard_id} - {request.item}")
    return _standard_to_response(created)


@app.post("/api/standard-library/standards/batch")
async def batch_create_library_standards(request: BatchCreateStandardsRequest):
    """æ‰¹é‡æ·»åŠ æ ‡å‡†åˆ°æ ‡å‡†åº“"""
    standards = []
    for req in request.standards:
        standard = ReviewStandard(
            category=req.category,
            item=req.item,
            description=req.description,
            risk_level=req.risk_level,
            applicable_to=req.applicable_to,
            usage_instruction=req.usage_instruction,
            tags=req.tags,
        )
        standards.append(standard)

    ids = standard_library_manager.add_standards_batch(standards)
    logger.info(f"æ‰¹é‡åˆ›å»º {len(ids)} æ¡æ ‡å‡†")
    return {"message": f"æˆåŠŸæ·»åŠ  {len(ids)} æ¡æ ‡å‡†", "ids": ids}


@app.get("/api/standard-library/standards/{standard_id}", response_model=StandardResponse)
async def get_library_standard(
    standard_id: str,
    user_id: str = Depends(get_current_user),
):
    """è·å–å•æ¡æ ‡å‡†è¯¦æƒ…ï¼ˆéœ€è¦ç™»å½•ï¼‰"""
    standard = standard_library_manager.get_standard(standard_id)
    _check_standard_access(standard, user_id, require_ownership=False)
    return _standard_to_response(standard)


@app.put("/api/standard-library/standards/{standard_id}", response_model=StandardResponse)
async def update_library_standard(
    standard_id: str,
    request: UpdateStandardRequest,
    user_id: str = Depends(get_current_user),
):
    """æ›´æ–°æ ‡å‡†ï¼ˆéœ€è¦ç™»å½•ï¼Œåªèƒ½æ›´æ–°è‡ªå·±é›†åˆå†…çš„æ ‡å‡†ï¼‰"""
    standard = standard_library_manager.get_standard(standard_id)
    _check_standard_access(standard, user_id, require_ownership=True)

    updates = {k: v for k, v in request.model_dump().items() if v is not None}

    success = standard_library_manager.update_standard(standard_id, updates)
    if not success:
        raise HTTPException(status_code=404, detail="æ ‡å‡†ä¸å­˜åœ¨")

    updated = standard_library_manager.get_standard(standard_id)
    logger.info(f"æ›´æ–°æ ‡å‡†: {standard_id}")
    return _standard_to_response(updated)


@app.delete("/api/standard-library/standards/{standard_id}")
async def delete_library_standard(
    standard_id: str,
    user_id: str = Depends(get_current_user),
):
    """åˆ é™¤æ ‡å‡†ï¼ˆéœ€è¦ç™»å½•ï¼Œåªèƒ½åˆ é™¤è‡ªå·±é›†åˆå†…çš„æ ‡å‡†ï¼‰"""
    standard = standard_library_manager.get_standard(standard_id)
    _check_standard_access(standard, user_id, require_ownership=True)

    success = standard_library_manager.delete_standard(standard_id)
    if not success:
        raise HTTPException(status_code=404, detail="æ ‡å‡†ä¸å­˜åœ¨")

    logger.info(f"åˆ é™¤æ ‡å‡†: {standard_id}")
    return {"message": "åˆ é™¤æˆåŠŸ"}


@app.get("/api/standard-library/categories")
async def get_library_categories():
    """è·å–æ‰€æœ‰åˆ†ç±»"""
    categories = standard_library_manager.get_categories()
    return {"categories": categories}


@app.get("/api/standard-library/export")
async def export_library(format: str = Query(default="csv", regex="^(csv|json)$")):
    """å¯¼å‡ºæ ‡å‡†åº“"""
    if format == "csv":
        content = standard_library_manager.export_to_csv()
        media_type = "text/csv"
        filename = "standard_library.csv"
    else:
        content = standard_library_manager.export_to_json()
        media_type = "application/json"
        filename = "standard_library.json"

    return Response(
        content=content,
        media_type=media_type,
        headers={"Content-Disposition": f'attachment; filename="{filename}"'},
    )


@app.post("/api/standard-library/import")
async def import_to_library(
    file: UploadFile = File(...),
    replace: bool = Query(default=False, description="æ˜¯å¦æ›¿æ¢ç°æœ‰åº“"),
):
    """ä»æ–‡ä»¶å¯¼å…¥æ ‡å‡†åˆ°æ ‡å‡†åº“"""
    import tempfile

    # æ£€æŸ¥æ–‡ä»¶ç±»å‹
    suffix = Path(file.filename).suffix.lower()
    allowed = {".xlsx", ".xls", ".csv", ".docx", ".md", ".txt"}
    if suffix not in allowed:
        raise HTTPException(
            status_code=400,
            detail=f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹ã€‚æ”¯æŒçš„æ ¼å¼: {', '.join(allowed)}",
        )

    # ä¿å­˜ä¸´æ—¶æ–‡ä»¶å¹¶è§£æ
    content = await file.read()
    with tempfile.NamedTemporaryFile(suffix=suffix, delete=False) as tmp:
        tmp.write(content)
        tmp_path = Path(tmp.name)

    try:
        # è§£ææ ‡å‡†æ–‡ä»¶
        standard_set = parse_standard_file(tmp_path)

        # å¯¼å…¥åˆ°æ ‡å‡†åº“
        imported_count, warnings = standard_library_manager.import_from_parsed_standards(
            standard_set.standards,
            replace=replace,
        )

        logger.info(f"å¯¼å…¥æ ‡å‡†: {imported_count} æ¡ï¼Œæ¥è‡ª {file.filename}")

        return {
            "message": f"æˆåŠŸå¯¼å…¥ {imported_count} æ¡æ ‡å‡†",
            "imported_count": imported_count,
            "warnings": warnings,
        }
    finally:
        tmp_path.unlink()


# ==================== æ ‡å‡†é›†åˆ API ====================

class CollectionResponse(BaseModel):
    """æ ‡å‡†é›†åˆå“åº”"""
    id: str
    name: str
    description: str
    usage_instruction: Optional[str] = None
    material_type: str
    is_preset: bool
    language: str = "zh-CN"
    standard_count: int
    standards: Optional[List[StandardResponse]] = None


class CollectionWithStandardsResponse(BaseModel):
    """æ ‡å‡†é›†åˆï¼ˆåŒ…å«æ ‡å‡†åˆ—è¡¨ï¼‰å“åº”"""
    id: str
    name: str
    description: str
    material_type: str
    is_preset: bool
    language: str = "zh-CN"
    standard_count: int
    standards: List[StandardResponse]


def _collection_to_response(collection, standards: list = None) -> CollectionResponse:
    """å°†é›†åˆè½¬æ¢ä¸ºå“åº”æ ¼å¼"""
    # é€šè¿‡ collection_id å…³è”è®¡ç®—æ ‡å‡†æ•°é‡
    library = standard_library_manager._load_library()
    standard_count = len([s for s in library.standards if s.collection_id == collection.id])

    response = CollectionResponse(
        id=collection.id,
        name=collection.name,
        description=collection.description,
        usage_instruction=getattr(collection, 'usage_instruction', None),
        material_type=collection.material_type,
        is_preset=collection.is_preset,
        language=getattr(collection, 'language', 'zh-CN'),
        standard_count=standard_count,
        standards=None,
    )
    if standards:
        response.standards = [_standard_to_response(s) for s in standards]
    return response


def _check_collection_access(collection, user_id: str, require_ownership: bool = False):
    """
    æ£€æŸ¥ç”¨æˆ·æ˜¯å¦æœ‰æƒé™è®¿é—®é›†åˆ

    Args:
        collection: é›†åˆå¯¹è±¡
        user_id: å½“å‰ç”¨æˆ· ID
        require_ownership: æ˜¯å¦è¦æ±‚æ‰€æœ‰æƒï¼ˆç”¨äºä¿®æ”¹/åˆ é™¤æ“ä½œï¼‰

    Raises:
        HTTPException: å¦‚æœæ— æƒé™è®¿é—®
    """
    if collection is None:
        raise HTTPException(status_code=404, detail="é›†åˆä¸å­˜åœ¨")

    # é¢„è®¾é›†åˆæ‰€æœ‰äººå¯è¯»ï¼Œä½†ä¸å¯ä¿®æ”¹
    if collection.is_preset:
        if require_ownership:
            raise HTTPException(status_code=403, detail="ç³»ç»Ÿé¢„è®¾é›†åˆä¸å¯ä¿®æ”¹")
        return  # å…è®¸è¯»å–

    # ç”¨æˆ·åªèƒ½è®¿é—®è‡ªå·±çš„é›†åˆ
    if collection.user_id != user_id:
        raise HTTPException(status_code=403, detail="æ— æƒè®¿é—®æ­¤é›†åˆ")


def _check_standard_access(standard, user_id: str, require_ownership: bool = False):
    """
    æ£€æŸ¥ç”¨æˆ·æ˜¯å¦æœ‰æƒé™è®¿é—®æ ‡å‡†

    é€šè¿‡æ ‡å‡†æ‰€å±çš„é›†åˆæ¥åˆ¤æ–­æƒé™

    Args:
        standard: æ ‡å‡†å¯¹è±¡
        user_id: å½“å‰ç”¨æˆ· ID
        require_ownership: æ˜¯å¦è¦æ±‚æ‰€æœ‰æƒï¼ˆç”¨äºä¿®æ”¹/åˆ é™¤æ“ä½œï¼‰

    Raises:
        HTTPException: å¦‚æœæ— æƒé™è®¿é—®
    """
    if standard is None:
        raise HTTPException(status_code=404, detail="æ ‡å‡†ä¸å­˜åœ¨")

    # å¦‚æœæ ‡å‡†å±äºæŸä¸ªé›†åˆï¼Œæ£€æŸ¥é›†åˆæƒé™
    if standard.collection_id:
        collection = standard_library_manager.get_collection(standard.collection_id)
        if collection:
            _check_collection_access(collection, user_id, require_ownership)
            return

    # æ— å½’å±æ ‡å‡†ï¼šåªè¯»è®¿é—®å…è®¸ï¼Œä¿®æ”¹éœ€è¦ç®¡ç†å‘˜æƒé™ï¼ˆæš‚æ—¶ç¦æ­¢ï¼‰
    if require_ownership:
        raise HTTPException(status_code=403, detail="æ— æ³•ä¿®æ”¹æ— å½’å±çš„æ ‡å‡†")


@app.get("/api/standard-library/collections", response_model=List[CollectionResponse])
async def list_collections(
    material_type: Optional[str] = None,
    language: Optional[str] = Query(default=None, description="æŒ‰è¯­è¨€ç­›é€‰ (zh-CN æˆ– en)"),
    user_id: str = Depends(get_current_user),
):
    """è·å–æ ‡å‡†é›†åˆåˆ—è¡¨ï¼ˆéœ€è¦ç™»å½•ï¼‰

    è¿”å›ç³»ç»Ÿé¢„è®¾é›†åˆ + ç”¨æˆ·è‡ªå·±åˆ›å»ºçš„é›†åˆ
    """
    collections = standard_library_manager.list_collections(
        user_id=user_id,
        language=language,
        include_preset=True,
    )

    # æŒ‰ææ–™ç±»å‹ç­›é€‰
    if material_type:
        collections = [c for c in collections if c.material_type == material_type or c.material_type == "both"]

    return [_collection_to_response(c) for c in collections]


@app.post("/api/standard-library/collections/recommend", response_model=List[CollectionRecommendationItem])
async def recommend_collections(
    request: RecommendCollectionsRequest,
    user_id: str = Depends(get_current_user),
):
    """
    æ ¹æ®æ–‡æ¡£å†…å®¹æ¨èæ ‡å‡†é›†åˆï¼ˆä½¿ç”¨ LLMï¼Œéœ€è¦ç™»å½•ï¼‰

    åˆ†ææ–‡æ¡£å†…å®¹ï¼Œæ ¹æ®å„é›†åˆçš„ usage_instruction æ¨èæœ€é€‚åˆçš„å®¡æ ¸æ ‡å‡†é›†åˆã€‚
    åªæ¨èé¢„è®¾é›†åˆå’Œç”¨æˆ·è‡ªå·±çš„é›†åˆã€‚
    """
    import json
    import re

    # è·å–ç”¨æˆ·å¯è®¿é—®çš„é›†åˆï¼ˆé¢„è®¾ + è‡ªå·±çš„ï¼‰
    collections = standard_library_manager.list_collections(
        user_id=user_id,
        include_preset=True,
    )

    # æŒ‰ææ–™ç±»å‹ç­›é€‰
    if request.material_type:
        collections = [
            c for c in collections
            if c.material_type == request.material_type or c.material_type == "both"
        ]

    if not collections:
        return []

    # å‡†å¤‡é›†åˆæ•°æ®ä¾› LLM åˆ†æ
    collections_for_llm = []
    for c in collections:
        # è®¡ç®—æ ‡å‡†æ•°é‡
        library = standard_library_manager._load_library()
        standard_count = len([s for s in library.standards if s.collection_id == c.id])

        collections_for_llm.append({
            "id": c.id,
            "name": c.name,
            "description": c.description,
            "usage_instruction": getattr(c, 'usage_instruction', None),
            "standard_count": standard_count,
        })

    try:
        # æ„å»º Prompt
        messages = build_collection_recommendation_messages(
            document_text=request.document_text[:1000],
            material_type=request.material_type,
            collections=collections_for_llm,
        )

        # è°ƒç”¨ LLM
        response = await llm_client.chat(messages, max_output_tokens=1000)

        # è§£æ JSON å“åº”
        response = response.strip()
        # ç§»é™¤å¯èƒ½çš„ markdown ä»£ç å—
        response = re.sub(r"```json\s*", "", response)
        response = re.sub(r"```\s*$", "", response)

        # å°è¯•æ‰¾åˆ° JSON æ•°ç»„
        start = response.find("[")
        end = response.rfind("]")
        if start != -1 and end != -1:
            response = response[start:end + 1]

        recommendations = json.loads(response)

        # æ„å»ºå“åº”
        results = []
        collection_map = {c.id: c for c in collections}
        collection_count_map = {c["id"]: c["standard_count"] for c in collections_for_llm}

        for rec in recommendations:
            collection_id = rec.get("collection_id")
            collection = collection_map.get(collection_id)
            if collection:
                results.append(CollectionRecommendationItem(
                    collection_id=collection_id,
                    collection_name=collection.name,
                    relevance_score=float(rec.get("relevance_score", 0)),
                    match_reason=rec.get("match_reason", ""),
                    standard_count=collection_count_map.get(collection_id, 0),
                    usage_instruction=getattr(collection, 'usage_instruction', None),
                ))

        # æŒ‰ç›¸å…³æ€§æ’åº
        results.sort(key=lambda x: x.relevance_score, reverse=True)

        logger.info(f"æ¨è {len(results)} ä¸ªæ ‡å‡†é›†åˆ")
        return results

    except json.JSONDecodeError as e:
        logger.error(f"è§£æ LLM å“åº”å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail="LLM å“åº”è§£æå¤±è´¥")
    except Exception as e:
        logger.error(f"æ¨èé›†åˆå¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æ¨èå¤±è´¥: {str(e)}")


@app.get("/api/standard-library/collections/{collection_id}", response_model=CollectionWithStandardsResponse)
async def get_collection(
    collection_id: str,
    user_id: str = Depends(get_current_user),
):
    """è·å–å•ä¸ªé›†åˆï¼ˆåŒ…å«æ ‡å‡†åˆ—è¡¨ï¼Œéœ€è¦ç™»å½•ï¼‰"""
    result = standard_library_manager.get_collection_with_standards(collection_id)
    if result is None:
        raise HTTPException(status_code=404, detail="é›†åˆä¸å­˜åœ¨")

    collection = result["collection"]
    standards = result["standards"]

    # æ£€æŸ¥è®¿é—®æƒé™ï¼ˆé¢„è®¾é›†åˆå¯è¯»ï¼Œç”¨æˆ·é›†åˆåªèƒ½è®¿é—®è‡ªå·±çš„ï¼‰
    _check_collection_access(collection, user_id, require_ownership=False)

    return CollectionWithStandardsResponse(
        id=collection.id,
        name=collection.name,
        description=collection.description,
        material_type=collection.material_type,
        is_preset=collection.is_preset,
        language=getattr(collection, 'language', 'zh-CN'),
        standard_count=len(standards),
        standards=[_standard_to_response(s) for s in standards],
    )


# ---------- é›†åˆåˆ›å»º/æ›´æ–°/åˆ é™¤ ----------

class CreateCollectionRequest(BaseModel):
    """åˆ›å»ºé›†åˆè¯·æ±‚"""
    name: str
    description: str = ""
    material_type: str = "both"
    language: str = "zh-CN"  # "zh-CN" æˆ– "en"


class UpdateCollectionRequest(BaseModel):
    """æ›´æ–°é›†åˆè¯·æ±‚"""
    name: Optional[str] = None
    description: Optional[str] = None
    usage_instruction: Optional[str] = None
    material_type: Optional[str] = None
    language: Optional[str] = None


@app.post("/api/standard-library/collections", response_model=CollectionResponse)
async def create_collection(
    request: CreateCollectionRequest,
    user_id: str = Depends(get_current_user),
):
    """åˆ›å»ºæ–°çš„æ ‡å‡†é›†åˆï¼ˆéœ€è¦ç™»å½•ï¼‰"""
    collection = standard_library_manager.add_collection(
        name=request.name,
        description=request.description,
        material_type=request.material_type,
        is_preset=False,
        language=request.language,
        user_id=user_id,  # å…³è”åˆ°å½“å‰ç”¨æˆ·
    )
    logger.info(f"åˆ›å»ºæ ‡å‡†é›†åˆ: {collection.id} - {collection.name} (language={request.language}, user={user_id})")
    return _collection_to_response(collection)


@app.put("/api/standard-library/collections/{collection_id}", response_model=CollectionResponse)
async def update_collection(
    collection_id: str,
    request: UpdateCollectionRequest,
    user_id: str = Depends(get_current_user),
):
    """æ›´æ–°é›†åˆä¿¡æ¯ï¼ˆéœ€è¦ç™»å½•ï¼Œåªèƒ½æ›´æ–°è‡ªå·±çš„é›†åˆï¼‰"""
    # å…ˆæ£€æŸ¥æƒé™
    collection = standard_library_manager.get_collection(collection_id)
    _check_collection_access(collection, user_id, require_ownership=True)

    updates = {k: v for k, v in request.model_dump().items() if v is not None}
    if not updates:
        raise HTTPException(status_code=400, detail="æ²¡æœ‰æä¾›è¦æ›´æ–°çš„å­—æ®µ")

    success = standard_library_manager.update_collection(collection_id, updates)
    if not success:
        raise HTTPException(status_code=404, detail="é›†åˆä¸å­˜åœ¨")

    collection = standard_library_manager.get_collection(collection_id)
    return _collection_to_response(collection)


@app.post("/api/standard-library/collections/{collection_id}/generate-usage-instruction")
async def generate_collection_usage_instruction(
    collection_id: str,
    user_id: str = Depends(get_current_user),
):
    """ä¸ºé›†åˆç”Ÿæˆé€‚ç”¨è¯´æ˜ï¼ˆä½¿ç”¨ LLMï¼Œéœ€è¦ç™»å½•ï¼‰"""
    # è·å–é›†åˆä¿¡æ¯
    result = standard_library_manager.get_collection_with_standards(collection_id)
    if result is None:
        raise HTTPException(status_code=404, detail="é›†åˆä¸å­˜åœ¨")

    collection = result["collection"]
    standards = result["standards"]

    # æ£€æŸ¥æƒé™ï¼ˆåªæœ‰è‡ªå·±çš„é›†åˆæ‰èƒ½ç”Ÿæˆé€‚ç”¨è¯´æ˜ï¼‰
    _check_collection_access(collection, user_id, require_ownership=True)

    try:
        # æ„å»ºæ ‡å‡†åˆ—è¡¨æ‘˜è¦
        standards_data = [
            {"category": s.category, "item": s.item}
            for s in standards
        ]

        # è·å–é›†åˆè¯­è¨€
        language = getattr(collection, 'language', 'zh-CN')

        # æ„å»º Prompt
        messages = build_collection_usage_instruction_messages(
            collection_name=collection.name,
            collection_description=collection.description or "",
            material_type=collection.material_type,
            standards=standards_data,
            language=language,
        )

        # è°ƒç”¨ LLM
        usage_instruction = await llm_client.chat(messages, max_output_tokens=300)
        usage_instruction = usage_instruction.strip()

        # æ›´æ–°é›†åˆ
        standard_library_manager.update_collection(
            collection_id,
            {"usage_instruction": usage_instruction}
        )

        logger.info(f"ä¸ºé›†åˆ {collection_id} ç”Ÿæˆé€‚ç”¨è¯´æ˜")

        return {
            "collection_id": collection_id,
            "usage_instruction": usage_instruction,
        }

    except Exception as e:
        logger.error(f"ç”Ÿæˆé›†åˆé€‚ç”¨è¯´æ˜å¤±è´¥: {collection_id} - {e}")
        raise HTTPException(status_code=500, detail=f"ç”Ÿæˆå¤±è´¥: {str(e)}")


@app.delete("/api/standard-library/collections/{collection_id}")
async def delete_collection(
    collection_id: str,
    force: bool = False,
    user_id: str = Depends(get_current_user),
):
    """åˆ é™¤é›†åˆï¼ˆè¿åŒåˆ é™¤æ‰€æœ‰æ ‡å‡†ï¼Œéœ€è¦ç™»å½•ï¼‰"""
    # æ£€æŸ¥æƒé™
    collection = standard_library_manager.get_collection(collection_id)
    _check_collection_access(collection, user_id, require_ownership=True)

    success = standard_library_manager.delete_collection(collection_id, force=force)
    if not success:
        raise HTTPException(status_code=400, detail="é›†åˆä¸å­˜åœ¨æˆ–ä¸ºç³»ç»Ÿé¢„è®¾ä¸å¯åˆ é™¤")
    return {"message": "åˆ é™¤æˆåŠŸ"}


# ---------- é›†åˆå†…æ ‡å‡†ç®¡ç† ----------

@app.get("/api/standard-library/collections/{collection_id}/standards", response_model=List[StandardResponse])
async def list_collection_standards(
    collection_id: str,
    category: Optional[str] = None,
    risk_level: Optional[str] = None,
    keyword: Optional[str] = None,
    user_id: str = Depends(get_current_user),
):
    """è·å–é›†åˆå†…çš„æ ‡å‡†åˆ—è¡¨ï¼ˆæ”¯æŒç­›é€‰ï¼Œéœ€è¦ç™»å½•ï¼‰"""
    collection = standard_library_manager.get_collection(collection_id)
    _check_collection_access(collection, user_id, require_ownership=False)

    standards = standard_library_manager.list_collection_standards(
        collection_id=collection_id,
        category=category,
        risk_level=risk_level,
        keyword=keyword,
    )
    return [_standard_to_response(s) for s in standards]


@app.post("/api/standard-library/collections/{collection_id}/standards", response_model=StandardResponse)
async def add_standard_to_collection(
    collection_id: str,
    request: CreateStandardRequest,
    user_id: str = Depends(get_current_user),
):
    """å‘é›†åˆä¸­æ·»åŠ å•æ¡æ ‡å‡†ï¼ˆéœ€è¦ç™»å½•ï¼Œåªèƒ½æ·»åŠ åˆ°è‡ªå·±çš„é›†åˆï¼‰"""
    collection = standard_library_manager.get_collection(collection_id)
    _check_collection_access(collection, user_id, require_ownership=True)

    standard = ReviewStandard(
        category=request.category,
        item=request.item,
        description=request.description,
        risk_level=request.risk_level,
        applicable_to=request.applicable_to,
        usage_instruction=request.usage_instruction,
        tags=request.tags,
    )

    standard_id = standard_library_manager.add_standard_to_collection(collection_id, standard)
    created = standard_library_manager.get_standard(standard_id)
    return _standard_to_response(created)


@app.get("/api/standard-library/collections/{collection_id}/categories", response_model=List[str])
async def get_collection_categories(
    collection_id: str,
    user_id: str = Depends(get_current_user),
):
    """è·å–é›†åˆå†…çš„æ‰€æœ‰åˆ†ç±»ï¼ˆéœ€è¦ç™»å½•ï¼‰"""
    collection = standard_library_manager.get_collection(collection_id)
    _check_collection_access(collection, user_id, require_ownership=False)

    return standard_library_manager.get_collection_categories(collection_id)


# ==================== æ ‡å‡†åˆ¶ä½œ API ====================

@app.post("/api/standards/create-from-business", response_model=StandardCreationResponse)
async def create_standards_from_business(request: StandardCreationRequest):
    """æ ¹æ®ä¸šåŠ¡ä¿¡æ¯ç”Ÿæˆå®¡é˜…æ ‡å‡†ï¼ˆä½¿ç”¨ Geminiï¼‰"""
    from src.contract_review.gemini_client import GeminiClient
    from src.contract_review.prompts import get_standard_creation_prompts

    # æ£€æŸ¥ Gemini API Key æ˜¯å¦é…ç½®
    if not settings.gemini.api_key:
        raise HTTPException(
            status_code=500,
            detail="Gemini API Key æœªé…ç½®ï¼Œè¯·è®¾ç½®ç¯å¢ƒå˜é‡ GEMINI_API_KEY"
        )

    # éªŒè¯å¿…å¡«å­—æ®µ
    if not request.business_scenario or not request.business_scenario.strip():
        raise HTTPException(status_code=400, detail="ä¸šåŠ¡åœºæ™¯æè¿°ä¸èƒ½ä¸ºç©º")
    if not request.focus_areas:
        raise HTTPException(status_code=400, detail="è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªæ ¸å¿ƒå…³æ³¨ç‚¹")

    # è·å–è¯­è¨€å¯¹åº”çš„æç¤ºè¯
    language = request.language if request.language in ("zh-CN", "en") else "zh-CN"
    prompts = get_standard_creation_prompts(language)

    # åˆ›å»º Gemini å®¢æˆ·ç«¯
    gemini_client = GeminiClient(
        api_key=settings.gemini.api_key,
        model=settings.gemini.model,
        timeout=settings.gemini.timeout,
    )

    # æ„å»ºä¸šåŠ¡ä¿¡æ¯
    business_info = {
        "document_type": request.document_type,
        "business_scenario": request.business_scenario,
        "focus_areas": request.focus_areas,
        "our_role": request.our_role,
        "industry": request.industry,
        "special_risks": request.special_risks,
        "reference_material": request.reference_material,
        "language": language,
    }

    try:
        # è°ƒç”¨ Gemini ç”Ÿæˆæ ‡å‡†
        result = await gemini_client.generate_standards(
            business_info=business_info,
            system_prompt=prompts["system"],
            user_prompt_template=prompts["user"],
        )

        # è½¬æ¢ä¸ºå“åº”æ ¼å¼
        standards = []
        for s in result.get("standards", []):
            # æ ¹æ® document_type è®¾ç½® applicable_to
            if request.document_type == "both":
                applicable_to = ["contract", "marketing"]
            elif request.document_type == "contract":
                applicable_to = ["contract"]
            else:
                applicable_to = ["marketing"]

            # ä¼˜å…ˆä½¿ç”¨ LLM ç”Ÿæˆçš„ applicable_toï¼Œå¦åˆ™ä½¿ç”¨é»˜è®¤å€¼
            final_applicable_to = s.get("applicable_to", applicable_to)

            standards.append(GeneratedStandard(
                category=s.get("category", "æœªåˆ†ç±»"),
                item=s.get("item", ""),
                description=s.get("description", ""),
                risk_level=s.get("risk_level", "medium"),
                applicable_to=final_applicable_to,
                usage_instruction=s.get("usage_instruction", ""),
            ))

        # AI ç”Ÿæˆçš„é›†åˆåç§°ï¼ˆå¦‚æœæ²¡æœ‰åˆ™æ ¹æ®ä¸šåŠ¡åœºæ™¯ç”Ÿæˆé»˜è®¤åç§°ï¼‰
        collection_name = result.get("collection_name", "")
        if not collection_name:
            # æ ¹æ®ä¸šåŠ¡åœºæ™¯ç”Ÿæˆé»˜è®¤åç§°
            industry = request.industry or ""
            scenario = request.business_scenario[:20] if request.business_scenario else ""
            collection_name = f"{industry}{scenario}å®¡æ ¸æ ‡å‡†".strip()

        logger.info(f"æˆåŠŸç”Ÿæˆ {len(standards)} æ¡å®¡é˜…æ ‡å‡†ï¼Œé›†åˆåç§°: {collection_name}")

        return StandardCreationResponse(
            collection_name=collection_name,
            standards=standards,
            generation_summary=result.get("generation_summary", f"æˆåŠŸç”Ÿæˆ {len(standards)} æ¡å®¡é˜…æ ‡å‡†"),
        )

    except Exception as e:
        logger.error(f"ç”Ÿæˆå®¡é˜…æ ‡å‡†å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(
            status_code=500,
            detail=f"ç”Ÿæˆå®¡é˜…æ ‡å‡†å¤±è´¥: {str(e)}"
        )


# ==================== æ ‡å‡†é¢„è§ˆä¸å…¥åº“ API ====================

@app.post("/api/standards/preview", response_model=StandardPreviewResponse)
async def preview_standards(file: UploadFile = File(...)):
    """é¢„è§ˆä¸Šä¼ çš„æ ‡å‡†æ–‡ä»¶ï¼ˆè§£æä½†ä¸ä¿å­˜ï¼‰"""
    import tempfile

    # æ£€æŸ¥æ–‡ä»¶ç±»å‹
    suffix = Path(file.filename).suffix.lower()
    allowed = {".xlsx", ".xls", ".csv", ".docx", ".md", ".txt"}
    if suffix not in allowed:
        raise HTTPException(
            status_code=400,
            detail=f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹ã€‚æ”¯æŒçš„æ ¼å¼: {', '.join(allowed)}",
        )

    # ä¿å­˜ä¸´æ—¶æ–‡ä»¶å¹¶è§£æ
    content = await file.read()
    with tempfile.NamedTemporaryFile(suffix=suffix, delete=False) as tmp:
        tmp.write(content)
        tmp_path = Path(tmp.name)

    try:
        # è§£ææ ‡å‡†æ–‡ä»¶
        standard_set = parse_standard_file(tmp_path)

        # è½¬æ¢ä¸ºå“åº”æ ¼å¼
        standards = [_standard_to_response(s) for s in standard_set.standards]

        logger.info(f"é¢„è§ˆæ ‡å‡†æ–‡ä»¶: {file.filename}ï¼Œå…± {len(standards)} æ¡")

        return StandardPreviewResponse(
            standards=standards,
            total_count=len(standards),
            parse_warnings=[],
        )
    except Exception as e:
        logger.error(f"è§£ææ ‡å‡†æ–‡ä»¶å¤±è´¥: {e}")
        raise HTTPException(status_code=400, detail=f"è§£ææ–‡ä»¶å¤±è´¥: {str(e)}")
    finally:
        tmp_path.unlink()


@app.post("/api/standards/save-to-library")
async def save_standards_to_library(
    request: SaveToLibraryRequest,
    user_id: str = Depends(get_current_user),
):
    """å°†é¢„è§ˆçš„æ ‡å‡†ä¿å­˜åˆ°æ ‡å‡†åº“ï¼ˆåˆ›å»ºæ–°é›†åˆï¼‰"""
    if not request.collection_name or not request.collection_name.strip():
        raise HTTPException(status_code=400, detail="é›†åˆåç§°ä¸èƒ½ä¸ºç©º")

    if not request.standards:
        raise HTTPException(status_code=400, detail="è‡³å°‘éœ€è¦ä¸€æ¡æ ‡å‡†")

    # 1. åˆ›å»ºé›†åˆ
    collection = standard_library_manager.add_collection(
        name=request.collection_name.strip(),
        description=request.collection_description,
        material_type=request.material_type,
        is_preset=False,
        language=request.language,
        user_id=user_id,
    )

    # 2. åˆ›å»ºæ ‡å‡†å¹¶å…³è”åˆ°é›†åˆ
    standards = []
    for req in request.standards:
        standard = ReviewStandard(
            category=req.category,
            item=req.item,
            description=req.description,
            risk_level=req.risk_level,
            applicable_to=req.applicable_to,
            usage_instruction=req.usage_instruction,
            tags=req.tags,
        )
        standards.append(standard)

    # 3. æ‰¹é‡æ·»åŠ åˆ°é›†åˆ
    standard_ids = standard_library_manager.add_standards_to_collection(collection.id, standards)

    logger.info(f"ä¿å­˜åˆ°æ ‡å‡†åº“: é›†åˆ {collection.name}ï¼Œå…± {len(standard_ids)} æ¡æ ‡å‡†ï¼Œç”¨æˆ· {user_id}")

    return {
        "message": f"æˆåŠŸåˆ›å»ºæ ‡å‡†é›†ã€Œ{collection.name}ã€ï¼ŒåŒ…å« {len(standard_ids)} æ¡æ ‡å‡†",
        "collection_id": collection.id,
        "collection_name": collection.name,
        "imported_count": len(standard_ids),
    }


# ==================== LLM ç›¸å…³ API ====================

# æ‰¹é‡ç”Ÿæˆä½¿ç”¨è¯´æ˜çš„æœ€å¤§æ ‡å‡†æ•°é‡
MAX_BATCH_USAGE_INSTRUCTION = 20


@app.post("/api/standards/generate-usage-instruction")
async def generate_usage_instruction(request: GenerateUsageInstructionRequest):
    """ä¸ºæŒ‡å®šæ ‡å‡†ç”Ÿæˆé€‚ç”¨è¯´æ˜ï¼ˆä½¿ç”¨ LLMï¼‰"""
    # é™åˆ¶å•æ¬¡å¤„ç†çš„æ ‡å‡†æ•°é‡
    if len(request.standard_ids) > MAX_BATCH_USAGE_INSTRUCTION:
        raise HTTPException(
            status_code=400,
            detail=f"å•æ¬¡æœ€å¤šå¤„ç† {MAX_BATCH_USAGE_INSTRUCTION} ä¸ªæ ‡å‡†ï¼Œå½“å‰è¯·æ±‚ {len(request.standard_ids)} ä¸ª",
        )

    results = []
    errors = []

    for standard_id in request.standard_ids:
        standard = standard_library_manager.get_standard(standard_id)
        if not standard:
            errors.append(f"æ ‡å‡†ä¸å­˜åœ¨: {standard_id}")
            continue

        try:
            # æ„å»º Prompt
            messages = build_usage_instruction_messages(
                standard=standard,
                sample_document_text=request.sample_document_text or "",
            )

            # è°ƒç”¨ LLM
            usage_instruction = await llm_client.chat(messages, max_output_tokens=200)
            usage_instruction = usage_instruction.strip()

            # æ›´æ–°æ ‡å‡†
            standard_library_manager.update_standard(
                standard_id,
                {"usage_instruction": usage_instruction}
            )

            results.append(UsageInstructionResult(
                standard_id=standard_id,
                usage_instruction=usage_instruction,
            ))

            logger.info(f"ä¸ºæ ‡å‡† {standard_id} ç”Ÿæˆé€‚ç”¨è¯´æ˜")

        except Exception as e:
            logger.error(f"ç”Ÿæˆé€‚ç”¨è¯´æ˜å¤±è´¥: {standard_id} - {e}")
            errors.append(f"ç”Ÿæˆå¤±è´¥ ({standard_id}): {str(e)}")

    return {
        "results": [r.model_dump() for r in results],
        "errors": errors,
        "success_count": len(results),
    }


# æ¨èæ ‡å‡†æ—¶çš„æ–‡æ¡£é•¿åº¦é™åˆ¶å’Œæ ‡å‡†æ•°é‡é™åˆ¶
MAX_RECOMMEND_DOC_CHARS = 10000  # æœ€å¤šä½¿ç”¨æ–‡æ¡£å‰ 10000 å­—ç¬¦
MAX_RECOMMEND_STANDARDS = 50     # æœ€å¤šè€ƒè™‘ 50 ä¸ªæ ‡å‡†


@app.post("/api/standards/recommend", response_model=List[StandardRecommendationResponse])
async def recommend_standards(request: RecommendStandardsRequest):
    """æ ¹æ®æ–‡æ¡£å†…å®¹æ¨èå®¡æ ¸æ ‡å‡†ï¼ˆä½¿ç”¨ LLMï¼‰"""
    import json
    import re

    # è·å–é€‚ç”¨è¯¥ææ–™ç±»å‹çš„æ‰€æœ‰æ ‡å‡†
    available_standards = standard_library_manager.list_standards(
        material_type=request.material_type
    )

    if not available_standards:
        return []

    # é™åˆ¶æ ‡å‡†æ•°é‡ï¼ˆä¼˜å…ˆä½¿ç”¨é«˜é£é™©æ ‡å‡†ï¼‰
    if len(available_standards) > MAX_RECOMMEND_STANDARDS:
        # æŒ‰é£é™©ç­‰çº§æ’åºï¼šhigh > medium > low
        risk_order = {"high": 0, "medium": 1, "low": 2}
        available_standards = sorted(
            available_standards,
            key=lambda s: risk_order.get(s.risk_level, 1)
        )[:MAX_RECOMMEND_STANDARDS]
        logger.info(f"æ¨èæ ‡å‡†ï¼šæ ‡å‡†æ•°é‡ {len(available_standards)} è¶…è¿‡é™åˆ¶ï¼Œå·²æˆªå–å‰ {MAX_RECOMMEND_STANDARDS} ä¸ªé«˜ä¼˜å…ˆçº§æ ‡å‡†")

    # é™åˆ¶æ–‡æ¡£é•¿åº¦
    doc_text = request.document_text
    if len(doc_text) > MAX_RECOMMEND_DOC_CHARS:
        doc_text = doc_text[:MAX_RECOMMEND_DOC_CHARS]
        logger.info(f"æ¨èæ ‡å‡†ï¼šæ–‡æ¡£é•¿åº¦è¶…è¿‡é™åˆ¶ï¼Œå·²æˆªå–å‰ {MAX_RECOMMEND_DOC_CHARS} å­—ç¬¦")

    try:
        # æ„å»º Prompt
        messages = build_standard_recommendation_messages(
            document_text=doc_text,
            material_type=request.material_type,
            available_standards=available_standards,
        )

        # è°ƒç”¨ LLM
        response = await llm_client.chat(messages, max_output_tokens=2000)

        # è§£æ JSON å“åº”
        response = response.strip()
        # ç§»é™¤å¯èƒ½çš„ markdown ä»£ç å—
        response = re.sub(r"```json\s*", "", response)
        response = re.sub(r"```\s*$", "", response)

        # å°è¯•æ‰¾åˆ° JSON æ•°ç»„
        start = response.find("[")
        end = response.rfind("]")
        if start != -1 and end != -1:
            response = response[start:end + 1]

        recommendations = json.loads(response)

        # æ„å»ºå“åº”
        results = []
        for rec in recommendations:
            standard_id = rec.get("standard_id")
            standard = standard_library_manager.get_standard(standard_id)
            if standard:
                results.append(StandardRecommendationResponse(
                    standard_id=standard_id,
                    relevance_score=float(rec.get("relevance_score", 0)),
                    match_reason=rec.get("match_reason", ""),
                    standard=_standard_to_response(standard),
                ))

        # æŒ‰ç›¸å…³æ€§æ’åº
        results.sort(key=lambda x: x.relevance_score, reverse=True)

        logger.info(f"æ¨è {len(results)} æ¡æ ‡å‡†")
        return results

    except json.JSONDecodeError as e:
        logger.error(f"è§£æ LLM å“åº”å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail="LLM å“åº”è§£æå¤±è´¥")
    except Exception as e:
        logger.error(f"æ¨èæ ‡å‡†å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æ¨èå¤±è´¥: {str(e)}")


class AIModifyStandardRequest(BaseModel):
    """AI è¾…åŠ©ä¿®æ”¹æ ‡å‡†è¯·æ±‚"""
    instruction: str  # ç”¨æˆ·çš„è‡ªç„¶è¯­è¨€ä¿®æ”¹æŒ‡ä»¤


class AIModifyStandardResponse(BaseModel):
    """AI è¾…åŠ©ä¿®æ”¹æ ‡å‡†å“åº”"""
    category: str
    item: str
    description: str
    risk_level: str
    applicable_to: List[str]
    usage_instruction: Optional[str] = None
    modification_summary: str


# ---------- ç‰¹æ®Šè¦æ±‚æ•´åˆç›¸å…³æ¨¡å‹ ----------

class MergedStandardItem(BaseModel):
    """æ•´åˆåçš„å•æ¡æ ‡å‡†"""
    id: Optional[str] = None  # åŸæ ‡å‡†IDï¼Œæ–°å¢æ—¶ä¸ºnull
    category: str
    item: str
    description: str
    risk_level: str
    change_type: str  # unchanged | modified | added | removed
    change_reason: Optional[str] = None  # ä¿®æ”¹åŸå› 


class MergeSummary(BaseModel):
    """æ•´åˆæ‘˜è¦"""
    total_original: int
    total_merged: int
    added_count: int
    modified_count: int
    removed_count: int
    unchanged_count: int


class MergeSpecialRequirementsRequest(BaseModel):
    """æ•´åˆç‰¹æ®Šè¦æ±‚è¯·æ±‚"""
    standards: List[CreateStandardRequest]  # åŸºç¡€æ ‡å‡†åˆ—è¡¨
    special_requirements: str  # ç”¨æˆ·è¾“å…¥çš„ç‰¹æ®Šè¦æ±‚
    our_party: str  # æˆ‘æ–¹èº«ä»½
    material_type: str = "contract"  # ææ–™ç±»å‹


class MergeSpecialRequirementsResponse(BaseModel):
    """æ•´åˆç‰¹æ®Šè¦æ±‚å“åº”"""
    merged_standards: List[MergedStandardItem]
    summary: MergeSummary
    merge_notes: str  # æ•´åˆè¯´æ˜


class PresetTemplateInfo(BaseModel):
    """é¢„è®¾æ¨¡æ¿ä¿¡æ¯"""
    id: str
    name: str
    description: str
    material_type: str
    standard_count: int
    standards: List[StandardResponse]


@app.post("/api/standards/{standard_id}/ai-modify", response_model=AIModifyStandardResponse)
async def ai_modify_standard(standard_id: str, request: AIModifyStandardRequest):
    """
    ä½¿ç”¨ AI è¾…åŠ©ä¿®æ”¹å®¡æ ¸æ ‡å‡†

    ç”¨æˆ·æä¾›è‡ªç„¶è¯­è¨€æŒ‡ä»¤ï¼ŒAI ç†è§£æ„å›¾åç”Ÿæˆä¿®æ”¹å»ºè®®ã€‚
    æ­¤æ¥å£åªç”Ÿæˆå»ºè®®ï¼Œä¸ç›´æ¥ä¿å­˜ï¼Œç”¨æˆ·éœ€ç¡®è®¤åå†ä¿å­˜ã€‚
    """
    import json
    import re

    # è·å–å½“å‰æ ‡å‡†
    standard = standard_library_manager.get_standard(standard_id)
    if not standard:
        raise HTTPException(status_code=404, detail="æ ‡å‡†ä¸å­˜åœ¨")

    if not request.instruction or not request.instruction.strip():
        raise HTTPException(status_code=400, detail="è¯·è¾“å…¥ä¿®æ”¹è¦æ±‚")

    try:
        # æ„å»º Prompt
        messages = build_standard_modification_messages(
            standard=standard,
            user_instruction=request.instruction.strip(),
        )

        # è°ƒç”¨ LLM
        response = await llm_client.chat(messages, max_output_tokens=1000)

        # è§£æ JSON å“åº”
        response = response.strip()
        # ç§»é™¤å¯èƒ½çš„ markdown ä»£ç å—
        response = re.sub(r"```json\s*", "", response)
        response = re.sub(r"```\s*$", "", response)

        # å°è¯•æ‰¾åˆ° JSON å¯¹è±¡
        start = response.find("{")
        end = response.rfind("}")
        if start != -1 and end != -1:
            response = response[start:end + 1]

        modified = json.loads(response)

        # éªŒè¯å¿…è¦å­—æ®µ
        required_fields = ["category", "item", "description", "risk_level", "applicable_to", "modification_summary"]
        for field in required_fields:
            if field not in modified:
                raise ValueError(f"å“åº”ç¼ºå°‘å¿…è¦å­—æ®µ: {field}")

        # éªŒè¯ risk_level
        if modified["risk_level"] not in ["high", "medium", "low"]:
            modified["risk_level"] = standard.risk_level

        # éªŒè¯ applicable_to
        valid_types = {"contract", "marketing"}
        modified["applicable_to"] = [
            t for t in modified.get("applicable_to", [])
            if t in valid_types
        ]
        if not modified["applicable_to"]:
            modified["applicable_to"] = list(standard.applicable_to)

        logger.info(f"AI è¾…åŠ©ä¿®æ”¹æ ‡å‡† {standard_id}: {modified.get('modification_summary', '')}")

        return AIModifyStandardResponse(
            category=modified["category"],
            item=modified["item"],
            description=modified["description"],
            risk_level=modified["risk_level"],
            applicable_to=modified["applicable_to"],
            usage_instruction=modified.get("usage_instruction"),
            modification_summary=modified["modification_summary"],
        )

    except json.JSONDecodeError as e:
        logger.error(f"è§£æ AI ä¿®æ”¹å“åº”å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail="AI å“åº”è§£æå¤±è´¥ï¼Œè¯·é‡è¯•")
    except ValueError as e:
        logger.error(f"AI ä¿®æ”¹å“åº”éªŒè¯å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))
    except Exception as e:
        logger.error(f"AI è¾…åŠ©ä¿®æ”¹å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"ä¿®æ”¹å¤±è´¥: {str(e)}")


# ==================== é¢„è®¾æ¨¡æ¿ API ====================

@app.get("/api/preset-templates", response_model=List[PresetTemplateInfo])
async def get_preset_templates():
    """
    è·å–é¢„è®¾æ¨¡æ¿åˆ—è¡¨ï¼ˆä» templates ç›®å½•è¯»å–ï¼‰

    é¢„è®¾æ¨¡æ¿æ˜¯ç³»ç»Ÿå†…ç½®çš„æ ‡å‡†æ¨¡æ¿ï¼Œç”¨æˆ·å¯ä»¥ç›´æ¥é€‰æ‹©ä½¿ç”¨ã€‚
    """
    templates = []

    if TEMPLATES_DIR.exists():
        for f in TEMPLATES_DIR.iterdir():
            if f.suffix.lower() in {".xlsx", ".csv"}:
                try:
                    # è§£ææ¨¡æ¿æ–‡ä»¶
                    standard_set = parse_standard_file(f)

                    # æ ¹æ®æ–‡ä»¶åç¡®å®šææ–™ç±»å‹å’Œæè¿°
                    name = f.stem
                    if "contract" in name.lower() or "åˆåŒ" in name:
                        material_type = "contract"
                        description = "é€šç”¨åˆåŒå®¡æ ¸æ ‡å‡†ï¼Œæ¶µç›–ä¸»ä½“èµ„æ ¼ã€æƒåˆ©ä¹‰åŠ¡ã€è´¹ç”¨æ¡æ¬¾ç­‰å…³é”®å®¡æ ¸è¦ç‚¹"
                    elif "marketing" in name.lower() or "è¥é”€" in name:
                        material_type = "marketing"
                        description = "è¥é”€ææ–™åˆè§„å®¡æ ¸æ ‡å‡†ï¼Œæ¶µç›–å¹¿å‘Šæ³•ã€æ¶ˆè´¹è€…æƒç›Šä¿æŠ¤ç­‰åˆè§„è¦ç‚¹"
                    else:
                        material_type = "contract"
                        description = "å®¡æ ¸æ ‡å‡†æ¨¡æ¿"

                    # å°†æ ‡å‡†è½¬æ¢ä¸ºå“åº”æ ¼å¼
                    standards_response = []
                    for s in standard_set.standards:
                        standards_response.append(StandardResponse(
                            id=s.id or "",
                            category=s.category,
                            item=s.item,
                            description=s.description,
                            risk_level=s.risk_level,
                            applicable_to=list(s.applicable_to),
                            usage_instruction=s.usage_instruction,
                            tags=list(s.tags) if s.tags else [],
                        ))

                    templates.append(PresetTemplateInfo(
                        id=name,
                        name=name,
                        description=description,
                        material_type=material_type,
                        standard_count=len(standard_set.standards),
                        standards=standards_response,
                    ))
                except Exception as e:
                    logger.error(f"è§£ææ¨¡æ¿æ–‡ä»¶å¤±è´¥ {f.name}: {e}")
                    continue

    return templates


@app.get("/api/preset-templates/{template_id}", response_model=PresetTemplateInfo)
async def get_preset_template(template_id: str):
    """è·å–å•ä¸ªé¢„è®¾æ¨¡æ¿çš„è¯¦ç»†ä¿¡æ¯"""
    template_path = TEMPLATES_DIR / f"{template_id}.xlsx"
    if not template_path.exists():
        template_path = TEMPLATES_DIR / f"{template_id}.csv"
    if not template_path.exists():
        raise HTTPException(status_code=404, detail="æ¨¡æ¿ä¸å­˜åœ¨")

    try:
        standard_set = parse_standard_file(template_path)

        name = template_path.stem
        if "contract" in name.lower() or "åˆåŒ" in name:
            material_type = "contract"
            description = "é€šç”¨åˆåŒå®¡æ ¸æ ‡å‡†ï¼Œæ¶µç›–ä¸»ä½“èµ„æ ¼ã€æƒåˆ©ä¹‰åŠ¡ã€è´¹ç”¨æ¡æ¬¾ç­‰å…³é”®å®¡æ ¸è¦ç‚¹"
        elif "marketing" in name.lower() or "è¥é”€" in name:
            material_type = "marketing"
            description = "è¥é”€ææ–™åˆè§„å®¡æ ¸æ ‡å‡†ï¼Œæ¶µç›–å¹¿å‘Šæ³•ã€æ¶ˆè´¹è€…æƒç›Šä¿æŠ¤ç­‰åˆè§„è¦ç‚¹"
        else:
            material_type = "contract"
            description = "å®¡æ ¸æ ‡å‡†æ¨¡æ¿"

        standards_response = []
        for s in standard_set.standards:
            standards_response.append(StandardResponse(
                id=s.id or "",
                category=s.category,
                item=s.item,
                description=s.description,
                risk_level=s.risk_level,
                applicable_to=list(s.applicable_to),
                usage_instruction=s.usage_instruction,
                tags=list(s.tags) if s.tags else [],
            ))

        return PresetTemplateInfo(
            id=name,
            name=name,
            description=description,
            material_type=material_type,
            standard_count=len(standard_set.standards),
            standards=standards_response,
        )
    except Exception as e:
        logger.error(f"è·å–æ¨¡æ¿å¤±è´¥ {template_id}: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–æ¨¡æ¿å¤±è´¥: {str(e)}")


# ==================== ç‰¹æ®Šè¦æ±‚æ•´åˆ API ====================

@app.post("/api/standards/merge-special-requirements", response_model=MergeSpecialRequirementsResponse)
async def merge_special_requirements(request: MergeSpecialRequirementsRequest):
    """
    æ•´åˆç‰¹æ®Šè¦æ±‚åˆ°å®¡æ ¸æ ‡å‡†ï¼ˆä½¿ç”¨ LLMï¼‰

    å°†ç”¨æˆ·è¾“å…¥çš„é¡¹ç›®ç‰¹æ®Šè¦æ±‚æ•´åˆåˆ°é€‰å®šçš„åŸºç¡€æ ‡å‡†ä¸­ï¼Œ
    LLM ä¼šæ ¹æ®ç‰¹æ®Šè¦æ±‚å¯¹æ ‡å‡†è¿›è¡Œæ–°å¢ã€ä¿®æ”¹æˆ–åˆ é™¤ã€‚
    """
    import json
    import re

    if not request.special_requirements or not request.special_requirements.strip():
        raise HTTPException(status_code=400, detail="è¯·è¾“å…¥ç‰¹æ®Šè¦æ±‚")

    if not request.standards:
        raise HTTPException(status_code=400, detail="è¯·é€‰æ‹©åŸºç¡€æ ‡å‡†")

    # å°†è¯·æ±‚ä¸­çš„æ ‡å‡†è½¬æ¢ä¸º ReviewStandard å¯¹è±¡
    base_standards = []
    for i, s in enumerate(request.standards):
        base_standards.append(ReviewStandard(
            id=f"std_{i+1}",
            category=s.category,
            item=s.item,
            description=s.description,
            risk_level=s.risk_level,
            applicable_to=s.applicable_to,
        ))

    try:
        # æ„å»º Prompt
        messages = build_merge_special_requirements_messages(
            standards=base_standards,
            special_requirements=request.special_requirements.strip(),
            our_party=request.our_party,
            material_type=request.material_type,
        )

        # è°ƒç”¨ LLM
        response = await llm_client.chat(messages, max_output_tokens=4000)

        # è§£æ JSON å“åº”
        response = response.strip()
        # ç§»é™¤å¯èƒ½çš„ markdown ä»£ç å—
        response = re.sub(r"```json\s*", "", response)
        response = re.sub(r"```\s*$", "", response)

        # å°è¯•æ‰¾åˆ° JSON å¯¹è±¡
        start = response.find("{")
        end = response.rfind("}")
        if start != -1 and end != -1:
            response = response[start:end + 1]

        result = json.loads(response)

        # éªŒè¯å“åº”ç»“æ„
        if "merged_standards" not in result:
            raise ValueError("å“åº”ç¼ºå°‘ merged_standards å­—æ®µ")

        # æ„å»ºå“åº”
        merged_standards = []
        for s in result.get("merged_standards", []):
            merged_standards.append(MergedStandardItem(
                id=s.get("id"),
                category=s.get("category", ""),
                item=s.get("item", ""),
                description=s.get("description", ""),
                risk_level=s.get("risk_level", "medium"),
                change_type=s.get("change_type", "unchanged"),
                change_reason=s.get("change_reason"),
            ))

        summary_data = result.get("summary", {})
        summary = MergeSummary(
            total_original=summary_data.get("total_original", len(request.standards)),
            total_merged=summary_data.get("total_merged", len(merged_standards)),
            added_count=summary_data.get("added_count", 0),
            modified_count=summary_data.get("modified_count", 0),
            removed_count=summary_data.get("removed_count", 0),
            unchanged_count=summary_data.get("unchanged_count", 0),
        )

        merge_notes = result.get("merge_notes", "å·²å®Œæˆç‰¹æ®Šè¦æ±‚æ•´åˆ")

        logger.info(f"æ•´åˆç‰¹æ®Šè¦æ±‚: {summary.modified_count} ä¿®æ”¹, {summary.added_count} æ–°å¢, {summary.removed_count} åˆ é™¤")

        return MergeSpecialRequirementsResponse(
            merged_standards=merged_standards,
            summary=summary,
            merge_notes=merge_notes,
        )

    except json.JSONDecodeError as e:
        logger.error(f"è§£æ LLM å“åº”å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail="AI å“åº”è§£æå¤±è´¥ï¼Œè¯·é‡è¯•")
    except ValueError as e:
        logger.error(f"å“åº”éªŒè¯å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))
    except Exception as e:
        logger.error(f"æ•´åˆç‰¹æ®Šè¦æ±‚å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æ•´åˆå¤±è´¥: {str(e)}")


# ==================== ä¸šåŠ¡æ¡çº¿ç®¡ç† API ====================

class BusinessLineCreate(BaseModel):
    """åˆ›å»ºä¸šåŠ¡æ¡çº¿è¯·æ±‚"""
    name: str
    description: str = ""
    industry: str = ""
    language: str = "zh-CN"


class BusinessLineUpdate(BaseModel):
    """æ›´æ–°ä¸šåŠ¡æ¡çº¿è¯·æ±‚"""
    name: Optional[str] = None
    description: Optional[str] = None
    industry: Optional[str] = None


class BusinessContextCreate(BaseModel):
    """åˆ›å»ºä¸šåŠ¡èƒŒæ™¯ä¿¡æ¯è¯·æ±‚"""
    category: str  # core_focus, typical_risks, compliance, business_practices, negotiation_priorities
    item: str
    description: str
    priority: str = "medium"  # high, medium, low
    tags: List[str] = []


class BusinessContextUpdate(BaseModel):
    """æ›´æ–°ä¸šåŠ¡èƒŒæ™¯ä¿¡æ¯è¯·æ±‚"""
    category: Optional[str] = None
    item: Optional[str] = None
    description: Optional[str] = None
    priority: Optional[str] = None
    tags: Optional[List[str]] = None


class BusinessContextBatchCreate(BaseModel):
    """æ‰¹é‡åˆ›å»ºä¸šåŠ¡èƒŒæ™¯ä¿¡æ¯è¯·æ±‚"""
    contexts: List[BusinessContextCreate]


class BusinessLineResponse(BaseModel):
    """ä¸šåŠ¡æ¡çº¿å“åº”"""
    id: str
    name: str
    description: str
    industry: str
    is_preset: bool
    language: str
    context_count: int
    created_at: str
    updated_at: str


class BusinessContextResponse(BaseModel):
    """ä¸šåŠ¡èƒŒæ™¯ä¿¡æ¯å“åº”"""
    id: str
    business_line_id: str
    category: str
    item: str
    description: str
    priority: str
    tags: List[str]
    created_at: Optional[str] = None
    updated_at: Optional[str] = None


class BusinessLineDetailResponse(BusinessLineResponse):
    """ä¸šåŠ¡æ¡çº¿è¯¦æƒ…å“åº”ï¼ˆå«èƒŒæ™¯ä¿¡æ¯ï¼‰"""
    contexts: List[BusinessContextResponse]


@app.get("/api/business-lines", response_model=List[BusinessLineResponse])
async def list_business_lines(
    language: Optional[str] = Query(default=None),
    include_preset: bool = Query(default=True),
    user_id: str = Depends(get_current_user),
):
    """è·å–ä¸šåŠ¡æ¡çº¿åˆ—è¡¨ï¼ˆéœ€è¦ç™»å½•ï¼‰"""
    lines = business_library_manager.list_business_lines(
        user_id=user_id,
        language=language,
        include_preset=include_preset,
    )
    return [
        BusinessLineResponse(
            id=line.id,
            name=line.name,
            description=line.description,
            industry=line.industry,
            is_preset=line.is_preset,
            language=line.language,
            context_count=line.context_count,
            created_at=line.created_at.isoformat() if line.created_at else "",
            updated_at=line.updated_at.isoformat() if line.updated_at else "",
        )
        for line in lines
    ]


@app.get("/api/business-lines/{line_id}", response_model=BusinessLineDetailResponse)
async def get_business_line(
    line_id: str,
    user_id: str = Depends(get_current_user),
):
    """è·å–ä¸šåŠ¡æ¡çº¿è¯¦æƒ…ï¼ˆå«èƒŒæ™¯ä¿¡æ¯ï¼‰"""
    line = business_library_manager.get_business_line(line_id)
    if not line:
        raise HTTPException(status_code=404, detail="ä¸šåŠ¡æ¡çº¿ä¸å­˜åœ¨")

    return BusinessLineDetailResponse(
        id=line.id,
        name=line.name,
        description=line.description,
        industry=line.industry,
        is_preset=line.is_preset,
        language=line.language,
        context_count=line.context_count,
        created_at=line.created_at.isoformat() if line.created_at else "",
        updated_at=line.updated_at.isoformat() if line.updated_at else "",
        contexts=[
            BusinessContextResponse(
                id=ctx.id,
                business_line_id=ctx.business_line_id or "",
                category=ctx.category,
                item=ctx.item,
                description=ctx.description,
                priority=ctx.priority,
                tags=ctx.tags,
                created_at=ctx.created_at.isoformat() if ctx.created_at else None,
                updated_at=ctx.updated_at.isoformat() if ctx.updated_at else None,
            )
            for ctx in line.contexts
        ],
    )


@app.post("/api/business-lines", response_model=BusinessLineResponse)
async def create_business_line(
    request: BusinessLineCreate,
    user_id: str = Depends(get_current_user),
):
    """åˆ›å»ºä¸šåŠ¡æ¡çº¿ï¼ˆéœ€è¦ç™»å½•ï¼‰"""
    line = business_library_manager.create_business_line(
        name=request.name,
        user_id=user_id,
        description=request.description,
        industry=request.industry,
        is_preset=False,  # ç”¨æˆ·åˆ›å»ºçš„ä¸èƒ½æ˜¯é¢„è®¾
        language=request.language,
    )
    return BusinessLineResponse(
        id=line.id,
        name=line.name,
        description=line.description,
        industry=line.industry,
        is_preset=line.is_preset,
        language=line.language,
        context_count=0,
        created_at=line.created_at.isoformat() if line.created_at else "",
        updated_at=line.updated_at.isoformat() if line.updated_at else "",
    )


@app.put("/api/business-lines/{line_id}", response_model=BusinessLineResponse)
async def update_business_line(
    line_id: str,
    request: BusinessLineUpdate,
    user_id: str = Depends(get_current_user),
):
    """æ›´æ–°ä¸šåŠ¡æ¡çº¿ï¼ˆéœ€è¦ç™»å½•ï¼‰"""
    updates = {k: v for k, v in request.model_dump().items() if v is not None}
    line = business_library_manager.update_business_line(line_id, updates)
    if not line:
        raise HTTPException(status_code=404, detail="ä¸šåŠ¡æ¡çº¿ä¸å­˜åœ¨æˆ–æ— æ³•ç¼–è¾‘")

    # è·å–æ›´æ–°åçš„å®Œæ•´ä¸šåŠ¡çº¿ä¿¡æ¯ï¼ˆå« context_countï¼‰
    updated_line = business_library_manager.get_business_line(line_id)
    context_count = updated_line.context_count if updated_line else 0
    return BusinessLineResponse(
        id=line.id,
        name=line.name,
        description=line.description,
        industry=line.industry,
        is_preset=line.is_preset,
        language=line.language,
        context_count=context_count,
        created_at=line.created_at.isoformat() if line.created_at else "",
        updated_at=line.updated_at.isoformat() if line.updated_at else "",
    )


@app.delete("/api/business-lines/{line_id}")
async def delete_business_line(
    line_id: str,
    user_id: str = Depends(get_current_user),
):
    """åˆ é™¤ä¸šåŠ¡æ¡çº¿ï¼ˆéœ€è¦ç™»å½•ï¼‰"""
    success = business_library_manager.delete_business_line(line_id)
    if not success:
        raise HTTPException(status_code=404, detail="ä¸šåŠ¡æ¡çº¿ä¸å­˜åœ¨æˆ–æ— æ³•åˆ é™¤")
    return {"message": "åˆ é™¤æˆåŠŸ"}


# ==================== ä¸šåŠ¡èƒŒæ™¯ä¿¡æ¯ç®¡ç† API ====================

@app.get("/api/business-lines/{line_id}/contexts", response_model=List[BusinessContextResponse])
async def list_business_contexts(
    line_id: str,
    category: Optional[str] = Query(default=None),
    user_id: str = Depends(get_current_user),
):
    """è·å–ä¸šåŠ¡æ¡çº¿çš„èƒŒæ™¯ä¿¡æ¯åˆ—è¡¨"""
    contexts = business_library_manager.list_contexts(line_id, category=category)
    return [
        BusinessContextResponse(
            id=ctx.id,
            business_line_id=ctx.business_line_id or "",
            category=ctx.category,
            item=ctx.item,
            description=ctx.description,
            priority=ctx.priority,
            tags=ctx.tags,
            created_at=ctx.created_at.isoformat() if ctx.created_at else None,
            updated_at=ctx.updated_at.isoformat() if ctx.updated_at else None,
        )
        for ctx in contexts
    ]


@app.post("/api/business-lines/{line_id}/contexts", response_model=BusinessContextResponse)
async def add_business_context(
    line_id: str,
    request: BusinessContextCreate,
    user_id: str = Depends(get_current_user),
):
    """æ·»åŠ ä¸šåŠ¡èƒŒæ™¯ä¿¡æ¯ï¼ˆéœ€è¦ç™»å½•ï¼‰"""
    from src.contract_review.models import BusinessContext

    # æ£€æŸ¥ä¸šåŠ¡æ¡çº¿æ˜¯å¦å­˜åœ¨
    line = business_library_manager.get_business_line(line_id)
    if not line:
        raise HTTPException(status_code=404, detail="ä¸šåŠ¡æ¡çº¿ä¸å­˜åœ¨")

    # é¢„è®¾ä¸šåŠ¡æ¡çº¿ä¸èƒ½æ·»åŠ å†…å®¹
    if line.is_preset:
        raise HTTPException(status_code=400, detail="é¢„è®¾ä¸šåŠ¡æ¡çº¿ä¸èƒ½æ·»åŠ å†…å®¹")

    context = BusinessContext(
        business_line_id=line_id,
        category=request.category,
        item=request.item,
        description=request.description,
        priority=request.priority,
        tags=request.tags,
    )

    context_id = business_library_manager.add_context(context)
    created_ctx = business_library_manager.get_context(context_id)

    return BusinessContextResponse(
        id=created_ctx.id,
        business_line_id=created_ctx.business_line_id or "",
        category=created_ctx.category,
        item=created_ctx.item,
        description=created_ctx.description,
        priority=created_ctx.priority,
        tags=created_ctx.tags,
        created_at=created_ctx.created_at.isoformat() if created_ctx.created_at else None,
        updated_at=created_ctx.updated_at.isoformat() if created_ctx.updated_at else None,
    )


@app.post("/api/business-lines/{line_id}/contexts/batch")
async def add_business_contexts_batch(
    line_id: str,
    request: BusinessContextBatchCreate,
    user_id: str = Depends(get_current_user),
):
    """æ‰¹é‡æ·»åŠ ä¸šåŠ¡èƒŒæ™¯ä¿¡æ¯ï¼ˆéœ€è¦ç™»å½•ï¼‰"""
    from src.contract_review.models import BusinessContext

    # æ£€æŸ¥ä¸šåŠ¡æ¡çº¿æ˜¯å¦å­˜åœ¨
    line = business_library_manager.get_business_line(line_id)
    if not line:
        raise HTTPException(status_code=404, detail="ä¸šåŠ¡æ¡çº¿ä¸å­˜åœ¨")

    if line.is_preset:
        raise HTTPException(status_code=400, detail="é¢„è®¾ä¸šåŠ¡æ¡çº¿ä¸èƒ½æ·»åŠ å†…å®¹")

    contexts = [
        BusinessContext(
            business_line_id=line_id,
            category=ctx.category,
            item=ctx.item,
            description=ctx.description,
            priority=ctx.priority,
            tags=ctx.tags,
        )
        for ctx in request.contexts
    ]

    ids = business_library_manager.add_contexts_batch(contexts)
    return {"message": f"æˆåŠŸæ·»åŠ  {len(ids)} æ¡èƒŒæ™¯ä¿¡æ¯", "ids": ids}


@app.put("/api/business-contexts/{context_id}", response_model=BusinessContextResponse)
async def update_business_context(
    context_id: str,
    request: BusinessContextUpdate,
    user_id: str = Depends(get_current_user),
):
    """æ›´æ–°ä¸šåŠ¡èƒŒæ™¯ä¿¡æ¯ï¼ˆéœ€è¦ç™»å½•ï¼‰"""
    updates = {k: v for k, v in request.model_dump().items() if v is not None}
    ctx = business_library_manager.update_context(context_id, updates)
    if not ctx:
        raise HTTPException(status_code=404, detail="èƒŒæ™¯ä¿¡æ¯ä¸å­˜åœ¨æˆ–æ— æ³•ç¼–è¾‘")

    return BusinessContextResponse(
        id=ctx.id,
        business_line_id=ctx.business_line_id or "",
        category=ctx.category,
        item=ctx.item,
        description=ctx.description,
        priority=ctx.priority,
        tags=ctx.tags,
        created_at=ctx.created_at.isoformat() if ctx.created_at else None,
        updated_at=ctx.updated_at.isoformat() if ctx.updated_at else None,
    )


@app.delete("/api/business-contexts/{context_id}")
async def delete_business_context(
    context_id: str,
    user_id: str = Depends(get_current_user),
):
    """åˆ é™¤ä¸šåŠ¡èƒŒæ™¯ä¿¡æ¯ï¼ˆéœ€è¦ç™»å½•ï¼‰"""
    success = business_library_manager.delete_context(context_id)
    if not success:
        raise HTTPException(status_code=404, detail="èƒŒæ™¯ä¿¡æ¯ä¸å­˜åœ¨æˆ–æ— æ³•åˆ é™¤")
    return {"message": "åˆ é™¤æˆåŠŸ"}


@app.get("/api/business-categories")
async def get_business_categories(
    language: str = Query(default="zh-CN"),
):
    """è·å–ä¸šåŠ¡èƒŒæ™¯åˆ†ç±»åˆ—è¡¨"""
    categories = business_library_manager.get_categories()
    display_names = business_library_manager.get_category_display_names(language)
    return [
        {"id": cat, "name": display_names.get(cat, cat)}
        for cat in categories
    ]


# ==================== æ·±åº¦äº¤äº’å®¡é˜…æ¨¡å¼ API ====================

class QuickReviewRequest(BaseModel):
    """å¿«é€Ÿåˆå®¡è¯·æ±‚"""
    llm_provider: str = "deepseek"


class UnifiedReviewRequest(BaseModel):
    """ç»Ÿä¸€å®¡é˜…è¯·æ±‚

    æ”¯æŒä¸¤ç§æ¨¡å¼ï¼š
    1. use_standards=False: AI è‡ªä¸»å®¡é˜…ï¼ˆæ— é¢„è®¾æ ‡å‡†ï¼‰
    2. use_standards=True: åŸºäºå·²ä¸Šä¼ çš„å®¡æ ¸æ ‡å‡†å®¡é˜…
    """
    llm_provider: str = "deepseek"
    use_standards: bool = False  # æ˜¯å¦ä½¿ç”¨å®¡æ ¸æ ‡å‡†
    business_line_id: Optional[str] = None  # ä¸šåŠ¡æ¡çº¿ IDï¼ˆå¯é€‰ï¼‰
    special_requirements: Optional[str] = None  # æœ¬æ¬¡ç‰¹æ®Šè¦æ±‚ï¼ˆå¯é€‰ï¼‰


class InteractiveItemResponse(BaseModel):
    """å•ä¸ªäº¤äº’æ¡ç›®å“åº”ï¼ˆåŸºäºé£é™©ç‚¹ï¼‰"""
    id: str
    item_id: str  # risk.id
    item_type: str = "risk"  # æ”¹ä¸ºåŸºäº risk
    risk_level: str = "medium"
    risk_type: str = ""  # é£é™©ç±»å‹
    description: str = ""  # é£é™©æè¿°
    analysis: Optional[str] = None  # æ·±åº¦åˆ†æ
    original_text: str  # ç›¸å…³åŸæ–‡ï¼ˆç¼ºå¤±æ¡æ¬¾ç±»å‹å¯èƒ½ä¸ºç©ºï¼‰
    reason: str = ""  # åˆ¤å®šç†ç”±
    # ä¿®æ”¹å»ºè®®ç›¸å…³ï¼ˆç”¨æˆ·ç¡®è®¤åæ‰æœ‰å€¼ï¼‰
    has_modification: bool = False
    modification_id: Optional[str] = None
    suggested_text: Optional[str] = None
    modification_reason: Optional[str] = None
    is_addition: bool = False  # æ˜¯å¦ä¸ºè¡¥å……æ¡æ¬¾ï¼ˆTrue=æ–°å¢æ¡æ¬¾ï¼ŒFalse=ä¿®æ”¹ç°æœ‰æ¡æ¬¾ï¼‰
    insertion_point: Optional[str] = None  # è¡¥å……æ¡æ¬¾çš„æ’å…¥ä½ç½®è¯´æ˜
    # å¯¹è¯çŠ¶æ€
    chat_status: str
    message_count: int
    last_updated: Optional[str] = None
    # è·³è¿‡çŠ¶æ€
    is_skipped: bool = False
    # æ˜¯å¦ä¸ºç¼ºå¤±æ¡æ¬¾ç±»å‹ï¼ˆæ²¡æœ‰åŸæ–‡çš„é£é™©ç‚¹ï¼‰
    is_missing_clause: bool = False


class InteractiveItemsResponse(BaseModel):
    """ä»»åŠ¡çš„æ‰€æœ‰äº¤äº’æ¡ç›®å“åº”"""
    task_id: str
    items: List[InteractiveItemResponse]
    summary: dict


class ChatRequest(BaseModel):
    """å¯¹è¯æ¶ˆæ¯è¯·æ±‚"""
    message: str
    llm_provider: str = "deepseek"


class ChatResponse(BaseModel):
    """å¯¹è¯å“åº”"""
    item_id: str
    assistant_reply: str
    updated_suggestion: str
    chat_status: str
    messages: List[dict]


class CompleteItemRequest(BaseModel):
    """å®Œæˆæ¡ç›®è¯·æ±‚"""
    final_suggestion: Optional[str] = None


async def run_unified_review(
    task_id: str,
    user_id: str,
    llm_provider: str = "deepseek",
    use_standards: bool = False,
    business_line_id: Optional[str] = None,
    special_requirements: Optional[str] = None,
):
    """åå°æ‰§è¡Œç»Ÿä¸€å®¡é˜…ä»»åŠ¡

    æ”¯æŒä¸¤ç§æ¨¡å¼ï¼š
    1. use_standards=False: AI è‡ªä¸»å®¡é˜…
    2. use_standards=True: åŸºäºå®¡æ ¸æ ‡å‡†å®¡é˜…
    """
    task = task_manager.get_task(task_id)
    if not task:
        logger.error(f"ä»»åŠ¡ä¸å­˜åœ¨: {task_id}")
        return

    try:
        # æ›´æ–°çŠ¶æ€
        if use_standards:
            task.update_status("reviewing", "æ­£åœ¨åŸºäºå®¡æ ¸æ ‡å‡†è¿›è¡Œå®¡é˜…...")
        else:
            task.update_status("reviewing", "æ­£åœ¨è¿›è¡Œ AI è‡ªä¸»å®¡é˜…...")
        task.review_mode = "interactive"  # ç»Ÿä¸€ä½¿ç”¨äº¤äº’æ¨¡å¼
        task_manager.update_task(task)

        # è·å–æ–‡æ¡£è·¯å¾„ï¼ˆtask_manager ä¼šä» Supabase Storage ä¸‹è½½åˆ°æœ¬åœ°ä¸´æ—¶ç›®å½•ï¼‰
        doc_path = task_manager.get_document_path(task_id, user_id)
        if not doc_path or not doc_path.exists():
            raise ValueError("æ–‡æ¡£æœªä¸Šä¼ æˆ–æ— æ³•ä¸‹è½½")

        # åŠ è½½æ–‡æ¡£
        ocr_service = get_ocr_service()
        document = await load_document_async(doc_path, ocr_service=ocr_service)

        # åŠ è½½å®¡æ ¸æ ‡å‡†ï¼ˆå¦‚æœéœ€è¦ï¼‰
        review_standards = None
        if use_standards:
            std_path = task_manager.get_standard_path(task_id, user_id)
            if not std_path or not std_path.exists():
                raise ValueError("ä½¿ç”¨æ ‡å‡†æ¨¡å¼ä½†æœªä¸Šä¼ å®¡æ ¸æ ‡å‡†")

            from src.contract_review.standard_parser import parse_standard_file
            standard_set = parse_standard_file(std_path)
            review_standards = standard_set.standards
            logger.info(f"å·²åŠ è½½ {len(review_standards)} æ¡å®¡æ ¸æ ‡å‡†")

        # è·å–ä¸šåŠ¡ä¸Šä¸‹æ–‡ï¼ˆå¦‚æœæŒ‡å®šäº†ä¸šåŠ¡æ¡çº¿ï¼‰
        business_context = None
        if business_line_id:
            business_line = business_library_manager.get_business_line(business_line_id)
            if business_line:
                business_context = {
                    "business_line_id": business_line.id,
                    "business_line_name": business_line.name,
                    "name": business_line.name,
                    "industry": business_line.industry,
                    "contexts": business_line.contexts,
                }
                logger.info(f"ä½¿ç”¨ä¸šåŠ¡æ¡çº¿: {business_line.name}")

        # è¿›åº¦å›è°ƒ
        def progress_callback(stage: str, percentage: int, message: str):
            task.update_progress(stage, percentage, message)
            task_manager.update_task(task)

        # åˆ›å»ºäº¤äº’å®¡é˜…å¼•æ“å¹¶æ‰§è¡Œç»Ÿä¸€å®¡é˜…
        # æ³¨æ„ï¼šskip_modifications=True è¡¨ç¤ºåˆå®¡åªç”Ÿæˆé£é™©åˆ†æï¼Œä¸ç”Ÿæˆä¿®æ”¹å»ºè®®
        # ç”¨æˆ·éœ€è¦åœ¨äº¤äº’ç•Œé¢è®¨è®ºåï¼Œç‚¹å‡»"ç¡®è®¤é£é™©"æ‰ä¼šç”Ÿæˆä¿®æ”¹å»ºè®®
        engine = InteractiveReviewEngine(settings, llm_provider=llm_provider)
        result = await engine.unified_review(
            document=document,
            our_party=task.our_party,
            material_type=task.material_type,
            task_id=task_id,
            language=getattr(task, 'language', 'zh-CN'),
            review_standards=review_standards,
            business_context=business_context,
            special_requirements=special_requirements,
            skip_modifications=True,  # é»˜è®¤è·³è¿‡ä¿®æ”¹å»ºè®®ï¼Œå¾…ç”¨æˆ·ç¡®è®¤åå†ç”Ÿæˆ
            progress_callback=progress_callback,
        )

        # ==================== å¢é‡ä¿å­˜ä¼˜åŒ– ====================
        # ç›®çš„ï¼šè®©ç”¨æˆ·åœ¨ LLM è¿”å›åç«‹å³è¿›å…¥è®¨è®ºç•Œé¢ï¼Œæ— éœ€ç­‰å¾…æ‰€æœ‰é£é™©ç‚¹å¤„ç†å®Œæ¯•
        # æµç¨‹ï¼š
        # 1. ç«‹å³ä¿å­˜ç¬¬ä¸€æ¡é£é™© â†’ çŠ¶æ€æ”¹ä¸º partial_ready â†’ ç”¨æˆ·å¯ä»¥è·³è½¬
        # 2. åå°é€æ¡è¿½åŠ å‰©ä½™é£é™©
        # 3. å…¨éƒ¨å®Œæˆ â†’ çŠ¶æ€æ”¹ä¸º completed

        interactive_manager = get_interactive_manager()
        total_risks = len(result.risks)

        if total_risks > 0:
            # === é˜¶æ®µ1ï¼šç«‹å³å¤„ç†ç¬¬ä¸€æ¡é£é™© ===
            first_risk = result.risks[0]
            first_risk_data = {
                "id": first_risk.id,
                "risk_level": first_risk.risk_level,
                "risk_type": first_risk.risk_type,
                "description": first_risk.description,
                "analysis": first_risk.analysis,
                "reason": first_risk.reason,
                "original_text": first_risk.location.original_text if first_risk.location else "",
            }

            # åˆ›å»ºåªåŒ…å«ç¬¬ä¸€æ¡é£é™©çš„åˆå§‹ç»“æœ
            from src.contract_review.models import ReviewResult, ReviewSummary
            initial_result = ReviewResult(
                task_id=task_id,
                document_name=result.document_name,
                document_path=result.document_path,
                material_type=result.material_type,
                our_party=result.our_party,
                review_standards_used=result.review_standards_used,
                language=result.language,
                business_line_id=result.business_line_id,
                business_line_name=result.business_line_name,
                risks=[first_risk],  # åªåŒ…å«ç¬¬ä¸€æ¡
                modifications=[],
                actions=[],
                reviewed_at=result.reviewed_at,
                llm_model=result.llm_model,
                prompt_version=result.prompt_version,
            )
            initial_result.calculate_summary()

            # ä¿å­˜åˆå§‹ç»“æœ
            storage_manager.save_result(initial_result)

            # ä¸ºç¬¬ä¸€æ¡é£é™©åˆ›å»ºå¯¹è¯è®°å½•
            interactive_manager.initialize_single_chat(task_id, first_risk_data)

            # æ›´æ–°çŠ¶æ€ä¸º partial_readyï¼ˆå‰ç«¯å¯ä»¥è·³è½¬äº†ï¼‰
            task.result = initial_result
            task.update_status("partial_ready", f"ç¬¬1æ¡é£é™©ç‚¹å·²å°±ç»ªï¼ˆå…±{total_risks}æ¡ï¼‰")
            task_manager.update_task(task)
            logger.info(f"ä»»åŠ¡ {task_id} ç¬¬1æ¡é£é™©ç‚¹å·²å°±ç»ªï¼ŒçŠ¶æ€æ›´æ–°ä¸º partial_ready")

            # === é˜¶æ®µ2ï¼šåå°é€æ¡è¿½åŠ å‰©ä½™é£é™© ===
            for i, risk in enumerate(result.risks[1:], start=2):
                risk_data = {
                    "id": risk.id,
                    "risk_level": risk.risk_level,
                    "risk_type": risk.risk_type,
                    "description": risk.description,
                    "analysis": risk.analysis,
                    "reason": risk.reason,
                    "original_text": risk.location.original_text if risk.location else "",
                }

                # è¿½åŠ é£é™©åˆ°ç»“æœ
                storage_manager.append_risk_to_result(task_id, risk_data)

                # ä¸ºè¯¥é£é™©åˆ›å»ºå¯¹è¯è®°å½•
                interactive_manager.initialize_single_chat(task_id, risk_data)

                # æ›´æ–°è¿›åº¦ï¼ˆä¿æŒ partial_ready çŠ¶æ€ï¼‰
                task.update_progress("partial_ready", 95, f"å·²å¤„ç† {i}/{total_risks} æ¡é£é™©ç‚¹")
                task_manager.update_task(task)
                logger.debug(f"ä»»åŠ¡ {task_id} è¿½åŠ ç¬¬ {i} æ¡é£é™©ç‚¹")

            # === é˜¶æ®µ3ï¼šå¤„ç†è¡ŒåŠ¨å»ºè®®å¹¶å®Œæˆ ===
            # æ‰¹é‡æ·»åŠ è¡ŒåŠ¨å»ºè®®ï¼ˆä¸éœ€è¦å¢é‡ï¼‰
            actions_data = [
                {
                    "id": action.id,
                    "action_type": action.action_type,
                    "description": action.description,
                    "urgency": action.urgency,
                }
                for action in result.actions
            ]
            if actions_data:
                interactive_manager.initialize_chats_for_task(
                    task_id=task_id,
                    risks=None,  # é£é™©å·²ç»å•ç‹¬å¤„ç†
                    actions=actions_data,
                )

        else:
            # æ²¡æœ‰é£é™©ç‚¹çš„æƒ…å†µï¼ˆè¾¹ç•Œæƒ…å†µï¼‰
            storage_manager.save_result(result)

        # é‡æ–°åŠ è½½å®Œæ•´ç»“æœå¹¶æ›´æ–°ä»»åŠ¡
        final_result = storage_manager.load_result(task_id)
        task.result = final_result
        task.update_status("completed", "å®¡é˜…å®Œæˆ")
        task_manager.update_task(task)

        # æ‰£é™¤é…é¢
        quota_service = get_quota_service()
        await quota_service.deduct_quota(user_id, task_id=task_id)

        logger.info(f"ä»»åŠ¡ {task_id} ç»Ÿä¸€å®¡é˜…å®Œæˆï¼Œå‘ç° {len(result.risks)} ä¸ªé£é™©ç‚¹")

    except Exception as e:
        logger.error(f"ä»»åŠ¡ {task_id} ç»Ÿä¸€å®¡é˜…å¤±è´¥: {e}")
        task.update_status("failed", str(e))
        task_manager.update_task(task)


@app.post("/api/tasks/{task_id}/unified-review")
async def start_unified_review(
    task_id: str,
    request: UnifiedReviewRequest,
    background_tasks: BackgroundTasks,
    user_id: str = Depends(get_current_user),
):
    """
    å¯åŠ¨ç»Ÿä¸€å®¡é˜…ï¼ˆæ”¯æŒå¯é€‰æ ‡å‡†ï¼‰

    è¿™æ˜¯æ–°çš„ç»Ÿä¸€å®¡é˜…å…¥å£ï¼Œæ”¯æŒä¸¤ç§æ¨¡å¼ï¼š
    - use_standards=Falseï¼ˆé»˜è®¤ï¼‰: AI è‡ªä¸»å®¡é˜…ï¼Œæ— éœ€ä¸Šä¼ å®¡æ ¸æ ‡å‡†
    - use_standards=True: åŸºäºå·²ä¸Šä¼ çš„å®¡æ ¸æ ‡å‡†è¿›è¡Œå®¡é˜…

    æ— è®ºå“ªç§æ¨¡å¼ï¼Œå®¡é˜…å®Œæˆåéƒ½ä¼šè¿›å…¥äº¤äº’å¼ç»“æœé¡µé¢ï¼Œæ”¯æŒé€æ¡å¯¹è¯æ‰“ç£¨ã€‚
    """
    # æ£€æŸ¥é…é¢
    quota_service = get_quota_service()
    try:
        await quota_service.check_quota(user_id)
    except Exception as e:
        raise HTTPException(status_code=402, detail=str(e))

    # éªŒè¯ä»»åŠ¡
    task = task_manager.get_task(task_id)
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")

    if task.status == "reviewing":
        raise HTTPException(status_code=400, detail="ä»»åŠ¡æ­£åœ¨å®¡é˜…ä¸­")

    if not task.document_filename:
        raise HTTPException(status_code=400, detail="è¯·å…ˆä¸Šä¼ å¾…å®¡é˜…æ–‡æ¡£")

    # å¦‚æœä½¿ç”¨æ ‡å‡†æ¨¡å¼ï¼Œæ£€æŸ¥æ˜¯å¦å·²ä¸Šä¼ æ ‡å‡†
    if request.use_standards and not task.standard_filename:
        raise HTTPException(status_code=400, detail="ä½¿ç”¨æ ‡å‡†æ¨¡å¼éœ€è¦å…ˆä¸Šä¼ å®¡æ ¸æ ‡å‡†")

    # éªŒè¯ä¸šåŠ¡æ¡çº¿ï¼ˆå¦‚æœæä¾›äº†ï¼‰
    if request.business_line_id:
        business_line = business_library_manager.get_business_line(request.business_line_id)
        if not business_line:
            raise HTTPException(status_code=400, detail="æŒ‡å®šçš„ä¸šåŠ¡æ¡çº¿ä¸å­˜åœ¨")
        logger.info(f"ä»»åŠ¡ {task_id} å°†ä½¿ç”¨ä¸šåŠ¡æ¡çº¿: {business_line.name}")

    # è®¾ç½®å®¡é˜…æ¨¡å¼
    task.review_mode = "interactive"
    task.update_status("reviewing", "æ­£åœ¨å¯åŠ¨å®¡é˜…...")
    task.update_progress("analyzing", 0, "æ­£åœ¨å¯åŠ¨...")
    task_manager.update_task(task)

    # å¯åŠ¨åå°ä»»åŠ¡
    background_tasks.add_task(
        run_unified_review,
        task_id,
        user_id,
        request.llm_provider,
        request.use_standards,
        request.business_line_id,
        request.special_requirements,
    )

    return {
        "message": "å®¡é˜…å·²å¯åŠ¨",
        "task_id": task_id,
        "mode": "with_standards" if request.use_standards else "ai_autonomous"
    }


# ==================== æµå¼å®¡é˜… SSE ç«¯ç‚¹ ====================


async def stream_review_generator(
    task_id: str,
    user_id: str,
    llm_provider: str = "deepseek",
    use_standards: bool = False,
    business_line_id: Optional[str] = None,
    special_requirements: Optional[str] = None,
):
    """
    æµå¼å®¡é˜…äº‹ä»¶ç”Ÿæˆå™¨

    äº§å‡º SSE æ ¼å¼çš„äº‹ä»¶:
    - event: start
    - event: risk (æ¯ä¸ªé£é™©ç‚¹)
    - event: progress
    - event: complete
    - event: error
    """
    import json as json_module

    task = task_manager.get_task(task_id)
    if not task:
        yield f"event: error\ndata: {json_module.dumps({'message': 'ä»»åŠ¡ä¸å­˜åœ¨'})}\n\n"
        return

    try:
        # æ›´æ–°çŠ¶æ€ä¸ºå®¡é˜…ä¸­
        if use_standards:
            task.update_status("reviewing", "æ­£åœ¨åŸºäºå®¡æ ¸æ ‡å‡†è¿›è¡Œæµå¼å®¡é˜…...")
        else:
            task.update_status("reviewing", "æ­£åœ¨è¿›è¡Œ AI æµå¼å®¡é˜…...")
        task.review_mode = "interactive"
        task_manager.update_task(task)

        # è·å–æ–‡æ¡£è·¯å¾„
        doc_path = task_manager.get_document_path(task_id, user_id)
        if not doc_path or not doc_path.exists():
            yield f"event: error\ndata: {json_module.dumps({'message': 'æ–‡æ¡£æœªä¸Šä¼ æˆ–æ— æ³•ä¸‹è½½'})}\n\n"
            task.update_status("failed", "æ–‡æ¡£æœªä¸Šä¼ æˆ–æ— æ³•ä¸‹è½½")
            task_manager.update_task(task)
            return

        # åŠ è½½æ–‡æ¡£
        ocr_service = get_ocr_service()
        document = await load_document_async(doc_path, ocr_service=ocr_service)

        # åŠ è½½å®¡æ ¸æ ‡å‡†ï¼ˆå¦‚æœéœ€è¦ï¼‰
        review_standards = None
        if use_standards:
            std_path = task_manager.get_standard_path(task_id, user_id)
            if not std_path or not std_path.exists():
                yield f"event: error\ndata: {json_module.dumps({'message': 'ä½¿ç”¨æ ‡å‡†æ¨¡å¼ä½†æœªä¸Šä¼ å®¡æ ¸æ ‡å‡†'})}\n\n"
                task.update_status("failed", "ä½¿ç”¨æ ‡å‡†æ¨¡å¼ä½†æœªä¸Šä¼ å®¡æ ¸æ ‡å‡†")
                task_manager.update_task(task)
                return

            from src.contract_review.standard_parser import parse_standard_file
            standard_set = parse_standard_file(std_path)
            review_standards = standard_set.standards
            logger.info(f"æµå¼å®¡é˜…ï¼šå·²åŠ è½½ {len(review_standards)} æ¡å®¡æ ¸æ ‡å‡†")

        # è·å–ä¸šåŠ¡ä¸Šä¸‹æ–‡
        business_context = None
        if business_line_id:
            business_line = business_library_manager.get_business_line(business_line_id)
            if business_line:
                business_context = {
                    "business_line_id": business_line.id,
                    "business_line_name": business_line.name,
                    "name": business_line.name,
                    "industry": business_line.industry,
                    "contexts": business_line.contexts,
                }

        # åˆ›å»ºäº¤äº’å®¡é˜…å¼•æ“
        engine = InteractiveReviewEngine(settings, llm_provider=llm_provider)
        interactive_manager = get_interactive_manager()

        # ç”¨äºæ”¶é›†æ‰€æœ‰é£é™©
        all_risks = []
        all_actions = []
        final_summary = {}

        # è°ƒç”¨æµå¼å®¡é˜…
        async for event in engine.unified_review_stream(
            document=document,
            our_party=task.our_party,
            material_type=task.material_type,
            task_id=task_id,
            language=getattr(task, 'language', 'zh-CN'),
            review_standards=review_standards,
            business_context=business_context,
            special_requirements=special_requirements,
        ):
            event_type = event.get("event")

            if event_type == "start":
                yield f"event: start\ndata: {json_module.dumps({'task_id': task_id})}\n\n"

            elif event_type == "progress":
                yield f"event: progress\ndata: {json_module.dumps(event)}\n\n"
                task.update_progress("reviewing", event.get("percentage", 0), event.get("message", ""))
                task_manager.update_task(task)

            elif event_type == "risk":
                risk_data = event.get("data", {})
                risk_index = event.get("index", 0)
                all_risks.append(risk_data)

                # ç«‹å³ä¿å­˜é£é™©å¹¶åˆ›å»ºå¯¹è¯è®°å½•
                if risk_index == 0:
                    # ç¬¬ä¸€æ¡é£é™©ï¼šåˆ›å»ºåˆå§‹ç»“æœå¹¶æ›´æ–°çŠ¶æ€ä¸º partial_ready
                    from src.contract_review.models import ReviewResult, RiskPoint, TextLocation

                    # åˆ›å»º RiskPoint å¯¹è±¡
                    risk_point = RiskPoint(
                        id=risk_data.get("id"),
                        risk_level=risk_data.get("risk_level", "medium"),
                        risk_type=risk_data.get("risk_type", "æœªåˆ†ç±»"),
                        description=risk_data.get("description", ""),
                        analysis=risk_data.get("analysis", ""),
                        reason=risk_data.get("reason", ""),
                        location=TextLocation(
                            original_text=risk_data.get("original_text", ""),
                            context="",
                        ) if risk_data.get("original_text") else None,
                    )

                    initial_result = ReviewResult(
                        task_id=task_id,
                        document_name=document.path.name,
                        document_path=str(doc_path),
                        material_type=task.material_type,
                        our_party=task.our_party,
                        review_standards_used="",
                        language=getattr(task, 'language', 'zh-CN'),
                        business_line_id=business_line_id,
                        business_line_name=business_context.get("name") if business_context else None,
                        risks=[risk_point],
                        modifications=[],
                        actions=[],
                        llm_model=llm_provider,
                        prompt_version="unified_stream_v1",
                    )
                    initial_result.calculate_summary()
                    storage_manager.save_result(initial_result)

                    # åˆ›å»ºç¬¬ä¸€æ¡é£é™©çš„å¯¹è¯è®°å½•
                    interactive_manager.initialize_single_chat(task_id, risk_data)

                    # æ›´æ–°çŠ¶æ€ä¸º partial_ready
                    task.result = initial_result
                    task.update_status("partial_ready", "ç¬¬1æ¡é£é™©ç‚¹å·²å°±ç»ª")
                    task_manager.update_task(task)
                    logger.info(f"æµå¼å®¡é˜…ï¼šä»»åŠ¡ {task_id} ç¬¬1æ¡é£é™©ç‚¹å·²å°±ç»ª")
                else:
                    # åç»­é£é™©ï¼šè¿½åŠ ä¿å­˜
                    storage_manager.append_risk_to_result(task_id, risk_data)
                    interactive_manager.initialize_single_chat(task_id, risk_data)
                    logger.debug(f"æµå¼å®¡é˜…ï¼šä»»åŠ¡ {task_id} è¿½åŠ ç¬¬ {risk_index + 1} æ¡é£é™©ç‚¹")

                # å‘é€é£é™©äº‹ä»¶åˆ°å‰ç«¯
                yield f"event: risk\ndata: {json_module.dumps({'data': risk_data, 'index': risk_index})}\n\n"

            elif event_type == "complete":
                final_summary = event.get("summary", {})
                all_actions = event.get("actions", [])

                # ä¿å­˜è¡ŒåŠ¨å»ºè®®
                if all_actions:
                    interactive_manager.initialize_chats_for_task(
                        task_id=task_id,
                        risks=None,
                        actions=all_actions,
                    )

                # æ›´æ–°æœ€ç»ˆç»“æœ
                final_result = storage_manager.load_result(task_id)
                if final_result:
                    task.result = final_result
                task.update_status("completed", "å®¡é˜…å®Œæˆ")
                task_manager.update_task(task)

                # æ‰£é™¤é…é¢
                quota_service = get_quota_service()
                await quota_service.deduct_quota(user_id, task_id=task_id)

                logger.info(f"æµå¼å®¡é˜…ï¼šä»»åŠ¡ {task_id} å®Œæˆï¼Œå‘ç° {len(all_risks)} ä¸ªé£é™©ç‚¹")

                yield f"event: complete\ndata: {json_module.dumps({'summary': final_summary, 'actions': all_actions, 'total_risks': len(all_risks)})}\n\n"

            elif event_type == "error":
                error_msg = event.get("message", "æœªçŸ¥é”™è¯¯")
                task.update_status("failed", error_msg)
                task_manager.update_task(task)
                yield f"event: error\ndata: {json_module.dumps({'message': error_msg})}\n\n"

    except Exception as e:
        logger.error(f"æµå¼å®¡é˜…å¤±è´¥: {e}", exc_info=True)
        task.update_status("failed", str(e))
        task_manager.update_task(task)
        yield f"event: error\ndata: {json_module.dumps({'message': str(e)})}\n\n"


@app.post("/api/tasks/{task_id}/unified-review-stream")
async def start_unified_review_stream(
    task_id: str,
    request: UnifiedReviewRequest,
    user_id: str = Depends(get_current_user),
):
    """
    å¯åŠ¨æµå¼ç»Ÿä¸€å®¡é˜…ï¼ˆSSEï¼‰

    ä¸ unified-review ä¸åŒï¼Œæ­¤ç«¯ç‚¹è¿”å› SSE æµï¼Œå®æ—¶æ¨é€å®¡é˜…è¿›åº¦å’Œé£é™©ç‚¹ã€‚
    å‰ç«¯å¯ä»¥åœ¨å®¡é˜…è¿‡ç¨‹ä¸­å°±å¼€å§‹æ˜¾ç¤ºå·²è¯†åˆ«çš„é£é™©ã€‚

    äº‹ä»¶ç±»å‹:
    - start: å®¡é˜…å¼€å§‹ {"task_id": "..."}
    - progress: è¿›åº¦æ›´æ–° {"percentage": 20, "message": "..."}
    - risk: æ–°é£é™©ç‚¹ {"data": {...}, "index": 0}
    - complete: å®¡é˜…å®Œæˆ {"summary": {...}, "actions": [...], "total_risks": 5}
    - error: é”™è¯¯ {"message": "..."}
    """
    # æ£€æŸ¥é…é¢
    quota_service = get_quota_service()
    try:
        await quota_service.check_quota(user_id)
    except Exception as e:
        raise HTTPException(status_code=402, detail=str(e))

    # éªŒè¯ä»»åŠ¡
    task = task_manager.get_task(task_id)
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")

    if task.status == "reviewing":
        raise HTTPException(status_code=400, detail="ä»»åŠ¡æ­£åœ¨å®¡é˜…ä¸­")

    if not task.document_filename:
        raise HTTPException(status_code=400, detail="è¯·å…ˆä¸Šä¼ å¾…å®¡é˜…æ–‡æ¡£")

    # å¦‚æœä½¿ç”¨æ ‡å‡†æ¨¡å¼ï¼Œæ£€æŸ¥æ˜¯å¦å·²ä¸Šä¼ æ ‡å‡†
    if request.use_standards and not task.standard_filename:
        raise HTTPException(status_code=400, detail="ä½¿ç”¨æ ‡å‡†æ¨¡å¼éœ€è¦å…ˆä¸Šä¼ å®¡æ ¸æ ‡å‡†")

    # éªŒè¯ä¸šåŠ¡æ¡çº¿
    if request.business_line_id:
        business_line = business_library_manager.get_business_line(request.business_line_id)
        if not business_line:
            raise HTTPException(status_code=400, detail="æŒ‡å®šçš„ä¸šåŠ¡æ¡çº¿ä¸å­˜åœ¨")

    # è¿”å› SSE æµ
    return StreamingResponse(
        stream_review_generator(
            task_id=task_id,
            user_id=user_id,
            llm_provider=request.llm_provider,
            use_standards=request.use_standards,
            business_line_id=request.business_line_id,
            special_requirements=request.special_requirements,
        ),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no",  # ç¦ç”¨ nginx ç¼“å†²
        },
    )


async def run_quick_review(
    task_id: str,
    user_id: str,
    llm_provider: str = "deepseek",
):
    """åå°æ‰§è¡Œå¿«é€Ÿåˆå®¡ä»»åŠ¡"""
    task = task_manager.get_task(task_id)
    if not task:
        logger.error(f"ä»»åŠ¡ä¸å­˜åœ¨: {task_id}")
        return

    try:
        # æ›´æ–°çŠ¶æ€
        task.update_status("reviewing", "æ­£åœ¨è¿›è¡Œå¿«é€Ÿåˆå®¡...")
        task.review_mode = "interactive"
        task_manager.update_task(task)

        # è·å–æ–‡æ¡£è·¯å¾„ï¼ˆtask_manager ä¼šä» Supabase Storage ä¸‹è½½åˆ°æœ¬åœ°ä¸´æ—¶ç›®å½•ï¼‰
        doc_path = task_manager.get_document_path(task_id, user_id)
        if not doc_path or not doc_path.exists():
            raise ValueError("æ–‡æ¡£æœªä¸Šä¼ æˆ–æ— æ³•ä¸‹è½½")

        # åŠ è½½æ–‡æ¡£
        ocr_service = get_ocr_service()
        document = await load_document_async(doc_path, ocr_service=ocr_service)

        # è¿›åº¦å›è°ƒ
        def progress_callback(stage: str, percentage: int, message: str):
            task.update_progress(stage, percentage, message)
            task_manager.update_task(task)

        # åˆ›å»ºäº¤äº’å®¡é˜…å¼•æ“
        engine = InteractiveReviewEngine(settings, llm_provider=llm_provider)

        # æ‰§è¡Œå¿«é€Ÿåˆå®¡
        result = await engine.quick_review(
            document=document,
            our_party=task.our_party,
            material_type=task.material_type,
            task_id=task_id,
            language=getattr(task, 'language', 'zh-CN'),
            progress_callback=progress_callback,
        )

        # ä¿å­˜ç»“æœ
        storage_manager.save_result(result)

        # ä¸ºæ‰€æœ‰æ¡ç›®åˆ›å»ºå¯¹è¯è®°å½•
        interactive_manager = get_interactive_manager()
        modifications_data = [
            {
                "id": mod.id,
                "original_text": mod.original_text,
                "suggested_text": mod.suggested_text,
                "modification_reason": mod.modification_reason,
                "priority": mod.priority,
            }
            for mod in result.modifications
        ]
        actions_data = [
            {
                "id": action.id,
                "action_type": action.action_type,
                "description": action.description,
                "urgency": action.urgency,
            }
            for action in result.actions
        ]
        interactive_manager.initialize_chats_for_task(
            task_id=task_id,
            modifications=modifications_data,
            actions=actions_data,
        )

        # æ›´æ–°ä»»åŠ¡
        task.result = result
        task.update_status("completed", "å¿«é€Ÿåˆå®¡å®Œæˆ")
        task_manager.update_task(task)

        # æ‰£é™¤é…é¢
        quota_service = get_quota_service()
        await quota_service.deduct_quota(user_id, task_id=task_id)

        logger.info(f"ä»»åŠ¡ {task_id} å¿«é€Ÿåˆå®¡å®Œæˆ")

    except Exception as e:
        logger.error(f"ä»»åŠ¡ {task_id} å¿«é€Ÿåˆå®¡å¤±è´¥: {e}")
        task.update_status("failed", str(e))
        task_manager.update_task(task)


@app.post("/api/tasks/{task_id}/quick-review")
async def start_quick_review(
    task_id: str,
    request: QuickReviewRequest,
    background_tasks: BackgroundTasks,
    user_id: str = Depends(get_current_user),
):
    """
    å¯åŠ¨å¿«é€Ÿåˆå®¡ï¼ˆæ·±åº¦äº¤äº’æ¨¡å¼ï¼‰

    æ— éœ€é¢„è®¾å®¡æ ¸æ ‡å‡†ï¼ŒAI è‡ªä¸»å‘ç°é—®é¢˜ã€‚
    """
    # æ£€æŸ¥é…é¢
    quota_service = get_quota_service()
    try:
        await quota_service.check_quota(user_id)
    except Exception as e:
        raise HTTPException(status_code=402, detail=str(e))

    # éªŒè¯ä»»åŠ¡
    task = task_manager.get_task(task_id)
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")

    if task.status == "reviewing":
        raise HTTPException(status_code=400, detail="ä»»åŠ¡æ­£åœ¨å®¡é˜…ä¸­")

    if not task.document_filename:
        raise HTTPException(status_code=400, detail="è¯·å…ˆä¸Šä¼ å¾…å®¡é˜…æ–‡æ¡£")

    # è®¾ç½®å®¡é˜…æ¨¡å¼
    task.review_mode = "interactive"
    task.update_status("reviewing", "æ­£åœ¨å¯åŠ¨å¿«é€Ÿåˆå®¡...")
    task.update_progress("analyzing", 0, "æ­£åœ¨å¯åŠ¨...")
    task_manager.update_task(task)

    # å¯åŠ¨åå°ä»»åŠ¡
    background_tasks.add_task(
        run_quick_review,
        task_id,
        user_id,
        request.llm_provider,
    )

    return {"message": "å¿«é€Ÿåˆå®¡å·²å¯åŠ¨", "task_id": task_id}


@app.get("/api/interactive/{task_id}/items", response_model=InteractiveItemsResponse)
async def get_interactive_items(
    task_id: str,
    user_id: str = Depends(get_current_user),
):
    """è·å–ä»»åŠ¡çš„æ‰€æœ‰äº¤äº’æ¡ç›®åŠå¯¹è¯çŠ¶æ€

    æ”¹é€ åï¼šåŸºäº risksï¼ˆé£é™©ç‚¹ï¼‰æ„å»ºæ¡ç›®ï¼Œè€Œé modificationsï¼ˆä¿®æ”¹å»ºè®®ï¼‰
    """
    # éªŒè¯ä»»åŠ¡
    task = task_manager.get_task(task_id)
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")

    # è·å–å®¡é˜…ç»“æœ
    result = storage_manager.load_result(task_id)
    if not result:
        raise HTTPException(status_code=404, detail="å®¡é˜…ç»“æœä¸å­˜åœ¨")

    # è·å–å¯¹è¯è®°å½•
    interactive_manager = get_interactive_manager()
    chats = interactive_manager.get_chats_by_task(task_id)
    chat_map = {chat.item_id: chat for chat in chats}

    # æ„å»º risk_id -> modification çš„æ˜ å°„
    mod_map = {}
    for mod in result.modifications:
        if mod.risk_id:
            mod_map[mod.risk_id] = mod

    # æ„å»ºå“åº”ï¼ˆåŸºäºé£é™©ç‚¹ï¼‰
    items = []

    for risk in result.risks:
        chat = chat_map.get(risk.id)
        modification = mod_map.get(risk.id)

        # è·å–åŸæ–‡
        original_text = ""
        if risk.location and risk.location.original_text:
            original_text = risk.location.original_text
        elif hasattr(risk, 'original_text') and risk.original_text:
            original_text = risk.original_text

        items.append(InteractiveItemResponse(
            id=chat.id if chat else f"temp_{risk.id}",
            item_id=risk.id,
            item_type="risk",
            risk_level=risk.risk_level,
            risk_type=risk.risk_type,
            description=risk.description,
            analysis=risk.analysis,
            original_text=original_text,
            reason=risk.reason,
            # ä¿®æ”¹å»ºè®®ï¼ˆå¦‚æœå·²ç”Ÿæˆï¼‰
            has_modification=modification is not None,
            modification_id=modification.id if modification else None,
            suggested_text=modification.suggested_text if modification else None,
            modification_reason=modification.modification_reason if modification else None,
            is_addition=modification.is_addition if modification else False,
            insertion_point=modification.insertion_point if modification else None,
            # å¯¹è¯çŠ¶æ€
            chat_status=chat.status if chat else "pending",
            message_count=len(chat.messages) if chat else 0,
            last_updated=chat.updated_at.isoformat() if chat else None,
            # è·³è¿‡çŠ¶æ€ï¼ˆä» chat å…ƒæ•°æ®è·å–ï¼‰
            is_skipped=getattr(chat, 'is_skipped', False) if chat else False,
            # æ˜¯å¦ä¸ºç¼ºå¤±æ¡æ¬¾ç±»å‹ï¼ˆæ²¡æœ‰åŸæ–‡ï¼‰
            is_missing_clause=not original_text,
        ))

    # è·å–ç»Ÿè®¡
    summary = interactive_manager.get_task_chat_summary(task_id)

    return InteractiveItemsResponse(
        task_id=task_id,
        items=items,
        summary=summary,
    )


@app.get("/api/interactive/{task_id}/items/{item_id}")
async def get_interactive_item_detail(
    task_id: str,
    item_id: str,
    user_id: str = Depends(get_current_user),
):
    """è·å–å•ä¸ªæ¡ç›®çš„è¯¦ç»†ä¿¡æ¯å’Œå¯¹è¯å†å²

    æ”¹é€ åï¼šitem_id æ˜¯ risk.idï¼ŒåŸºäºé£é™©ç‚¹æŸ¥æ‰¾
    """
    # éªŒè¯ä»»åŠ¡
    task = task_manager.get_task(task_id)
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")

    # è·å–å®¡é˜…ç»“æœ
    result = storage_manager.load_result(task_id)
    if not result:
        raise HTTPException(status_code=404, detail="å®¡é˜…ç»“æœä¸å­˜åœ¨")

    # æŸ¥æ‰¾é£é™©ç‚¹ï¼ˆitem_id ç°åœ¨æ˜¯ risk.idï¼‰
    risk = None
    for r in result.risks:
        if r.id == item_id:
            risk = r
            break

    if not risk:
        raise HTTPException(status_code=404, detail="æ¡ç›®ä¸å­˜åœ¨")

    # æŸ¥æ‰¾å…³è”çš„ä¿®æ”¹å»ºè®®ï¼ˆå¦‚æœæœ‰ï¼‰
    modification = None
    for mod in result.modifications:
        if mod.risk_id == risk.id:
            modification = mod
            break

    # è·å–å¯¹è¯è®°å½•
    interactive_manager = get_interactive_manager()
    chat = interactive_manager.get_chat_by_item(task_id, item_id)

    # è·å–åŸæ–‡
    original_text = ""
    if risk.location and risk.location.original_text:
        original_text = risk.location.original_text

    return {
        "task_id": task_id,
        "item_id": item_id,
        "item_type": "risk",
        # é£é™©ä¿¡æ¯
        "risk_level": risk.risk_level,
        "risk_type": risk.risk_type,
        "description": risk.description,
        "analysis": risk.analysis,
        "reason": risk.reason,
        "original_text": original_text,
        # ä¿®æ”¹å»ºè®®ï¼ˆå¦‚æœå·²ç”Ÿæˆï¼‰
        "has_modification": modification is not None,
        "modification": {
            "id": modification.id,
            "suggested_text": modification.suggested_text,
            "modification_reason": modification.modification_reason,
            "priority": modification.priority,
        } if modification else None,
        "current_suggestion": (
            chat.current_suggestion if chat
            else (modification.suggested_text if modification else None)
        ),
        # å¯¹è¯è®°å½•
        "status": chat.status if chat else "pending",
        "messages": [
            {
                "role": msg.role,
                "content": msg.content,
                "timestamp": msg.timestamp.isoformat() if msg.timestamp else None,
                "suggestion_snapshot": msg.suggestion_snapshot,
            }
            for msg in (chat.messages if chat else [])
        ],
        # è·³è¿‡çŠ¶æ€
        "is_skipped": getattr(chat, 'is_skipped', False) if chat else False,
    }


@app.post("/api/interactive/{task_id}/items/{item_id}/chat", response_model=ChatResponse)
async def chat_with_item(
    task_id: str,
    item_id: str,
    request: ChatRequest,
    user_id: str = Depends(get_current_user),
):
    """ä¸ç‰¹å®šæ¡ç›®è¿›è¡Œå¯¹è¯ï¼Œæ‰“ç£¨ä¿®æ”¹å»ºè®®"""
    # éªŒè¯ä»»åŠ¡
    task = task_manager.get_task(task_id)
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")

    # è·å–å®¡é˜…ç»“æœ
    result = storage_manager.load_result(task_id)
    if not result:
        raise HTTPException(status_code=404, detail="å®¡é˜…ç»“æœä¸å­˜åœ¨")

    # æŸ¥æ‰¾æ¡ç›® - æ”¯æŒ risk_id æˆ– modification_id
    modification = None
    risk = None
    original_text = ""

    # é¦–å…ˆæ£€æŸ¥æ˜¯å¦æ˜¯ risk_id
    for r in result.risks:
        if r.id == item_id:
            risk = r
            # è·å–åŸæ–‡
            if risk.location and risk.location.original_text:
                original_text = risk.location.original_text
            elif hasattr(risk, 'original_text') and risk.original_text:
                original_text = risk.original_text
            # æŸ¥æ‰¾å¯¹åº”çš„ modification
            for mod in result.modifications:
                if mod.risk_id == risk.id:
                    modification = mod
                    break
            break

    # å¦‚æœä¸æ˜¯ risk_idï¼Œå°è¯•ä½œä¸º modification_id æŸ¥æ‰¾
    if not risk:
        for mod in result.modifications:
            if mod.id == item_id:
                modification = mod
                original_text = mod.original_text or ""
                for r in result.risks:
                    if r.id == mod.risk_id:
                        risk = r
                        break
                break

    if not risk:
        raise HTTPException(status_code=404, detail="æ¡ç›®ä¸å­˜åœ¨")

    # è·å–æˆ–åˆ›å»ºå¯¹è¯è®°å½•
    interactive_manager = get_interactive_manager()
    chat = interactive_manager.get_chat_by_item(task_id, item_id)

    if not chat:
        # åˆ›å»ºæ–°çš„å¯¹è¯è®°å½•
        chat = interactive_manager.create_chat(
            task_id=task_id,
            item_id=item_id,
            item_type="risk",
            initial_suggestion=modification.suggested_text if modification else "",
        )

    # å‡†å¤‡å¯¹è¯å†å²
    chat_history = [
        {"role": msg.role, "content": msg.content}
        for msg in chat.messages
    ]

    # åˆ›å»ºå¼•æ“å¹¶è°ƒç”¨
    engine = InteractiveReviewEngine(settings, llm_provider=request.llm_provider)

    try:
        response = await engine.refine_item(
            original_clause=modification.original_text,
            current_suggestion=chat.current_suggestion or modification.suggested_text,
            risk_description=risk.description if risk else modification.modification_reason,
            user_message=request.message,
            chat_history=chat_history,
            document_summary="",  # TODO: å¯ä»¥æ·»åŠ æ–‡æ¡£æ‘˜è¦
            language=getattr(task, 'language', 'zh-CN'),
        )
    except Exception as e:
        logger.error(f"å¯¹è¯å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"å¯¹è¯å¤±è´¥: {str(e)}")

    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
    interactive_manager.add_message(
        chat_id=chat.id,
        role="user",
        content=request.message,
    )

    # æ·»åŠ  AI å›å¤
    updated_chat = interactive_manager.add_message(
        chat_id=chat.id,
        role="assistant",
        content=response["assistant_reply"],
        suggestion_snapshot=response["updated_suggestion"],
    )

    # åŒæ­¥æ›´æ–° review_results ä¸­çš„å»ºè®®
    for mod in result.modifications:
        if mod.id == item_id:
            mod.suggested_text = response["updated_suggestion"]
            break
    storage_manager.save_result(result)

    # æ„å»ºå“åº”
    return ChatResponse(
        item_id=item_id,
        assistant_reply=response["assistant_reply"],
        updated_suggestion=response["updated_suggestion"],
        chat_status=updated_chat.status if updated_chat else "in_progress",
        messages=[
            {
                "role": msg.role,
                "content": msg.content,
                "timestamp": msg.timestamp.isoformat() if msg.timestamp else None,
            }
            for msg in (updated_chat.messages if updated_chat else [])
        ],
    )


@app.post("/api/interactive/{task_id}/items/{item_id}/chat/stream")
async def chat_with_item_stream(
    task_id: str,
    item_id: str,
    request: ChatRequest,
    user_id: str = Depends(get_current_user),
):
    """
    æµå¼ä¸ç‰¹å®šæ¡ç›®è¿›è¡Œå¯¹è¯ï¼ˆSSEï¼‰

    è¿”å› Server-Sent Events æµï¼Œæ ¼å¼ï¼š
    - data: {"type": "chunk", "content": "æ–‡æœ¬ç‰‡æ®µ"}
    - data: {"type": "suggestion", "content": "æ›´æ–°åçš„å»ºè®®"}
    - data: {"type": "done", "content": "å®Œæ•´å›å¤"}
    - data: {"type": "error", "content": "é”™è¯¯ä¿¡æ¯"}
    """
    import json as json_module

    # éªŒè¯ä»»åŠ¡
    task = task_manager.get_task(task_id)
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")

    # è·å–å®¡é˜…ç»“æœ
    result = storage_manager.load_result(task_id)
    if not result:
        raise HTTPException(status_code=404, detail="å®¡é˜…ç»“æœä¸å­˜åœ¨")

    # è·å–æ–‡æ¡£æ®µè½ç»“æ„ï¼ˆç”¨äºå·¥å…·è°ƒç”¨éªŒè¯ï¼‰
    doc_paragraphs = []
    try:
        # ä»ä»»åŠ¡ä¸­è·å–æ–‡æ¡£æ–‡æœ¬
        doc_text = getattr(task, 'document', '') or ''
        if doc_text:
            # ç®€å•æŒ‰åŒæ¢è¡Œåˆ†æ®µï¼ˆå®é™…åº”è¯¥ç”¨æ›´å¤æ‚çš„é€»è¾‘ï¼‰
            paragraphs = doc_text.split('\n\n')
            doc_paragraphs = [
                {"id": i+1, "content": para.strip()}
                for i, para in enumerate(paragraphs)
                if para.strip()
            ]
        logger.info(f"æ–‡æ¡£åŒ…å« {len(doc_paragraphs)} ä¸ªæ®µè½")
    except Exception as e:
        logger.warning(f"æ— æ³•è§£ææ–‡æ¡£æ®µè½: {e}")

    # æŸ¥æ‰¾æ¡ç›® - æ”¯æŒ risk_id æˆ– modification_id
    modification = None
    risk = None
    original_text = ""

    # é¦–å…ˆæ£€æŸ¥æ˜¯å¦æ˜¯ risk_id
    for r in result.risks:
        if r.id == item_id:
            risk = r
            # è·å–åŸæ–‡
            if risk.location and risk.location.original_text:
                original_text = risk.location.original_text
            elif hasattr(risk, 'original_text') and risk.original_text:
                original_text = risk.original_text
            # æŸ¥æ‰¾å¯¹åº”çš„ modification
            for mod in result.modifications:
                if mod.risk_id == risk.id:
                    modification = mod
                    break
            break

    # å¦‚æœä¸æ˜¯ risk_idï¼Œå°è¯•ä½œä¸º modification_id æŸ¥æ‰¾
    if not risk:
        for mod in result.modifications:
            if mod.id == item_id:
                modification = mod
                original_text = mod.original_text or ""
                for r in result.risks:
                    if r.id == mod.risk_id:
                        risk = r
                        break
                break

    if not risk:
        raise HTTPException(status_code=404, detail="æ¡ç›®ä¸å­˜åœ¨")

    # è·å–æˆ–åˆ›å»ºå¯¹è¯è®°å½•
    interactive_manager = get_interactive_manager()
    chat = interactive_manager.get_chat_by_item(task_id, item_id)

    if not chat:
        # åˆ›å»ºæ–°çš„å¯¹è¯è®°å½•
        chat = interactive_manager.create_chat(
            task_id=task_id,
            item_id=item_id,
            item_type="risk",
            initial_suggestion=modification.suggested_text if modification else "",
        )

    # å‡†å¤‡å¯¹è¯å†å²
    chat_history = [
        {"role": msg.role, "content": msg.content}
        for msg in chat.messages
    ]

    # åˆ›å»ºå¼•æ“
    engine = InteractiveReviewEngine(settings, llm_provider=request.llm_provider)

    async def event_generator():
        """ç”Ÿæˆ SSE äº‹ä»¶æµï¼ˆæ”¯æŒå·¥å…·è°ƒç”¨ï¼‰"""
        full_response = ""
        updated_suggestion = ""

        try:
            # æ¨é€æ€è€ƒäº‹ä»¶
            yield create_tool_thinking_event("æ­£åœ¨åˆ†ææ‚¨çš„è¯·æ±‚...")

            # æ„å»ºæ¶ˆæ¯ï¼ˆä½¿ç”¨prompts_interactiveçš„å‡½æ•°ï¼‰
            messages = build_item_chat_messages(
                original_clause=original_text or (modification.original_text if modification else ""),
                current_suggestion=chat.current_suggestion or (modification.suggested_text if modification else ""),
                risk_description=risk.description if risk else "",
                user_message=request.message,
                chat_history=chat_history,
                document_summary="",
                language=getattr(task, 'language', 'zh-CN'),
            )

            # æ³¨å…¥æ–‡æ¡£ç»“æ„åˆ°ç³»ç»Ÿæ¶ˆæ¯ï¼ˆé˜²æ­¢AIå¹»è§‰ï¼‰
            if doc_paragraphs and messages:
                doc_structure = format_document_structure(doc_paragraphs, max_paragraphs=100)

                # åœ¨ç¬¬ä¸€ä¸ªç³»ç»Ÿæ¶ˆæ¯åè¿½åŠ æ–‡æ¡£ç»“æ„
                if messages[0]["role"] == "system":
                    messages[0]["content"] += f"\n\n**å®Œæ•´æ–‡æ¡£ç»“æ„ï¼ˆç”¨äºå·¥å…·è°ƒç”¨ï¼‰ï¼š**\n{doc_structure}\n\n**é‡è¦ï¼šä½¿ç”¨å·¥å…·æ—¶ï¼Œparagraph_id å¿…é¡»æ˜¯ä¸Šè¿°åˆ—è¡¨ä¸­å®é™…å­˜åœ¨çš„ID**"

            # è°ƒç”¨LLMï¼ˆæ”¯æŒå·¥å…·ï¼‰
            response_text, tool_calls = await engine.llm.chat_with_tools(
                messages=messages,
                tools=DOCUMENT_TOOLS,
                temperature=0.3,
            )

            # å¤„ç†å·¥å…·è°ƒç”¨
            if tool_calls:
                supabase = get_supabase_client()
                tool_executor = DocumentToolExecutor(supabase)

                for tool_call in tool_calls:
                    tool_id = tool_call["id"]
                    tool_name = tool_call["function"]["name"]
                    tool_args = json_module.loads(tool_call["function"]["arguments"])

                    # æ¨é€å·¥å…·è°ƒç”¨äº‹ä»¶
                    yield create_tool_call_event(tool_id, tool_name, tool_args)

                    # æ‰§è¡Œå·¥å…·
                    result = await tool_executor.execute_tool(
                        tool_call=tool_call,
                        task_id=task_id,
                        document_paragraphs=doc_paragraphs
                    )

                    # æ¨é€å·¥å…·ç»“æœ
                    if result["success"]:
                        yield create_tool_result_event(
                            tool_id,
                            True,
                            result["message"],
                            result.get("data")
                        )

                        # å¦‚æœæ˜¯æ–‡æ¡£ä¿®æ”¹ç±»å·¥å…·ï¼Œæ¨é€doc_updateäº‹ä»¶
                        if tool_name in ["modify_paragraph", "batch_replace_text", "insert_clause"]:
                            yield create_doc_update_event(
                                result["change_id"],
                                tool_name,
                                result["data"]
                            )
                    else:
                        yield create_tool_error_event(tool_id, result["message"])

            # æµå¼æ¨é€AIå›å¤æ–‡æœ¬
            if response_text:
                words = response_text.split()
                for i, word in enumerate(words):
                    yield create_message_delta_event(word + (" " if i < len(words) - 1 else ""))
                    await asyncio.sleep(0.01)  # æ¨¡æ‹Ÿæ‰“å­—æ•ˆæœ

                full_response = response_text

            # ä¿å­˜å¯¹è¯è®°å½•
            if full_response or tool_calls:
                # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
                interactive_manager.add_message(
                    chat_id=chat.id,
                    role="user",
                    content=request.message,
                )

                # æ·»åŠ AIå›å¤ï¼ˆåŒ…å«å·¥å…·è°ƒç”¨ä¿¡æ¯ï¼‰
                interactive_manager.add_message(
                    chat_id=chat.id,
                    role="assistant",
                    content=full_response or "å·²æ‰§è¡Œæ“ä½œ",
                    suggestion_snapshot=updated_suggestion or chat.current_suggestion,
                )

                # åŒæ­¥æ›´æ–° review_results ä¸­çš„å»ºè®®
                if updated_suggestion:
                    found = False
                    for mod in result.modifications:
                        if mod.id == item_id or mod.risk_id == item_id:
                            mod.suggested_text = updated_suggestion
                            found = True
                            break
                    if found:
                        storage_manager.save_result(result)

            # å®Œæˆ
            yield create_done_event(True)

        except Exception as e:
            logger.error(f"æµå¼å¯¹è¯å¤±è´¥: {e}", exc_info=True)
            yield create_error_event(str(e))

    return StreamingResponse(
        event_generator(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no",  # ç¦ç”¨ nginx ç¼“å†²
        },
    )


@app.post("/api/interactive/{task_id}/items/{item_id}/complete")
async def complete_item(
    task_id: str,
    item_id: str,
    request: CompleteItemRequest,
    user_id: str = Depends(get_current_user),
):
    """æ ‡è®°æ¡ç›®ä¸ºå·²å®Œæˆ"""
    # éªŒè¯ä»»åŠ¡
    task = task_manager.get_task(task_id)
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")

    # è·å–å¯¹è¯è®°å½•
    interactive_manager = get_interactive_manager()
    chat = interactive_manager.get_chat_by_item(task_id, item_id)

    if not chat:
        raise HTTPException(status_code=404, detail="å¯¹è¯è®°å½•ä¸å­˜åœ¨")

    # å®Œæˆå¯¹è¯
    final_suggestion = request.final_suggestion or chat.current_suggestion
    success = interactive_manager.complete_chat(chat.id, final_suggestion)

    if not success:
        raise HTTPException(status_code=500, detail="å®Œæˆæ¡ç›®å¤±è´¥")

    # åŒæ­¥æ›´æ–° review_results
    result = storage_manager.load_result(task_id)
    if result:
        found = False
        # æ”¯æŒ risk_id æˆ– modification_id
        for mod in result.modifications:
            if mod.id == item_id or mod.risk_id == item_id:
                mod.suggested_text = final_suggestion
                mod.user_confirmed = True
                found = True
                break

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å¯¹åº”çš„ modificationï¼Œå¯èƒ½éœ€è¦åˆ›å»ºä¸€ä¸ªæ–°çš„
        # æ³¨æ„ï¼šRiskPoint.id æ˜¯ä¸€ä¸ªç®€çŸ­çš„ UUIDï¼ˆå¦‚ a1b2c3d4ï¼‰ï¼Œä¸æ˜¯ä»¥ risk_ å¼€å¤´
        if not found:
            # æŸ¥æ‰¾å¯¹åº”çš„é£é™©ç‚¹
            risk = next((r for r in result.risks if r.id == item_id), None)
            if risk:
                # è·å–åŸæ–‡
                original_text = ""
                if risk.location and risk.location.original_text:
                    original_text = risk.location.original_text
                elif hasattr(risk, 'original_text') and risk.original_text:
                    original_text = risk.original_text

                # åˆ›å»ºæ–°çš„ä¿®æ”¹å»ºè®®
                from src.contract_review.models import ModificationSuggestion
                new_mod = ModificationSuggestion(
                    risk_id=item_id,
                    original_text=original_text,
                    suggested_text=final_suggestion,
                    modification_reason=risk.description,
                    user_confirmed=True,
                )
                result.modifications.append(new_mod)

        storage_manager.save_result(result)

    return {
        "item_id": item_id,
        "status": "completed",
        "final_suggestion": final_suggestion,
    }


@app.post("/api/interactive/{task_id}/items/{item_id}/skip")
async def skip_item(
    task_id: str,
    item_id: str,
    user_id: str = Depends(get_current_user),
):
    """è·³è¿‡é£é™©ç‚¹ï¼ˆç”¨æˆ·é€‰æ‹©ä¸å¤„ç†ï¼‰

    æ ‡è®°è¯¥é£é™©ç‚¹ä¸º"è·³è¿‡"çŠ¶æ€ï¼Œä¸ç”Ÿæˆä¿®æ”¹å»ºè®®ã€‚
    """
    # éªŒè¯ä»»åŠ¡
    task = task_manager.get_task(task_id)
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")

    # è·å–å¯¹è¯è®°å½•
    interactive_manager = get_interactive_manager()
    chat = interactive_manager.get_chat_by_item(task_id, item_id)

    if not chat:
        # å¦‚æœæ²¡æœ‰å¯¹è¯è®°å½•ï¼Œå°è¯•åˆ›å»ºä¸€ä¸ª
        raise HTTPException(status_code=404, detail="å¯¹è¯è®°å½•ä¸å­˜åœ¨")

    # æ ‡è®°ä¸ºè·³è¿‡çŠ¶æ€
    success = interactive_manager.skip_chat(chat.id)

    if not success:
        raise HTTPException(status_code=500, detail="è·³è¿‡æ¡ç›®å¤±è´¥")

    return {
        "item_id": item_id,
        "status": "skipped",
        "message": "å·²è·³è¿‡è¯¥é£é™©ç‚¹",
    }


# ==================== æ–‡æ¡£å˜æ›´ç®¡ç† API ====================


@app.get("/api/tasks/{task_id}/changes")
async def get_task_changes(
    task_id: str,
    status: Optional[str] = Query(None, description="ç­›é€‰çŠ¶æ€: pending|applied|rejected|reverted"),
    user_id: str = Depends(get_current_user),
):
    """è·å–ä»»åŠ¡çš„æ‰€æœ‰æ–‡æ¡£å˜æ›´è®°å½•"""
    # éªŒè¯ä»»åŠ¡
    task = task_manager.get_task(task_id)
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")

    try:
        supabase = get_supabase_client()

        # æ„å»ºæŸ¥è¯¢
        query = supabase.table("document_changes").select("*").eq("task_id", task_id)

        if status:
            query = query.eq("status", status)

        query = query.order("created_at", desc=True)

        response = query.execute()

        return {
            "task_id": task_id,
            "changes": response.data,
            "total": len(response.data),
        }
    except Exception as e:
        logger.error(f"è·å–å˜æ›´è®°å½•å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"è·å–å˜æ›´è®°å½•å¤±è´¥: {str(e)}")


@app.post("/api/tasks/{task_id}/changes/{change_id}/apply")
async def apply_change(
    task_id: str,
    change_id: str,
    user_id: str = Depends(get_current_user),
):
    """åº”ç”¨ä¸€ä¸ªæ–‡æ¡£å˜æ›´"""
    # éªŒè¯ä»»åŠ¡
    task = task_manager.get_task(task_id)
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")

    try:
        supabase = get_supabase_client()

        # è·å–å˜æ›´è®°å½•
        response = supabase.table("document_changes").select("*").eq("id", change_id).eq("task_id", task_id).execute()

        if not response.data:
            raise HTTPException(status_code=404, detail="å˜æ›´è®°å½•ä¸å­˜åœ¨")

        change = response.data[0]

        # æ£€æŸ¥çŠ¶æ€
        if change["status"] == "applied":
            return {
                "change_id": change_id,
                "status": "applied",
                "message": "è¯¥å˜æ›´å·²ç»åº”ç”¨è¿‡äº†",
            }

        if change["status"] not in ["pending", "rejected"]:
            raise HTTPException(status_code=400, detail=f"æ— æ³•åº”ç”¨çŠ¶æ€ä¸º {change['status']} çš„å˜æ›´")

        # æ›´æ–°çŠ¶æ€ä¸º applied
        update_response = supabase.table("document_changes").update({
            "status": "applied",
            "applied_at": datetime.utcnow().isoformat(),
            "applied_by": user_id,
        }).eq("id", change_id).execute()

        return {
            "change_id": change_id,
            "status": "applied",
            "message": "å˜æ›´å·²åº”ç”¨",
            "data": update_response.data[0] if update_response.data else None,
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"åº”ç”¨å˜æ›´å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"åº”ç”¨å˜æ›´å¤±è´¥: {str(e)}")


@app.post("/api/tasks/{task_id}/changes/{change_id}/revert")
async def revert_change(
    task_id: str,
    change_id: str,
    user_id: str = Depends(get_current_user),
):
    """å›æ»šä¸€ä¸ªå·²åº”ç”¨çš„æ–‡æ¡£å˜æ›´"""
    # éªŒè¯ä»»åŠ¡
    task = task_manager.get_task(task_id)
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")

    try:
        supabase = get_supabase_client()

        # è·å–å˜æ›´è®°å½•
        response = supabase.table("document_changes").select("*").eq("id", change_id).eq("task_id", task_id).execute()

        if not response.data:
            raise HTTPException(status_code=404, detail="å˜æ›´è®°å½•ä¸å­˜åœ¨")

        change = response.data[0]

        # æ£€æŸ¥çŠ¶æ€ - åªèƒ½å›æ»šå·²åº”ç”¨çš„å˜æ›´
        if change["status"] != "applied":
            raise HTTPException(status_code=400, detail=f"åªèƒ½å›æ»šå·²åº”ç”¨çš„å˜æ›´ï¼Œå½“å‰çŠ¶æ€ä¸º: {change['status']}")

        # æ›´æ–°çŠ¶æ€ä¸º reverted
        update_response = supabase.table("document_changes").update({
            "status": "reverted",
        }).eq("id", change_id).execute()

        return {
            "change_id": change_id,
            "status": "reverted",
            "message": "å˜æ›´å·²å›æ»š",
            "data": update_response.data[0] if update_response.data else None,
        }
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"å›æ»šå˜æ›´å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"å›æ»šå˜æ›´å¤±è´¥: {str(e)}")


# ==================== æ‰¹é‡ç”Ÿæˆä¿®æ”¹å»ºè®® API ====================


class GenerateModificationsRequest(BaseModel):
    """æ‰¹é‡ç”Ÿæˆä¿®æ”¹å»ºè®®è¯·æ±‚"""
    risk_ids: List[str]  # éœ€è¦ç”Ÿæˆä¿®æ”¹å»ºè®®çš„é£é™©ç‚¹ ID åˆ—è¡¨
    user_notes: Optional[dict] = None  # ç”¨æˆ·å¤‡æ³¨ï¼Œkey ä¸º risk_idï¼Œvalue ä¸ºå¤‡æ³¨å†…å®¹


class GenerateModificationsResponse(BaseModel):
    """æ‰¹é‡ç”Ÿæˆä¿®æ”¹å»ºè®®å“åº”"""
    task_id: str
    modifications_count: int
    modifications: List[dict]


@app.post("/api/tasks/{task_id}/generate-modifications", response_model=GenerateModificationsResponse)
async def generate_modifications_for_risks(
    task_id: str,
    request: GenerateModificationsRequest,
    user_id: str = Depends(get_current_user),
):
    """
    ä¸ºæŒ‡å®šçš„é£é™©ç‚¹æ‰¹é‡ç”Ÿæˆä¿®æ”¹å»ºè®®

    è¿™ä¸ª API ç”¨äº"å…ˆåˆ†æè®¨è®ºã€åç»Ÿä¸€æ”¹åŠ¨"çš„å·¥ä½œæµç¨‹ï¼š
    1. ç”¨æˆ·å…ˆæŸ¥çœ‹é£é™©åˆ†æï¼Œä¸ AI è®¨è®º
    2. ç”¨æˆ·é€‰æ‹©éœ€è¦ä¿®æ”¹çš„é£é™©ç‚¹
    3. è°ƒç”¨æ­¤ API ä¸ºé€‰ä¸­çš„é£é™©ç‚¹ç”Ÿæˆä¿®æ”¹å»ºè®®

    Args:
        task_id: ä»»åŠ¡ ID
        request: åŒ…å« risk_idsï¼ˆéœ€è¦ç”Ÿæˆä¿®æ”¹å»ºè®®çš„é£é™©ç‚¹ ID åˆ—è¡¨ï¼‰å’Œå¯é€‰çš„ user_notes

    Returns:
        ç”Ÿæˆçš„ä¿®æ”¹å»ºè®®åˆ—è¡¨
    """
    # éªŒè¯ä»»åŠ¡
    task = task_manager.get_task(task_id)
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")

    # éªŒè¯ä»»åŠ¡å½’å±
    if USE_SUPABASE:
        task_user_id = task_manager.get_task_user_id(task_id)
        if task_user_id != user_id:
            raise HTTPException(status_code=403, detail="æ— æƒè®¿é—®æ­¤ä»»åŠ¡")

    # è·å–å®¡é˜…ç»“æœ
    result = storage_manager.load_result(task_id)
    if not result:
        raise HTTPException(status_code=404, detail="å®¡é˜…ç»“æœä¸å­˜åœ¨")

    # è·å–æ–‡æ¡£æ–‡æœ¬
    try:
        if USE_SUPABASE:
            doc_path = task_manager.get_document_path(task_id, user_id)
        else:
            doc_path = storage_manager.get_document_path(task_id)

        if not doc_path or not doc_path.exists():
            raise HTTPException(status_code=404, detail="æ–‡æ¡£æ–‡ä»¶ä¸å­˜åœ¨")

        document = await load_document_async(doc_path)
        document_text = document.text if document else ""
    except Exception as e:
        logger.error(f"åŠ è½½æ–‡æ¡£å¤±è´¥: {e}")
        document_text = ""

    # æ„å»ºéœ€è¦ç”Ÿæˆä¿®æ”¹å»ºè®®çš„é£é™©ç‚¹åˆ—è¡¨
    risk_map = {r.id: r for r in result.risks}
    confirmed_risks = []

    for risk_id in request.risk_ids:
        if risk_id not in risk_map:
            logger.warning(f"é£é™©ç‚¹ {risk_id} ä¸å­˜åœ¨ï¼Œè·³è¿‡")
            continue

        risk = risk_map[risk_id]

        # è·å–åŸæ–‡
        original_text = ""
        if risk.location and risk.location.original_text:
            original_text = risk.location.original_text

        # è·å–ç”¨æˆ·å¤‡æ³¨
        user_note = ""
        if request.user_notes and risk_id in request.user_notes:
            user_note = request.user_notes[risk_id]

        confirmed_risks.append({
            "risk": risk,
            "original_text": original_text,
            "user_notes": user_note,
        })

    if not confirmed_risks:
        return GenerateModificationsResponse(
            task_id=task_id,
            modifications_count=0,
            modifications=[],
        )

    # åˆ›å»ºäº¤äº’å¼•æ“å¹¶ç”Ÿæˆä¿®æ”¹å»ºè®®
    try:
        engine = InteractiveReviewEngine(settings, llm_provider="deepseek")
        modifications = await engine.generate_modifications_batch(
            confirmed_risks=confirmed_risks,
            document_text=document_text,
            our_party=result.our_party,
            material_type=result.material_type,
            language=result.language,
        )
    except Exception as e:
        logger.error(f"æ‰¹é‡ç”Ÿæˆä¿®æ”¹å»ºè®®å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"ç”Ÿæˆä¿®æ”¹å»ºè®®å¤±è´¥: {str(e)}")

    # å°†ç”Ÿæˆçš„ä¿®æ”¹å»ºè®®æ·»åŠ åˆ°ç»“æœä¸­
    for mod in modifications:
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨è¯¥é£é™©ç‚¹çš„ä¿®æ”¹å»ºè®®
        existing = next((m for m in result.modifications if m.risk_id == mod.risk_id), None)
        if existing:
            # æ›´æ–°å·²å­˜åœ¨çš„ä¿®æ”¹å»ºè®®
            existing.suggested_text = mod.suggested_text
            existing.modification_reason = mod.modification_reason
            existing.priority = mod.priority
        else:
            # æ·»åŠ æ–°çš„ä¿®æ”¹å»ºè®®
            result.modifications.append(mod)

    # é‡æ–°è®¡ç®—æ‘˜è¦
    result.calculate_summary()

    # ä¿å­˜ç»“æœ
    storage_manager.save_result(result)

    # è¿”å›ç”Ÿæˆçš„ä¿®æ”¹å»ºè®®
    return GenerateModificationsResponse(
        task_id=task_id,
        modifications_count=len(modifications),
        modifications=[
            {
                "id": m.id,
                "risk_id": m.risk_id,
                "original_text": m.original_text,
                "suggested_text": m.suggested_text,
                "modification_reason": m.modification_reason,
                "priority": m.priority,
            }
            for m in modifications
        ],
    )


class GenerateSingleModificationRequest(BaseModel):
    """å•æ¡ä¿®æ”¹å»ºè®®ç”Ÿæˆè¯·æ±‚"""
    discussion_summary: str  # ä¸ç”¨æˆ·çš„è®¨è®ºæ‘˜è¦
    user_decision: str  # ç”¨æˆ·çš„æœ€ç»ˆå†³å®š


@app.post("/api/tasks/{task_id}/risks/{risk_id}/generate-modification")
async def generate_single_modification(
    task_id: str,
    risk_id: str,
    request: GenerateSingleModificationRequest,
    user_id: str = Depends(get_current_user),
):
    """
    ä¸ºå•ä¸ªé£é™©ç‚¹ç”Ÿæˆä¿®æ”¹å»ºè®®ï¼ˆåŸºäºè®¨è®ºç»“æœï¼‰

    ç”¨äºç”¨æˆ·ä¸ AI è®¨è®ºå®ŒæŸä¸ªé£é™©ç‚¹åï¼ŒåŸºäºè®¨è®ºç»“æœç”Ÿæˆç²¾å‡†çš„ä¿®æ”¹å»ºè®®ã€‚

    Args:
        task_id: ä»»åŠ¡ ID
        risk_id: é£é™©ç‚¹ ID
        request: åŒ…å«è®¨è®ºæ‘˜è¦å’Œç”¨æˆ·å†³å®š

    Returns:
        ç”Ÿæˆçš„ä¿®æ”¹å»ºè®®
    """
    # éªŒè¯ä»»åŠ¡
    task = task_manager.get_task(task_id)
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")

    # éªŒè¯ä»»åŠ¡å½’å±
    if USE_SUPABASE:
        task_user_id = task_manager.get_task_user_id(task_id)
        if task_user_id != user_id:
            raise HTTPException(status_code=403, detail="æ— æƒè®¿é—®æ­¤ä»»åŠ¡")

    # è·å–å®¡é˜…ç»“æœ
    result = storage_manager.load_result(task_id)
    if not result:
        raise HTTPException(status_code=404, detail="å®¡é˜…ç»“æœä¸å­˜åœ¨")

    # æŸ¥æ‰¾é£é™©ç‚¹
    risk = next((r for r in result.risks if r.id == risk_id), None)
    if not risk:
        raise HTTPException(status_code=404, detail="é£é™©ç‚¹ä¸å­˜åœ¨")

    # è·å–åŸæ–‡
    original_text = ""
    if risk.location and risk.location.original_text:
        original_text = risk.location.original_text

    # æ ¹æ®æ˜¯å¦æœ‰åŸæ–‡ï¼Œé€‰æ‹©ç”Ÿæˆä¿®æ”¹å»ºè®®æˆ–è¡¥å……æ¡æ¬¾
    engine = InteractiveReviewEngine(settings, llm_provider="deepseek")

    if original_text:
        # æœ‰åŸæ–‡ï¼šç”Ÿæˆä¿®æ”¹å»ºè®®
        try:
            modification = await engine.generate_single_modification(
                risk_point=risk,
                original_text=original_text,
                our_party=result.our_party,
                material_type=result.material_type,
                discussion_summary=request.discussion_summary,
                user_decision=request.user_decision,
                language=result.language,
            )
        except Exception as e:
            logger.error(f"ç”Ÿæˆå•æ¡ä¿®æ”¹å»ºè®®å¤±è´¥: {e}", exc_info=True)
            raise HTTPException(status_code=500, detail=f"ç”Ÿæˆä¿®æ”¹å»ºè®®å¤±è´¥: {str(e)}")
    else:
        # æ²¡æœ‰åŸæ–‡ï¼šç”Ÿæˆè¡¥å……æ¡æ¬¾å»ºè®®ï¼ˆç¼ºå¤±æ¡æ¬¾ç±»å‹ï¼‰
        logger.info(f"é£é™©ç‚¹ {risk_id} æ²¡æœ‰åŸæ–‡ï¼Œå°†ç”Ÿæˆè¡¥å……æ¡æ¬¾å»ºè®®")
        try:
            modification = await engine.generate_addition_clause(
                risk_point=risk,
                our_party=result.our_party,
                material_type=result.material_type,
                discussion_summary=request.discussion_summary,
                user_decision=request.user_decision,
                language=result.language,
            )
        except Exception as e:
            logger.error(f"ç”Ÿæˆè¡¥å……æ¡æ¬¾å¤±è´¥: {e}", exc_info=True)
            raise HTTPException(status_code=500, detail=f"ç”Ÿæˆè¡¥å……æ¡æ¬¾å¤±è´¥: {str(e)}")

    if not modification:
        raise HTTPException(status_code=500, detail="ç”Ÿæˆå»ºè®®å¤±è´¥")

    # å°†ä¿®æ”¹å»ºè®®æ·»åŠ åˆ°ç»“æœä¸­
    existing = next((m for m in result.modifications if m.risk_id == risk_id), None)
    if existing:
        existing.suggested_text = modification.suggested_text
        existing.modification_reason = modification.modification_reason
        existing.priority = modification.priority
        existing.is_addition = modification.is_addition
        existing.insertion_point = modification.insertion_point
    else:
        result.modifications.append(modification)

    # é‡æ–°è®¡ç®—æ‘˜è¦å¹¶ä¿å­˜
    result.calculate_summary()
    storage_manager.save_result(result)

    return {
        "id": modification.id,
        "risk_id": modification.risk_id,
        "original_text": modification.original_text,
        "suggested_text": modification.suggested_text,
        "modification_reason": modification.modification_reason,
        "priority": modification.priority,
        "is_addition": modification.is_addition,
        "insertion_point": modification.insertion_point,
    }


# ==================== æ–‡æ¡£å†…å®¹ API ====================


class DocumentParagraph(BaseModel):
    """æ–‡æ¡£æ®µè½"""
    index: int
    text: str
    start_char: int
    end_char: int


class DocumentTextResponse(BaseModel):
    """æ–‡æ¡£å…¨æ–‡å“åº”"""
    task_id: str
    document_name: str
    text: str
    paragraphs: List[DocumentParagraph]


@app.get("/api/tasks/{task_id}/document/text", response_model=DocumentTextResponse)
async def get_document_text(
    task_id: str,
    user_id: str = Depends(get_current_user),
):
    """
    è·å–æ–‡æ¡£çš„çº¯æ–‡æœ¬å†…å®¹

    è¿”å›æ–‡æ¡£å…¨æ–‡åŠæ®µè½ä¿¡æ¯ï¼Œç”¨äºäº¤äº’å®¡é˜…é¡µé¢å·¦ä¾§çš„æ–‡æ¡£å±•ç¤ºã€‚
    """
    # éªŒè¯ä»»åŠ¡
    task = task_manager.get_task(task_id)
    if not task:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")

    # éªŒè¯ä»»åŠ¡å½’å±
    if USE_SUPABASE:
        task_user_id = task_manager.get_task_user_id(task_id)
        if task_user_id != user_id:
            raise HTTPException(status_code=403, detail="æ— æƒè®¿é—®æ­¤ä»»åŠ¡")

    if not task.document_filename:
        raise HTTPException(status_code=404, detail="æœªæ‰¾åˆ°æ–‡æ¡£")

    try:
        # è·å–æ–‡æ¡£è·¯å¾„
        if USE_SUPABASE:
            doc_path = task_manager.get_document_path(task_id, user_id)
        else:
            doc_path = storage_manager.get_document_path(task_id)

        if not doc_path or not doc_path.exists():
            raise HTTPException(status_code=404, detail="æ–‡æ¡£æ–‡ä»¶ä¸å­˜åœ¨")

        # ä½¿ç”¨å·²æœ‰çš„æ–‡æ¡£åŠ è½½åŠŸèƒ½è§£ææ–‡æ¡£
        document = await load_document_async(doc_path)

        if not document or not document.text:
            raise HTTPException(status_code=500, detail="æ— æ³•è§£ææ–‡æ¡£å†…å®¹")

        # å°†æ–‡æ¡£æ‹†åˆ†ä¸ºæ®µè½
        paragraphs = []
        current_pos = 0

        # æŒ‰æ¢è¡Œç¬¦åˆ†å‰²ï¼Œä¿ç•™éç©ºæ®µè½
        raw_paragraphs = document.text.split('\n')

        for idx, para_text in enumerate(raw_paragraphs):
            # è·³è¿‡ç©ºæ®µè½
            stripped = para_text.strip()
            if not stripped:
                current_pos += len(para_text) + 1  # +1 for newline
                continue

            start_pos = current_pos
            end_pos = current_pos + len(para_text)

            paragraphs.append(DocumentParagraph(
                index=len(paragraphs),
                text=stripped,
                start_char=start_pos,
                end_char=end_pos,
            ))

            current_pos = end_pos + 1  # +1 for newline

        return DocumentTextResponse(
            task_id=task_id,
            document_name=task.document_filename,
            text=document.text,
            paragraphs=paragraphs,
        )

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–æ–‡æ¡£å†…å®¹å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"è·å–æ–‡æ¡£å†…å®¹å¤±è´¥: {str(e)}")


# ==================== å¥åº·æ£€æŸ¥ ====================

@app.get("/api/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "healthy",
        "version": "1.0.0",
        "llm_model": settings.llm.model,
    }


# ==================== é™æ€æ–‡ä»¶æœåŠ¡ ====================

# æŒ‚è½½å‰ç«¯é™æ€æ–‡ä»¶ï¼ˆç”Ÿäº§ç¯å¢ƒï¼‰
frontend_dist = Path(__file__).parent / "frontend" / "dist"
if frontend_dist.exists():
    app.mount("/", StaticFiles(directory=str(frontend_dist), html=True), name="frontend")


# ==================== å¯åŠ¨å…¥å£ ====================

if __name__ == "__main__":
    import uvicorn

    uvicorn.run(
        "api_server:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
    )
